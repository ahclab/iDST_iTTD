{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check GPU availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import copy\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import plotly\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm_notebook\n",
    "from idst_util import trivial\n",
    "from idst_util import dstc2\n",
    "from dstc2.dstc2_scripts import score\n",
    "\n",
    "from plotly.graph_objs import Scatter, Layout, Histogram, Histogram2d\n",
    "from plotly.graph_objs.layout import Margin\n",
    "plotly.offline.init_notebook_mode(connected = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check DSTC2 availability and retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trivial.print_idst()\n",
    "\n",
    "dstc2.check()\n",
    "\n",
    "raw_X_train, raw_Y_train, \\\n",
    "raw_X_dev, raw_Y_dev, \\\n",
    "raw_X_test, raw_Y_test, \\\n",
    "ontology = dstc2.retrieve_raw_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"+--------------------------------+\")\n",
    "logging.info(\"|             Device             |\")\n",
    "logging.info(\"+--------------------------------+\")\n",
    "\n",
    "GPU_ID = 1\n",
    "DEVICE = torch.device(\"cuda:{}\".format(GPU_ID) if torch.cuda.is_available() else \"cpu\")\n",
    "if str(DEVICE) == \"cpu\":\n",
    "    logging.warning(\"Running on CPU\")\n",
    "else:\n",
    "    logging.info(\"Running on GPU {}\".format(GPU_ID))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create vocabularies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"+--------------------------------+\")\n",
    "logging.info(\"|          Vocabulary            |\")\n",
    "logging.info(\"+--------------------------------+\")\n",
    "logging.info(\"Creating token_to_index, index_to_token and token_to_count dictionaries\")\n",
    "\n",
    "token_to_index = {\"<unk>\": 0}\n",
    "index_to_token = {0: \"<unk>\"}\n",
    "token_to_count = {\"<unk>\": 1}\n",
    "\n",
    "for raw_train_dialog in tqdm_notebook(raw_X_train):\n",
    "    for raw_train_turn in raw_train_dialog[\"turns\"]:\n",
    "        tokens_scores = raw_train_turn[\"system\"] + raw_train_turn[\"user\"]\n",
    "        for token_score in tokens_scores:\n",
    "            token = token_score[0]\n",
    "            if token not in token_to_index:\n",
    "                token_to_index[token] = len(token_to_index)\n",
    "                index_to_token[len(token_to_index)] = token\n",
    "                token_to_count[token] = 1\n",
    "            else:\n",
    "                token_to_count[token] += 1\n",
    "                \n",
    "assert len(token_to_index) == len(index_to_token)\n",
    "assert len(token_to_index) == len(token_to_count)\n",
    "\n",
    "logging.info(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"+--------------------------------+\")\n",
    "logging.info(\"|         Configuration          |\")\n",
    "logging.info(\"+--------------------------------+\")\n",
    "\n",
    "VOCABULARY_SIZE = len(token_to_index)\n",
    "\n",
    "# NOTE: we add +2 because of null and dontcare cases\n",
    "GOAL_FOOD_DIM = len(ontology[\"informable\"][\"food\"]) + 2 \n",
    "GOAL_PRICERANGE_DIM = len(ontology[\"informable\"][\"pricerange\"]) + 2\n",
    "GOAL_NAME_DIM = len(ontology[\"informable\"][\"name\"]) + 2\n",
    "GOAL_AREA_DIM = len(ontology[\"informable\"][\"area\"]) + 2\n",
    "\n",
    "METHOD_DIM = len(ontology[\"method\"])\n",
    "\n",
    "REQUESTED_DIM = len(ontology[\"requestable\"])\n",
    "\n",
    "EMBEDDING_DIM = 170\n",
    "ALTERED_EMBEDDING_DIM = 300\n",
    "HIDDEN_DIM = 100\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 10\n",
    "PATIENCE = 4\n",
    "\n",
    "GOAL_LOSS_FUNCTION = nn.CrossEntropyLoss()\n",
    "METHOD_LOSS_FUNCTION = nn.CrossEntropyLoss()\n",
    "REQUESTED_LOSS_FUNCTION = nn.BCELoss()\n",
    "\n",
    "logging.info(\"VOCABULARY_SIZE:\\t\\t\\t{}\".format(VOCABULARY_SIZE))\n",
    "\n",
    "logging.info(\"GOAL_FOOD_DIM:\\t\\t\\t{}\".format(GOAL_FOOD_DIM))\n",
    "logging.info(\"GOAL_PRICERANGE_DIM:\\t\\t\\t{}\".format(GOAL_PRICERANGE_DIM))\n",
    "logging.info(\"GOAL_NAME_DIM:\\t\\t\\t{}\".format(GOAL_NAME_DIM))\n",
    "logging.info(\"GOAL_AREA_DIM:\\t\\t\\t{}\".format(GOAL_AREA_DIM))\n",
    "\n",
    "logging.info(\"METHOD_DIM:\\t\\t\\t\\t{}\".format(METHOD_DIM))\n",
    "\n",
    "logging.info(\"REQUESTED_DIM:\\t\\t\\t{}\".format(REQUESTED_DIM))\n",
    "\n",
    "logging.info(\"EMBEDDING_DIM:\\t\\t\\t{}\".format(EMBEDDING_DIM))\n",
    "logging.info(\"ALTERED_EMBEDDING_DIM:\\t\\t{}\".format(ALTERED_EMBEDDING_DIM))\n",
    "logging.info(\"HIDDEN_DIM:\\t\\t\\t\\t{}\".format(HIDDEN_DIM))\n",
    "\n",
    "logging.info(\"NUM_EPOCHS:\\t\\t\\t\\t{}\".format(NUM_EPOCHS))\n",
    "logging.info(\"BATCH_SIZE:\\t\\t\\t\\t{}\".format(BATCH_SIZE))\n",
    "logging.info(\"PATIENCE:\\t\\t\\t\\t{}\".format(PATIENCE))\n",
    "\n",
    "logging.info(\"GOAL_LOSS_FUNCTION:\\t\\t\\t{}\".format(GOAL_LOSS_FUNCTION))\n",
    "logging.info(\"METHOD_LOSS_FUNCTION:\\t\\t\\t{}\".format(METHOD_LOSS_FUNCTION))\n",
    "logging.info(\"REQUESTED_LOSS_FUNCTION:\\t\\t{}\".format(REQUESTED_LOSS_FUNCTION))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_and_score(turn, token_to_index, mode, device):\n",
    "    \n",
    "    indices = []\n",
    "    scores = []\n",
    "    \n",
    "    if mode == \"train\": # LecTrack 4.3: Out-of-Vocabulary Words\n",
    "        for system_token, system_token_score in turn[\"system\"]:\n",
    "            indices.append(token_to_index[system_token])\n",
    "            scores.append(system_token_score)\n",
    "        for user_token, user_token_score in turn[\"user\"]:\n",
    "            if np.random.binomial(n = 1, p = 0.1) == 1:\n",
    "                indices.append(token_to_index[\"<unk>\"])\n",
    "            else:\n",
    "                indices.append(token_to_index[user_token])\n",
    "            scores.append(user_token_score)\n",
    "    else:\n",
    "        tokens_scores = turn[\"system\"] + turn[\"user\"]\n",
    "        for token, score in tokens_scores:\n",
    "            if token not in token_to_index:\n",
    "                indices.append(token_to_index[\"<unk>\"])\n",
    "            else:\n",
    "                indices.append(token_to_index[token])\n",
    "            scores.append(score)\n",
    "            \n",
    "    assert len(indices) == len(scores)\n",
    "    \n",
    "    return torch.tensor(indices, dtype = torch.long, device = device), torch.tensor(scores, dtype = torch.float, device = device)\n",
    "\n",
    "# --------------------\n",
    "\n",
    "class EarlyStopping():\n",
    "    \n",
    "    def __init__(self, min_delta = 0, patience = 0):\n",
    "        \n",
    "        self.min_delta = min_delta\n",
    "        self.patience = patience\n",
    "        self.wait = 0\n",
    "        self.stopped_epoch = 0\n",
    "        self.best = -np.Inf\n",
    "        self.stop_training = False\n",
    "    \n",
    "    def on_epoch_end(self, epoch, current_value):\n",
    "        if np.greater((current_value - self.min_delta), self.best):\n",
    "            self.best = current_value\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait > self.patience:\n",
    "                self.stopped_epoch = epoch\n",
    "                self.stop_training = True\n",
    "        return self.stop_training\n",
    "\n",
    "# --------------------\n",
    "    \n",
    "def get_incremental_index_and_percentage(percentage, length):\n",
    "    \n",
    "    incremental_index = -1\n",
    "    new_percentage = None\n",
    "    \n",
    "    if length != 0:\n",
    "        incremental_index = int(np.around(percentage * length)) - 1\n",
    "        new_percentage = np.around(((incremental_index + 1) / length), decimals = 2)\n",
    "    \n",
    "    return incremental_index, new_percentage\n",
    "\n",
    "# --------------------\n",
    "\n",
    "def make_tracker(model_Goal, model_Requested, model_Method, raw_X, raw_Y, dataset, percentage = 1.0):\n",
    "    \n",
    "    model_Goal = model_Goal.eval()\n",
    "    model_Requested = model_Requested.eval()\n",
    "    model_Method = model_Method.eval()\n",
    "    \n",
    "    percentage_points = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        tracker_json = {}\n",
    "        tracker_json[\"dataset\"] = dataset\n",
    "        tracker_json[\"sessions\"] = []\n",
    "\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for raw_X_dialog, raw_Y_dialog in tqdm_notebook(zip(raw_X, raw_Y), total = len(raw_X)):\n",
    "            \n",
    "            model_Goal.hidden = model_Goal.init_hidden()\n",
    "            model_Requested.hidden = model_Requested.init_hidden()\n",
    "            model_Method.hidden = model_Method.init_hidden()\n",
    "            \n",
    "            session = {}\n",
    "            session[\"session-id\"] = raw_X_dialog[\"session-id\"]\n",
    "            session[\"turns\"] = []\n",
    "\n",
    "            for turn_num, (raw_X_turn, raw_Y_turn) in enumerate(zip(raw_X_dialog[\"turns\"], raw_Y_dialog[\"turns\"])):\n",
    "\n",
    "                indices, scores = get_index_and_score(raw_X_turn, token_to_index, mode = \"eval\", device = DEVICE)\n",
    "                \n",
    "                # NOTE: percentage is based on user utterance\n",
    "                incremental_index, new_percentage_point = get_incremental_index_and_percentage(percentage = percentage, length = len(raw_X_turn[\"user\"]))\n",
    "                incremental_index += len(raw_X_turn[\"system\"])\n",
    "                if new_percentage_point != None:\n",
    "                    percentage_points.append(new_percentage_point)\n",
    "                \n",
    "                goal_priceranges, goal_areas, goal_names, goal_foods = model_Goal(indices, scores)\n",
    "                requesteds = model_Requested(indices, scores)\n",
    "                methods = model_Method(indices, scores)\n",
    "                goal_pricerange = goal_priceranges[incremental_index]\n",
    "                goal_name = goal_names[incremental_index]\n",
    "                goal_area = goal_areas[incremental_index]\n",
    "                goal_food = goal_foods[incremental_index]\n",
    "                requested = requesteds[incremental_index]\n",
    "                method = methods[incremental_index]\n",
    "                \n",
    "                turn = {}\n",
    "                turn[\"num\"] = turn_num\n",
    "                turn[\"goal-labels\"] = {}\n",
    "                turn[\"goal-labels\"][\"food\"] = retrieve_output_GoalFood(goal_food, ontology)\n",
    "                turn[\"goal-labels\"][\"pricerange\"] = retrieve_output_GoalPricerange(goal_pricerange, ontology)\n",
    "                turn[\"goal-labels\"][\"name\"] = retrieve_output_GoalName(goal_name, ontology)\n",
    "                turn[\"goal-labels\"][\"area\"] = retrieve_output_GoalArea(goal_area, ontology)\n",
    "                turn[\"requested-slots\"] = retrieve_output_Requested(requested, ontology)\n",
    "                turn[\"method-label\"] = retrieve_output_Method(method, ontology)\n",
    "                \n",
    "                session[\"turns\"].append(turn)\n",
    "                \n",
    "            tracker_json[\"sessions\"].append(session)\n",
    "            \n",
    "        end_time = time.time()\n",
    "        tracker_json[\"wall-time\"] = end_time - start_time\n",
    "        \n",
    "        return tracker_json, np.around(np.mean(np.array(percentage_points)), decimals = 2)\n",
    "\n",
    "# --------------------\n",
    "    \n",
    "def get_scores(tracker, dataset, ontology):\n",
    "    \n",
    "    scores_dict = None\n",
    "\n",
    "    if dataset == \"dstc2_train\":\n",
    "        scores_dict = score.compute_score(dataset = \"dstc2_train\", dataroot = \"dstc2/dstc2_traindev/data\", tracker_output = tracker, ontology = ontology)\n",
    "    elif dataset == \"dstc2_dev\":\n",
    "        scores_dict = score.compute_score(dataset = \"dstc2_dev\", dataroot = \"dstc2/dstc2_traindev/data\", tracker_output = tracker, ontology = ontology)\n",
    "    else: # dataset == \"dstc2_test\"\n",
    "        scores_dict = score.compute_score(dataset = \"dstc2_test\", dataroot = \"dstc2/dstc2_test/data\", tracker_output = tracker, ontology = ontology)\n",
    "            \n",
    "    return scores_dict\n",
    "\n",
    "# --------------------\n",
    "\n",
    "def retrieve_gold_GoalPricerange(raw_Y, ontology, device):\n",
    "    ontology_informable_pricerange = ontology[\"informable\"][\"pricerange\"]\n",
    "    raw_goal_pricerange = raw_Y[\"goal\"][\"pricerange\"]\n",
    "    goal_pricerange = 0\n",
    "    if raw_goal_pricerange != None:\n",
    "        if raw_goal_pricerange == \"dontcare\":\n",
    "            goal_pricerange = 1\n",
    "        else:    \n",
    "            goal_pricerange = ontology_informable_pricerange.index(raw_goal_pricerange) + 2\n",
    "    return torch.tensor([goal_pricerange], dtype = torch.long, device = device)\n",
    "\n",
    "def retrieve_output_GoalPricerange(output_tensor, ontology):\n",
    "    ontology_informable_pricerange = ontology[\"informable\"][\"pricerange\"]\n",
    "    output_tensor = output_tensor.view(-1)\n",
    "    output_tensor = torch.exp(output_tensor)\n",
    "    goal_pricerange_dict = {}\n",
    "    goal_pricerange_dict[\"dontcare\"] = output_tensor[1].item()\n",
    "    for index in range(len(output_tensor) - 2):     \n",
    "        goal_pricerange_dict[ontology_informable_pricerange[index]] = output_tensor[index + 2].item()\n",
    "    return goal_pricerange_dict\n",
    "\n",
    "# --------------------\n",
    "\n",
    "def retrieve_gold_GoalArea(raw_Y, ontology, device):\n",
    "    ontology_informable_area = ontology[\"informable\"][\"area\"]\n",
    "    raw_goal_area = raw_Y[\"goal\"][\"area\"]\n",
    "    goal_area = 0\n",
    "    if raw_goal_area != None:\n",
    "        if raw_goal_area == \"dontcare\":\n",
    "            goal_area = 1\n",
    "        else:    \n",
    "            goal_area = ontology_informable_area.index(raw_goal_area) + 2\n",
    "    return torch.tensor([goal_area], dtype = torch.long, device = device)\n",
    "\n",
    "def retrieve_output_GoalArea(output_tensor, ontology):\n",
    "    ontology_informable_area = ontology[\"informable\"][\"area\"]\n",
    "    output_tensor = output_tensor.view(-1)\n",
    "    output_tensor = torch.exp(output_tensor)\n",
    "    goal_area_dict = {}\n",
    "    goal_area_dict[\"dontcare\"] = output_tensor[1].item()\n",
    "    for index in range(len(output_tensor) - 2):\n",
    "        goal_area_dict[ontology_informable_area[index]] = output_tensor[index + 2].item()\n",
    "    return goal_area_dict\n",
    "\n",
    "# --------------------\n",
    "\n",
    "def retrieve_gold_GoalName(raw_Y, ontology, device):\n",
    "    ontology_informable_name = ontology[\"informable\"][\"name\"]\n",
    "    raw_goal_name = raw_Y[\"goal\"][\"name\"]\n",
    "    goal_name = 0\n",
    "    if raw_goal_name != None:\n",
    "        if raw_goal_name == \"dontcare\":\n",
    "            goal_name = 1\n",
    "        else:    \n",
    "            goal_name = ontology_informable_name.index(raw_goal_name) + 2\n",
    "    return torch.tensor([goal_name], dtype = torch.long, device = device)\n",
    "\n",
    "def retrieve_output_GoalName(output_tensor, ontology):\n",
    "    ontology_informable_name = ontology[\"informable\"][\"name\"]\n",
    "    output_tensor = output_tensor.view(-1)\n",
    "    output_tensor = torch.exp(output_tensor)\n",
    "    goal_name_dict = {}\n",
    "    goal_name_dict[\"dontcare\"] = output_tensor[1].item()\n",
    "    for index in range(len(output_tensor) - 2):\n",
    "        goal_name_dict[ontology_informable_name[index]] = output_tensor[index + 2].item()\n",
    "    return goal_name_dict\n",
    "\n",
    "# --------------------\n",
    "\n",
    "def retrieve_gold_GoalFood(raw_Y, ontology, device):\n",
    "    ontology_informable_food = ontology[\"informable\"][\"food\"]\n",
    "    raw_goal_food = raw_Y[\"goal\"][\"food\"]\n",
    "    goal_food = 0\n",
    "    if raw_goal_food != None:\n",
    "        if raw_goal_food == \"dontcare\":\n",
    "            goal_food = 1\n",
    "        else:    \n",
    "            goal_food = ontology_informable_food.index(raw_goal_food) + 2\n",
    "    return torch.tensor([goal_food], dtype = torch.long, device = device)\n",
    "\n",
    "def retrieve_output_GoalFood(output_tensor, ontology):\n",
    "    ontology_informable_food = ontology[\"informable\"][\"food\"]\n",
    "    output_tensor = output_tensor.view(-1)\n",
    "    output_tensor = torch.exp(output_tensor)\n",
    "    goal_food_dict = {}\n",
    "    goal_food_dict[\"dontcare\"] = output_tensor[1].item() \n",
    "    for index in range(len(output_tensor) - 2):\n",
    "        goal_food_dict[ontology_informable_food[index]] = output_tensor[index + 2].item()\n",
    "    return goal_food_dict\n",
    "\n",
    "# --------------------\n",
    "\n",
    "def retrieve_gold_Requested(raw_Y, ontology, device):\n",
    "    ontology_requestable = ontology[\"requestable\"]\n",
    "    raw_gold_requested = raw_Y[\"requested\"]\n",
    "    gold_requested = np.zeros(len(ontology_requestable), dtype = float)\n",
    "    if len(raw_gold_requested) != 0:\n",
    "        for requested in raw_gold_requested:\n",
    "            gold_requested[ontology_requestable.index(requested)] = 1.0\n",
    "    return torch.tensor([gold_requested], dtype = torch.float, device = device)\n",
    "\n",
    "def retrieve_output_Requested(output_tensor, ontology):\n",
    "    ontology_requestable = ontology[\"requestable\"]\n",
    "    output_tensor = output_tensor.view(-1)\n",
    "    requested_dict = {}\n",
    "    for index in range(len(output_tensor)):\n",
    "        probability_value = output_tensor[index].item()\n",
    "        requested_dict[ontology_requestable[index]] = probability_value\n",
    "    return requested_dict\n",
    "\n",
    "# --------------------\n",
    "\n",
    "def retrieve_gold_Method(raw_Y, ontology, device):\n",
    "    ontology_method = ontology[\"method\"]\n",
    "    raw_gold_method = raw_Y[\"method\"]\n",
    "    gold_method = ontology_method.index(raw_gold_method)\n",
    "    return torch.tensor([gold_method], dtype = torch.long, device = device)\n",
    "\n",
    "def retrieve_output_Method(output_tensor, ontology):\n",
    "    ontology_method = ontology[\"method\"]\n",
    "    output_tensor = output_tensor.view(-1)\n",
    "    output_tensor = torch.exp(output_tensor)\n",
    "    method_dict = {}\n",
    "    for index in range(len(output_tensor)):\n",
    "        method_dict[ontology_method[index]] = output_tensor[index].item()\n",
    "    return method_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iDST Goal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class iDSTGoalModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocabulary_size, embedding_dim, altered_embedding_dim, hidden_dim,\n",
    "                 goal_pricerange_dim, goal_area_dim, goal_name_dim, goal_food_dim, device):\n",
    "        super(iDSTGoalModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.device = device\n",
    "        self.goal_pricerange_dim = goal_pricerange_dim\n",
    "        self.goal_area_dim = goal_area_dim\n",
    "        self.goal_name_dim = goal_name_dim\n",
    "        self.goal_food_dim = goal_food_dim\n",
    "        self.embeddings = nn.Embedding(num_embeddings = vocabulary_size, embedding_dim = embedding_dim)\n",
    "        self.altered_embeddings = nn.Linear(in_features = (embedding_dim + 1), out_features = altered_embedding_dim) # +1 for the ASR-score\n",
    "        self.lstm = nn.LSTM(input_size = altered_embedding_dim, hidden_size = hidden_dim)\n",
    "        self.goal_pricerange_classifier = nn.Linear(in_features = hidden_dim, out_features = goal_pricerange_dim)\n",
    "        self.goal_area_classifier = nn.Linear(in_features = hidden_dim, out_features = goal_area_dim)\n",
    "        self.goal_name_classifier = nn.Linear(in_features = hidden_dim, out_features = goal_name_dim)\n",
    "        self.goal_food_classifier = nn.Linear(in_features = hidden_dim, out_features = goal_food_dim)\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(1, 1, self.hidden_dim, device = self.device),\n",
    "                torch.zeros(1, 1, self.hidden_dim, device = self.device))\n",
    "\n",
    "    def forward(self, indices, scores):\n",
    "        embeddings = self.embeddings(indices)\n",
    "        embeddings_concat_score = torch.cat((embeddings, scores.unsqueeze(dim = 1)), dim = 1) \n",
    "        altered_embeddings = F.relu(self.altered_embeddings(embeddings_concat_score))\n",
    "        lstm_out, self.hidden = self.lstm(altered_embeddings.view(len(indices), 1, -1), self.hidden)\n",
    "        goal_pricerange_output = F.log_softmax(self.goal_pricerange_classifier(lstm_out).view(-1, self.goal_pricerange_dim), dim = 1)\n",
    "        goal_area_output = F.log_softmax(self.goal_area_classifier(lstm_out).view(-1, self.goal_area_dim), dim = 1)\n",
    "        goal_name_output = F.log_softmax(self.goal_name_classifier(lstm_out).view(-1, self.goal_name_dim), dim = 1)\n",
    "        goal_food_output = F.log_softmax(self.goal_food_classifier(lstm_out).view(-1, self.goal_food_dim), dim = 1)\n",
    "        return goal_pricerange_output, goal_area_output, goal_name_output, goal_food_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iDST Requested Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class iDSTRequestedModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocabulary_size, embedding_dim, altered_embedding_dim, hidden_dim, requested_dim, device):\n",
    "        super(iDSTRequestedModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.device = device\n",
    "        self.requested_dim = requested_dim\n",
    "        self.embeddings = nn.Embedding(num_embeddings = vocabulary_size, embedding_dim = embedding_dim)\n",
    "        self.altered_embeddings = nn.Linear(in_features = (embedding_dim + 1), out_features = altered_embedding_dim) # +1 for the ASR-score\n",
    "        self.lstm = nn.LSTM(input_size = altered_embedding_dim, hidden_size = hidden_dim)\n",
    "        self.requested_classifier = nn.Linear(in_features = hidden_dim, out_features = requested_dim)\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(1, 1, self.hidden_dim, device = self.device),\n",
    "                torch.zeros(1, 1, self.hidden_dim, device = self.device))\n",
    "\n",
    "    def forward(self, indices, scores):\n",
    "        embeddings = self.embeddings(indices)\n",
    "        embeddings_concat_score = torch.cat((embeddings, scores.unsqueeze(dim = 1)), dim = 1) \n",
    "        altered_embeddings = F.relu(self.altered_embeddings(embeddings_concat_score))\n",
    "        lstm_out, self.hidden = self.lstm(altered_embeddings.view(len(indices), 1, -1), self.hidden)\n",
    "        requested_output = torch.sigmoid(self.requested_classifier(lstm_out).view(-1, self.requested_dim))\n",
    "        return requested_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iDST Method Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class iDSTMethodModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocabulary_size, embedding_dim, altered_embedding_dim, hidden_dim, method_dim, device):\n",
    "        super(iDSTMethodModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.device = device\n",
    "        self.method_dim = method_dim\n",
    "        self.embeddings = nn.Embedding(num_embeddings = vocabulary_size, embedding_dim = embedding_dim)\n",
    "        self.altered_embeddings = nn.Linear(in_features = (embedding_dim + 1), out_features = altered_embedding_dim) # +1 for the ASR-score\n",
    "        self.lstm = nn.LSTM(input_size = altered_embedding_dim, hidden_size = hidden_dim)\n",
    "        self.method_classifier = nn.Linear(in_features = hidden_dim, out_features = method_dim)\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(1, 1, self.hidden_dim, device = self.device),\n",
    "                torch.zeros(1, 1, self.hidden_dim, device = self.device))\n",
    "\n",
    "    def forward(self, indices, scores):\n",
    "        embeddings = self.embeddings(indices)\n",
    "        embeddings_concat_score = torch.cat((embeddings, scores.unsqueeze(dim = 1)), dim = 1) \n",
    "        altered_embeddings = F.relu(self.altered_embeddings(embeddings_concat_score))\n",
    "        lstm_out, self.hidden = self.lstm(altered_embeddings.view(len(indices), 1, -1), self.hidden)\n",
    "        method_output = F.log_softmax(self.method_classifier(lstm_out).view(-1, self.method_dim), dim = 1)\n",
    "        return method_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iDST Goal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Goal = iDSTGoalModel(vocabulary_size = VOCABULARY_SIZE,\n",
    "                           embedding_dim = EMBEDDING_DIM,\n",
    "                           altered_embedding_dim = ALTERED_EMBEDDING_DIM,\n",
    "                           hidden_dim = HIDDEN_DIM,\n",
    "                           goal_pricerange_dim = GOAL_PRICERANGE_DIM,\n",
    "                           goal_area_dim = GOAL_AREA_DIM,\n",
    "                           goal_name_dim = GOAL_NAME_DIM,\n",
    "                           goal_food_dim = GOAL_FOOD_DIM,\n",
    "                           device = DEVICE).to(DEVICE)\n",
    "optimizer_Goal = optim.Adam(model_Goal.parameters(), lr = 1e-3, amsgrad = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iDST Requested Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Requested = iDSTRequestedModel(vocabulary_size = VOCABULARY_SIZE,\n",
    "                                     embedding_dim = EMBEDDING_DIM,\n",
    "                                     altered_embedding_dim = ALTERED_EMBEDDING_DIM,\n",
    "                                     hidden_dim = HIDDEN_DIM,\n",
    "                                     requested_dim = REQUESTED_DIM,\n",
    "                                     device = DEVICE).to(DEVICE)\n",
    "optimizer_Requested = optim.Adam(model_Requested.parameters(), lr = 1e-3, amsgrad = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iDST Method Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Method = iDSTMethodModel(vocabulary_size = VOCABULARY_SIZE,\n",
    "                               embedding_dim = EMBEDDING_DIM,\n",
    "                               altered_embedding_dim = ALTERED_EMBEDDING_DIM,\n",
    "                               hidden_dim = HIDDEN_DIM,\n",
    "                               method_dim = METHOD_DIM,\n",
    "                               device = DEVICE).to(DEVICE)\n",
    "optimizer_Method = optim.Adam(model_Method.parameters(), lr = 1e-3, amsgrad = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train iDST Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "goal_early_stopping = EarlyStopping(patience = PATIENCE)\n",
    "requested_early_stopping = EarlyStopping(patience = PATIENCE)\n",
    "method_early_stopping = EarlyStopping(patience = PATIENCE)\n",
    "\n",
    "train_indices_loader = torch.utils.data.DataLoader(np.arange(raw_X_train.shape[0]), batch_size = BATCH_SIZE, shuffle = True)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    logging.info(\"Epoch\\t{}/{}\".format(epoch + 1, NUM_EPOCHS))\n",
    "    \n",
    "    if not goal_early_stopping.stop_training:\n",
    "        model_Goal = model_Goal.train()\n",
    "    if not requested_early_stopping.stop_training:\n",
    "        model_Requested = model_Requested.train()\n",
    "    if not method_early_stopping.stop_training:\n",
    "        model_Method = model_Method.train()\n",
    "    \n",
    "    for train_indices in tqdm_notebook(train_indices_loader, total = len(train_indices_loader)):\n",
    "        \n",
    "        if not goal_early_stopping.stop_training:\n",
    "            optimizer_Goal.zero_grad()\n",
    "            goal_accumulated_loss = 0\n",
    "        if not requested_early_stopping.stop_training:\n",
    "            optimizer_Requested.zero_grad()\n",
    "            requested_accumulated_loss = 0\n",
    "        if not method_early_stopping.stop_training:\n",
    "            optimizer_Method.zero_grad()\n",
    "            method_accumulated_loss = 0\n",
    "        \n",
    "        for raw_X_train_dialog, raw_Y_train_dialog in zip(raw_X_train[train_indices], raw_Y_train[train_indices]):\n",
    "            \n",
    "            if not goal_early_stopping.stop_training:\n",
    "                model_Goal.hidden = model_Goal.init_hidden()\n",
    "            if not requested_early_stopping.stop_training:\n",
    "                model_Requested.hidden = model_Requested.init_hidden()\n",
    "            if not method_early_stopping.stop_training:\n",
    "                model_Method.hidden = model_Method.init_hidden()\n",
    "                \n",
    "            for raw_X_train_turn, raw_Y_train_turn in zip(raw_X_train_dialog[\"turns\"], raw_Y_train_dialog[\"turns\"]):\n",
    "\n",
    "                indices, scores = get_index_and_score(raw_X_train_turn, token_to_index, mode = \"train\", device = DEVICE)\n",
    "                \n",
    "                if not goal_early_stopping.stop_training:\n",
    "                    goal_pricerange_outputs, goal_area_outputs, goal_name_outputs, goal_food_outputs = model_Goal(indices, scores)\n",
    "                    gold_goal_pricerange = retrieve_gold_GoalPricerange(raw_Y_train_turn, ontology = ontology, device = DEVICE).repeat(len(goal_pricerange_outputs))\n",
    "                    goal_accumulated_loss += GOAL_LOSS_FUNCTION(goal_pricerange_outputs, gold_goal_pricerange)\n",
    "                    gold_goal_area = retrieve_gold_GoalArea(raw_Y_train_turn, ontology = ontology, device = DEVICE).repeat(len(goal_area_outputs))\n",
    "                    goal_accumulated_loss += GOAL_LOSS_FUNCTION(goal_area_outputs, gold_goal_area)\n",
    "                    gold_goal_name = retrieve_gold_GoalName(raw_Y_train_turn, ontology = ontology, device = DEVICE).repeat(len(goal_name_outputs))\n",
    "                    goal_accumulated_loss += GOAL_LOSS_FUNCTION(goal_name_outputs, gold_goal_name)\n",
    "                    gold_goal_food = retrieve_gold_GoalFood(raw_Y_train_turn, ontology = ontology, device = DEVICE).repeat(len(goal_food_outputs))\n",
    "                    goal_accumulated_loss += GOAL_LOSS_FUNCTION(goal_food_outputs, gold_goal_food)\n",
    "                if not requested_early_stopping.stop_training:\n",
    "                    requested_outputs = model_Requested(indices, scores)\n",
    "                    gold_requested = retrieve_gold_Requested(raw_Y_train_turn, ontology = ontology, device = DEVICE).repeat(requested_outputs.size(0), 1)\n",
    "                    requested_accumulated_loss += REQUESTED_LOSS_FUNCTION(requested_outputs, gold_requested)\n",
    "                if not method_early_stopping.stop_training:\n",
    "                    method_outputs = model_Method(indices, scores)\n",
    "                    gold_method = retrieve_gold_Method(raw_Y_train_turn, ontology = ontology, device = DEVICE).repeat(len(method_outputs))\n",
    "                    method_accumulated_loss += METHOD_LOSS_FUNCTION(method_outputs, gold_method)\n",
    "                    \n",
    "        if not goal_early_stopping.stop_training:\n",
    "            goal_accumulated_loss.backward()\n",
    "            optimizer_Goal.step()\n",
    "        if not requested_early_stopping.stop_training:\n",
    "            requested_accumulated_loss.backward()\n",
    "            optimizer_Requested.step()\n",
    "        if not method_early_stopping.stop_training:\n",
    "            method_accumulated_loss.backward()\n",
    "            optimizer_Method.step()\n",
    "        \n",
    "    dev_tracker, _ = make_tracker(model_Goal, model_Requested, model_Method, raw_X_dev, raw_Y_dev, dataset = \"dstc2_dev\", percentage = 1.0)\n",
    "    \n",
    "    dev_scores_dict = get_scores(dev_tracker, dataset = \"dstc2_dev\", ontology = ontology)\n",
    "    \n",
    "    logging.info(dev_scores_dict)\n",
    "    \n",
    "    current_goal_score_value = dev_scores_dict[\"goal_pricerange_accuracy\"] + dev_scores_dict[\"goal_area_accuracy\"] + dev_scores_dict[\"goal_name_accuracy\"] + dev_scores_dict[\"goal_food_accuracy\"] \n",
    "    goal_early_stopping.on_epoch_end(epoch = (epoch + 1), current_value = current_goal_score_value)\n",
    "    \n",
    "    current_requested_score_value = dev_scores_dict[\"requested_all_accuracy\"]\n",
    "    requested_early_stopping.on_epoch_end(epoch = (epoch + 1), current_value = current_requested_score_value)\n",
    "    \n",
    "    current_method_score_value = dev_scores_dict[\"method_accuracy\"]\n",
    "    method_early_stopping.on_epoch_end(epoch = (epoch + 1), current_value = current_method_score_value)\n",
    "    \n",
    "    if goal_early_stopping.wait == 0:\n",
    "        torch.save(model_Goal.state_dict(), \"model_Goal.pt\")\n",
    "    if requested_early_stopping.wait == 0:\n",
    "        torch.save(model_Requested.state_dict(), \"model_Requested.pt\")\n",
    "    if method_early_stopping.wait == 0:\n",
    "        torch.save(model_Method.state_dict(), \"model_Method.pt\")\n",
    "        \n",
    "    if goal_early_stopping.stop_training and requested_early_stopping.stop_training and method_early_stopping.stop_training:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load iDST Goal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Goal = iDSTGoalModel(vocabulary_size = VOCABULARY_SIZE,\n",
    "                           embedding_dim = EMBEDDING_DIM,\n",
    "                           altered_embedding_dim = ALTERED_EMBEDDING_DIM,\n",
    "                           hidden_dim = HIDDEN_DIM,\n",
    "                           goal_pricerange_dim = GOAL_PRICERANGE_DIM,\n",
    "                           goal_area_dim = GOAL_AREA_DIM,\n",
    "                           goal_name_dim = GOAL_NAME_DIM,\n",
    "                           goal_food_dim = GOAL_FOOD_DIM,\n",
    "                           device = DEVICE).to(DEVICE)\n",
    "model_Goal.load_state_dict(torch.load(\"model_Goal.pt\"))\n",
    "model_Goal.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load iDST Requested Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Requested = iDSTRequestedModel(vocabulary_size = VOCABULARY_SIZE,\n",
    "                                     embedding_dim = EMBEDDING_DIM,\n",
    "                                     altered_embedding_dim = ALTERED_EMBEDDING_DIM,\n",
    "                                     hidden_dim = HIDDEN_DIM,\n",
    "                                     requested_dim = REQUESTED_DIM,\n",
    "                                     device = DEVICE).to(DEVICE)\n",
    "model_Requested.load_state_dict(torch.load(\"model_Requested.pt\"))\n",
    "model_Requested.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Method = iDSTMethodModel(vocabulary_size = VOCABULARY_SIZE,\n",
    "                               embedding_dim = EMBEDDING_DIM,\n",
    "                               altered_embedding_dim = ALTERED_EMBEDDING_DIM,\n",
    "                               hidden_dim = HIDDEN_DIM,\n",
    "                               method_dim = METHOD_DIM,\n",
    "                               device = DEVICE).to(DEVICE)\n",
    "model_Method.load_state_dict(torch.load(\"model_Method.pt\"))\n",
    "model_Method.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dev_tracker, _ = make_tracker(model_Goal, model_Requested, model_Method, raw_X_dev, raw_Y_dev, dataset = \"dstc2_dev\", percentage = 1.0)\n",
    "get_scores(dev_tracker, dataset = \"dstc2_dev\", ontology = ontology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tracker, _ = make_tracker(model_Goal, model_Requested, model_Method, raw_X_test, raw_Y_test, dataset = \"dstc2_test\", percentage = 1.0)\n",
    "get_scores(test_tracker, dataset = \"dstc2_test\", ontology = ontology)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotly_plot_incremental(goal_pricerange_accuracies, goal_area_accuracies, goal_name_accuracies, goal_food_accuracies,\n",
    "                            requested_accuracies, method_accuracies, percentages, predictor_percentage_point, predictor_goal_pricerange_accuracy,\n",
    "                            predictor_goal_area_accuracy, predictor_goal_name_accuracy, predictor_goal_food_accuracy,\n",
    "                            predictor_requested_accuracy, predictor_method_accuracy, dataset):\n",
    "    \n",
    "    if dataset == \"dstc2_train\":\n",
    "        dataset = \"TRAIN\"\n",
    "    elif dataset == \"dstc2_dev\":\n",
    "        dataset = \"DEV\"\n",
    "    else:\n",
    "        dataset = \"TEST\"\n",
    "        \n",
    "    plotly.offline.iplot({\"data\": [Scatter(x = percentages, y = goal_pricerange_accuracies, mode = \"lines+markers\", name = \"{} Goal Pricerange Accuracy\".format(dataset), marker = dict(color = \"#1abc9c\")),\n",
    "                                   Scatter(x = percentages, y = goal_area_accuracies, mode = \"lines+markers\", name = \"{} Goal Area Accuracy\".format(dataset), marker = dict(color = \"#3498db\")),\n",
    "                                   Scatter(x = percentages, y = goal_name_accuracies, mode = \"lines+markers\", name = \"{} Goal Name Accuracy\".format(dataset), marker = dict(color = \"#9b59b6\")),\n",
    "                                   Scatter(x = percentages, y = goal_food_accuracies, mode = \"lines+markers\", name = \"{} Goal Food Accuracy\".format(dataset), marker = dict(color = \"#e74c3c\")),\n",
    "                                   Scatter(x = percentages, y = requested_accuracies, mode = \"lines+markers\", name = \"{} Requested Accuracy\".format(dataset), marker = dict(color = \"#34495e\")),\n",
    "                                   Scatter(x = percentages, y = method_accuracies, mode = \"lines+markers\", name = \"{} Method Accuracy\".format(dataset), marker = dict(color = \"#f1c40f\"))]\n",
    "                            \"layout\": Layout(title = \"<b>{} Percentage - Accuracy</b>\".format(dataset),\n",
    "                                             xaxis = dict(title = \"<b>Percentage</b>\",\n",
    "                                                          dtick = 0.1,\n",
    "                                                          titlefont = dict(color = \"#34495e\")),\n",
    "                                             yaxis = dict(title = \"<b>Accuracy</b>\",\n",
    "                                                          dtick = 0.05,\n",
    "                                                          titlefont = dict(color = \"#34495e\")),\n",
    "                                             margin = Margin(b = 150))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_goal_pricerange_accuracies = []\n",
    "dev_goal_area_accuracies = []\n",
    "dev_goal_name_accuracies = []\n",
    "dev_goal_food_accuracies = []\n",
    "dev_requested_accuracies = []\n",
    "dev_method_accuracies = []\n",
    "dev_percentages = []\n",
    "\n",
    "test_goal_pricerange_accuracies = []\n",
    "test_goal_area_accuracies = []\n",
    "test_goal_name_accuracies = []\n",
    "test_goal_food_accuracies = []\n",
    "test_requested_accuracies = []\n",
    "test_method_accuracies = []\n",
    "test_percentages = []\n",
    "\n",
    "percentages = list(frange(0.1, 1.05, 0.1))\n",
    "for percentage in tqdm_notebook(percentages, total = len(percentages)):\n",
    "    \n",
    "    dev_incremental_tracker, dev_incremental_percentage = make_tracker(model_Goal, model_Requested, model_Method, raw_X_dev, raw_Y_dev, dataset = \"dstc2_dev\", percentage = percentage)\n",
    "    dev_percentages.append(dev_incremental_percentage)\n",
    "    dev_scores_dict = get_scores(dev_incremental_tracker, dataset = \"dstc2_dev\", ontology = ontology)\n",
    "    dev_goal_pricerange_accuracies.append(dev_scores_dict[\"goal_pricerange_accuracy\"])\n",
    "    dev_goal_area_accuracies.append(dev_scores_dict[\"goal_area_accuracy\"])\n",
    "    dev_goal_name_accuracies.append(dev_scores_dict[\"goal_name_accuracy\"])\n",
    "    dev_goal_food_accuracies.append(dev_scores_dict[\"goal_food_accuracy\"])\n",
    "    dev_requested_accuracies.append(dev_scores_dict[\"requested_all_accuracy\"])\n",
    "    dev_method_accuracies.append(dev_scores_dict[\"method_accuracy\"])\n",
    "    \n",
    "    test_incremental_tracker, test_incremental_percentage = make_tracker(model_Goal, model_Requested, model_Method, raw_X_test, raw_Y_test, dataset = \"dstc2_test\", percentage = percentage)\n",
    "    test_percentages.append(test_incremental_percentage)\n",
    "    test_scores_dict = get_scores(test_incremental_tracker, dataset = \"dstc2_test\", ontology = ontology)\n",
    "    test_goal_pricerange_accuracies.append(test_scores_dict[\"goal_pricerange_accuracy\"])\n",
    "    test_goal_area_accuracies.append(test_scores_dict[\"goal_area_accuracy\"])\n",
    "    test_goal_name_accuracies.append(test_scores_dict[\"goal_name_accuracy\"])\n",
    "    test_goal_food_accuracies.append(test_scores_dict[\"goal_food_accuracy\"])\n",
    "    test_requested_accuracies.append(test_scores_dict[\"requested_all_accuracy\"])\n",
    "    test_method_accuracies.append(test_scores_dict[\"method_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_plot_incremental(dev_goal_pricerange_accuracies, dev_goal_area_accuracies, dev_goal_name_accuracies, dev_goal_food_accuracies,\n",
    "                        dev_requested_accuracies, dev_method_accuracies, dev_percentages, \"dstc2_dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_plot_incremental(test_goal_pricerange_accuracies, test_goal_area_accuracies, test_goal_name_accuracies, test_goal_food_accuracies,\n",
    "                        test_requested_accuracies, test_method_accuracies, test_percentages, \"dstc2_test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
