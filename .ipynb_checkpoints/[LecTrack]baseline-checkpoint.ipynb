{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check GPU availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Dec 27 20:58:36 2018       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 384.145                Driver Version: 384.145                   |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:02:00.0 Off |                  N/A |\r\n",
      "| 23%   29C    P8    17W / 250W |      0MiB / 11172MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:03:00.0 Off |                  N/A |\r\n",
      "| 23%   36C    P8    17W / 250W |      0MiB / 11172MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/is/andrei-\n",
      "[nltk_data]     cc/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import plotly\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "from tqdm import tqdm\n",
    "from idst_util import trivial\n",
    "from idst_util import dstc2\n",
    "\n",
    "from plotly.graph_objs import Scatter, Layout\n",
    "from plotly.graph_objs.layout import Margin\n",
    "plotly.offline.init_notebook_mode(connected = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check DSTC2 availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:+--------------------------------+\n",
      "INFO:root:|         _ ____  ___________    |\n",
      "INFO:root:|        (_) __ \\/ ___/_  __/    |\n",
      "INFO:root:|       / / / / /\\__ \\ / /       |\n",
      "INFO:root:|      / / /_/ /___/ // /        |\n",
      "INFO:root:|     /_/_____//____//_/         |\n",
      "INFO:root:|                                |\n",
      "INFO:root:+--------------------------------+\n",
      "INFO:root:|Incremental Dialog State Tracker|\n",
      "INFO:root:+--------------------------------+\n",
      "INFO:root:+--------------------------------+\n",
      "INFO:root:|     Dialog State Tracker 2     |\n",
      "INFO:root:|         Data Checker           |\n",
      "INFO:root:+--------------------------------+\n",
      "INFO:root:Looking for dstc2 directory in .\n",
      "INFO:root:dstc2 was found!\n",
      "INFO:root:Looking for dstc2_traindev directory in ./dstc2\n",
      "INFO:root:dstc2_traindev was found!\n",
      "INFO:root:Looking for dstc2_test directory in ./dstc2\n",
      "INFO:root:dstc2_test was found!\n",
      "INFO:root:Looking for dstc2_scripts directory in ./dstc2\n",
      "INFO:root:dstc2_scripts was found!\n",
      "INFO:root:Done!\n"
     ]
    }
   ],
   "source": [
    "trivial.print_idst()\n",
    "dstc2.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:+--------------------------------+\n",
      "INFO:root:|     Dialog State Tracker 2     |\n",
      "INFO:root:|       Dataset Retrieval        |\n",
      "INFO:root:+--------------------------------+\n",
      "INFO:root:Reading dstc2_train.flist, dstc2_dev.flist and ontology_dstc2.json\n",
      "INFO:root:Asserted 1612 dialogs for dstc2_train.flist\n",
      "INFO:root:Asserted 506 dialogs for dstc2_dev.flist\n",
      "INFO:root:Extracting raw train features\n",
      "100%|██████████| 1612/1612 [00:11<00:00, 141.28it/s]\n",
      "INFO:root:Extracting raw dev features\n",
      "100%|██████████| 506/506 [00:03<00:00, 166.05it/s]\n",
      "INFO:root:Reading dstc2_test.flist\n",
      "INFO:root:Asserted 1117 dialogs for dstc2_test.flist\n",
      "INFO:root:Extracting raw test features\n",
      "100%|██████████| 1117/1117 [00:07<00:00, 148.36it/s]\n"
     ]
    }
   ],
   "source": [
    "raw_X_train, raw_Y_train, \\\n",
    "raw_X_dev, raw_Y_dev, \\\n",
    "raw_X_test, raw_Y_test, \\\n",
    "ontology = dstc2.retrieve_raw_datasets(train_data_augmentation = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:+--------------------------------+\n",
      "INFO:root:|            Baseline            |\n",
      "INFO:root:+--------------------------------+\n",
      "INFO:root:Running on GPU 1\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"+--------------------------------+\")\n",
    "logging.info(\"|            Baseline            |\")\n",
    "logging.info(\"+--------------------------------+\")\n",
    "\n",
    "GPU_ID = 1\n",
    "DEVICE = torch.device(\"cuda:{}\".format(GPU_ID) if torch.cuda.is_available() else \"cpu\")\n",
    "#DEVICE = \"cpu\"\n",
    "if DEVICE == \"cpu\":\n",
    "    logging.warning(\"Running on CPU\")\n",
    "else:\n",
    "    logging.info(\"Running on GPU {}\".format(GPU_ID))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create vocabularies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:+--------------------------------+\n",
      "INFO:root:|          Vocabulary            |\n",
      "INFO:root:+--------------------------------+\n",
      "INFO:root:Creating token_to_index, index_to_token and token_to_count dictionaries\n",
      "100%|██████████| 3224/3224 [00:00<00:00, 25220.10it/s]\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"+--------------------------------+\")\n",
    "logging.info(\"|          Vocabulary            |\")\n",
    "logging.info(\"+--------------------------------+\")\n",
    "logging.info(\"Creating token_to_index, index_to_token and token_to_count dictionaries\")\n",
    "\n",
    "token_to_index = {\"<unk>\": 0}\n",
    "index_to_token = {0: \"<unk>\"}\n",
    "token_to_count = {\"<unk>\": 1}\n",
    "\n",
    "for raw_train_dialog in tqdm(raw_X_train):\n",
    "    \n",
    "    for raw_train_turn in raw_train_dialog[\"turns\"]:\n",
    "        \n",
    "        tokens_scores = raw_train_turn[\"system\"] + raw_train_turn[\"user\"]\n",
    "        \n",
    "        for token_score in tokens_scores:\n",
    "            token = token_score[0]\n",
    "            if token not in token_to_index:\n",
    "                token_to_index[token] = len(token_to_index)\n",
    "                index_to_token[len(token_to_index)] = token\n",
    "                token_to_count[token] = 1\n",
    "            else:\n",
    "                token_to_count[token] += 1\n",
    "                \n",
    "assert len(token_to_index) == len(index_to_token)\n",
    "assert len(token_to_index) == len(token_to_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:+--------------------------------+\n",
      "INFO:root:|         Configuration          |\n",
      "INFO:root:+--------------------------------+\n",
      "INFO:root:VOCABULARY_SIZE:\t\t1149\n",
      "\n",
      "INFO:root:GOAL_FOOD_DIM:\t\t93\n",
      "INFO:root:GOAL_PRICERANGE_DIM:\t\t5\n",
      "INFO:root:GOAL_NAME_DIM:\t\t115\n",
      "INFO:root:GOAL_AREA_DIM:\t\t7\n",
      "INFO:root:GOAL_EMBEDDING_DIM:\t\t170\n",
      "INFO:root:GOAL_ALTERED_EMBEDDING_DIM:\t300\n",
      "INFO:root:GOAL_HIDDEN_DIM:\t\t100\n",
      "INFO:root:GOAL_NUM_EPOCHS:\t\t10\n",
      "INFO:root:GOAL_LOSS_FUNCTION:\t\tCrossEntropyLoss()\n",
      "\n",
      "INFO:root:METHOD_DIM:\t\t\t5\n",
      "INFO:root:METHOD_EMBEDDING_DIM:\t\t85\n",
      "INFO:root:METHOD_ALTERED_EMBEDDING_DIM:\t90\n",
      "INFO:root:METHOD_HIDDEN_DIM:\t\t50\n",
      "INFO:root:METHOD_NUM_EPOCHS:\t\t10\n",
      "INFO:root:METHOD_LOSS_FUNCTION:\t\tCrossEntropyLoss()\n",
      "\n",
      "INFO:root:REQUESTED_DIM:\t\t\t8\n",
      "INFO:root:REQUESTED_EMBEDDING_DIM:\t\t170\n",
      "INFO:root:REQUESTED_ALTERED_EMBEDDING_DIM:\t300\n",
      "INFO:root:REQUESTED_HIDDEN_DIM:\t\t\t100\n",
      "INFO:root:REQUESTED_NUM_EPOCHS:\t\t\t10\n",
      "INFO:root:REQUESTED_LOSS_FUNCTION:\t\tBCELoss()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"+--------------------------------+\")\n",
    "logging.info(\"|         Configuration          |\")\n",
    "logging.info(\"+--------------------------------+\")\n",
    "\n",
    "VOCABULARY_SIZE = len(token_to_index)\n",
    "logging.info(\"VOCABULARY_SIZE:\\t\\t{}\\n\".format(VOCABULARY_SIZE))\n",
    "\n",
    "# NOTE: +2 because of null and dontcare\n",
    "GOAL_FOOD_DIM = len(ontology[\"informable\"][\"food\"]) + 2 \n",
    "GOAL_PRICERANGE_DIM = len(ontology[\"informable\"][\"pricerange\"]) + 2\n",
    "GOAL_NAME_DIM = len(ontology[\"informable\"][\"name\"]) + 2\n",
    "GOAL_AREA_DIM = len(ontology[\"informable\"][\"area\"]) + 2\n",
    "GOAL_EMBEDDING_DIM = 170\n",
    "GOAL_ALTERED_EMBEDDING_DIM = 300\n",
    "GOAL_HIDDEN_DIM = 100\n",
    "GOAL_NUM_EPOCHS = 10\n",
    "GOAL_LOSS_FUNCTION = nn.CrossEntropyLoss()\n",
    "logging.info(\"GOAL_FOOD_DIM:\\t\\t{}\".format(GOAL_FOOD_DIM))\n",
    "logging.info(\"GOAL_PRICERANGE_DIM:\\t\\t{}\".format(GOAL_PRICERANGE_DIM))\n",
    "logging.info(\"GOAL_NAME_DIM:\\t\\t{}\".format(GOAL_NAME_DIM))\n",
    "logging.info(\"GOAL_AREA_DIM:\\t\\t{}\".format(GOAL_AREA_DIM))\n",
    "logging.info(\"GOAL_EMBEDDING_DIM:\\t\\t{}\".format(GOAL_EMBEDDING_DIM))\n",
    "logging.info(\"GOAL_ALTERED_EMBEDDING_DIM:\\t{}\".format(GOAL_ALTERED_EMBEDDING_DIM))\n",
    "logging.info(\"GOAL_HIDDEN_DIM:\\t\\t{}\".format(GOAL_HIDDEN_DIM))\n",
    "logging.info(\"GOAL_NUM_EPOCHS:\\t\\t{}\".format(GOAL_NUM_EPOCHS))\n",
    "logging.info(\"GOAL_LOSS_FUNCTION:\\t\\t{}\\n\".format(GOAL_LOSS_FUNCTION))\n",
    "\n",
    "METHOD_DIM = len(ontology[\"method\"])\n",
    "METHOD_EMBEDDING_DIM = 85\n",
    "METHOD_ALTERED_EMBEDDING_DIM = 90\n",
    "METHOD_HIDDEN_DIM = 50\n",
    "METHOD_NUM_EPOCHS = 10\n",
    "METHOD_LOSS_FUNCTION = nn.CrossEntropyLoss()\n",
    "logging.info(\"METHOD_DIM:\\t\\t\\t{}\".format(METHOD_DIM))\n",
    "logging.info(\"METHOD_EMBEDDING_DIM:\\t\\t{}\".format(METHOD_EMBEDDING_DIM))\n",
    "logging.info(\"METHOD_ALTERED_EMBEDDING_DIM:\\t{}\".format(METHOD_ALTERED_EMBEDDING_DIM))\n",
    "logging.info(\"METHOD_HIDDEN_DIM:\\t\\t{}\".format(METHOD_HIDDEN_DIM))\n",
    "logging.info(\"METHOD_NUM_EPOCHS:\\t\\t{}\".format(METHOD_NUM_EPOCHS))\n",
    "logging.info(\"METHOD_LOSS_FUNCTION:\\t\\t{}\\n\".format(METHOD_LOSS_FUNCTION))\n",
    "\n",
    "#REQUESTED_DIM = int(math.pow(2, len(ontology[\"requestable\"])))\n",
    "REQUESTED_DIM = len(ontology[\"requestable\"])\n",
    "REQUESTED_EMBEDDING_DIM = 170\n",
    "REQUESTED_ALTERED_EMBEDDING_DIM = 300\n",
    "REQUESTED_HIDDEN_DIM = 100\n",
    "REQUESTED_NUM_EPOCHS = 10\n",
    "#REQUESTED_LOSS_FUNCTION = nn.CrossEntropyLoss()\n",
    "REQUESTED_LOSS_FUNCTION = nn.BCELoss()\n",
    "logging.info(\"REQUESTED_DIM:\\t\\t\\t{}\".format(REQUESTED_DIM))\n",
    "logging.info(\"REQUESTED_EMBEDDING_DIM:\\t\\t{}\".format(REQUESTED_EMBEDDING_DIM))\n",
    "logging.info(\"REQUESTED_ALTERED_EMBEDDING_DIM:\\t{}\".format(REQUESTED_ALTERED_EMBEDDING_DIM))\n",
    "logging.info(\"REQUESTED_HIDDEN_DIM:\\t\\t\\t{}\".format(REQUESTED_HIDDEN_DIM))\n",
    "logging.info(\"REQUESTED_NUM_EPOCHS:\\t\\t\\t{}\".format(REQUESTED_NUM_EPOCHS))\n",
    "logging.info(\"REQUESTED_LOSS_FUNCTION:\\t\\t{}\\n\".format(REQUESTED_LOSS_FUNCTION))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_and_score(turn, token_to_index, device):\n",
    "    indices = []\n",
    "    scores = []\n",
    "    tokens_scores = turn[\"system\"] + turn[\"user\"]\n",
    "    for token, score in tokens_scores:\n",
    "        if token not in token_to_index:\n",
    "            indices.append(token_to_index[\"<unk>\"])\n",
    "        else:\n",
    "            indices.append(token_to_index[token])\n",
    "        scores.append(score)\n",
    "    assert len(indices) == len(scores)\n",
    "    return torch.tensor(indices, dtype = torch.long, device = device), torch.tensor(scores, dtype = torch.float, device = device)\n",
    "\n",
    "def plotly_plot(train_losses, dev_losses):\n",
    "    plotly.offline.iplot({\n",
    "                            \"data\": [Scatter(\n",
    "                                            x = list(range(len(train_losses))),\n",
    "                                            y = train_losses,\n",
    "                                            mode = \"lines+markers\",\n",
    "                                            name = \"Train Loss\",\n",
    "                                            marker = dict(color = \"#1abc9c\")),\n",
    "                                    Scatter(\n",
    "                                            x = list(range(len(dev_losses))),\n",
    "                                            y = dev_losses,\n",
    "                                            mode = \"lines+markers\",\n",
    "                                            name = \"Dev Loss\",\n",
    "                                            marker = dict(color = \"#3498db\"))],\n",
    "                            \"layout\": Layout(\n",
    "                                             title = \"<b>Train-Dev Loss</b>\",\n",
    "                                             xaxis = dict(title = \"<b>Epoch</b>\",\n",
    "                                                          dtick = 1,\n",
    "                                                          titlefont = dict(color = \"#34495e\")),\n",
    "                                             yaxis = dict(title = \"<b>Loss</b>\",\n",
    "                                                          titlefont = dict(color = \"#34495e\")),\n",
    "                                             margin = Margin(b = 150))\n",
    "                        })\n",
    "\n",
    "class EarlyStopping():\n",
    "    \n",
    "    def __init__(self, min_delta = 0, patience = 1):\n",
    "        \n",
    "        self.min_delta = min_delta\n",
    "        self.patience = patience\n",
    "        self.wait = 0\n",
    "        self.stopped_epoch = 0\n",
    "        self.best = np.Inf\n",
    "        self.stop_training = False\n",
    "    \n",
    "    def on_epoch_end(self, epoch, current_loss):\n",
    "        if np.less((current_loss - self.min_delta), self.best):\n",
    "            self.best = current_loss\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait > self.patience:\n",
    "                self.stopped_epoch = epoch\n",
    "                self.stop_training = True\n",
    "        return self.stop_training\n",
    "\n",
    "get_bin = lambda x, n: format(x, \"b\").zfill(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoalModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 vocabulary_size,\n",
    "                 embedding_dim,\n",
    "                 altered_embedding_dim,\n",
    "                 hidden_dim,\n",
    "                 goal_food_dim,\n",
    "                 goal_pricerange_dim,\n",
    "                 goal_name_dim,\n",
    "                 goal_area_dim,\n",
    "                 device):\n",
    "        \n",
    "        super(GoalModel, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.goal_food_dim = goal_food_dim\n",
    "        self.goal_pricerange_dim = goal_pricerange_dim\n",
    "        self.goal_name_dim = goal_name_dim\n",
    "        self.goal_area_dim = goal_area_dim\n",
    "        self.device = device\n",
    "        \n",
    "        self.embeddings = nn.Embedding(num_embeddings = vocabulary_size,\n",
    "                                       embedding_dim = embedding_dim)\n",
    "        \n",
    "        self.altered_embeddings = nn.Linear(in_features = (embedding_dim + 1),\n",
    "                                            out_features = altered_embedding_dim)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size = altered_embedding_dim,\n",
    "                            hidden_size = hidden_dim)\n",
    "        \n",
    "        self.goal_food_classifier = nn.Linear(in_features = hidden_dim,\n",
    "                                              out_features = goal_food_dim)\n",
    "        \n",
    "        self.goal_pricerange_classifier = nn.Linear(in_features = hidden_dim,\n",
    "                                                    out_features = goal_pricerange_dim)\n",
    "        \n",
    "        self.goal_name_classifier = nn.Linear(in_features = hidden_dim,\n",
    "                                              out_features = goal_name_dim)\n",
    "        \n",
    "        self.goal_area_classifier = nn.Linear(in_features = hidden_dim,\n",
    "                                              out_features = goal_area_dim)\n",
    "        \n",
    "        self.hidden = self.init_hidden()\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        \n",
    "        return (torch.zeros(1, 1, self.hidden_dim, device = self.device),\n",
    "                torch.zeros(1, 1, self.hidden_dim, device = self.device))\n",
    "        \n",
    "    def forward(self, indices, scores):\n",
    "    \n",
    "        embeddings = self.embeddings(indices)\n",
    "        \n",
    "        embeddings_concat_score = torch.cat((embeddings, scores.unsqueeze(dim = 1)), dim = 1) \n",
    "        \n",
    "        altered_embeddings = F.relu(self.altered_embeddings(embeddings_concat_score))\n",
    "        \n",
    "        lstm_out, self.hidden = self.lstm(altered_embeddings.view(len(indices), 1, -1), self.hidden)\n",
    "        \n",
    "        goal_food = F.log_softmax(self.goal_food_classifier(self.hidden[0]).view(-1, self.goal_food_dim), dim = 1)        \n",
    "        \n",
    "        goal_pricerange = F.log_softmax(self.goal_pricerange_classifier(self.hidden[0]).view(-1, self.goal_pricerange_dim), dim = 1) \n",
    "        \n",
    "        goal_name = F.log_softmax(self.goal_name_classifier(self.hidden[0]).view(-1, self.goal_name_dim), dim = 1)\n",
    "        \n",
    "        goal_area = F.log_softmax(self.goal_area_classifier(self.hidden[0]).view(-1, self.goal_area_dim), dim = 1)\n",
    "        \n",
    "        return goal_food, goal_pricerange, goal_name, goal_area\n",
    "\n",
    "def retrieve_gold_GoalFood(raw_Y, ontology, device):\n",
    "    ontology_informable_food = ontology[\"informable\"][\"food\"]\n",
    "    raw_goal_food = raw_Y[\"goal\"][\"food\"]\n",
    "    goal_food = 0\n",
    "    if raw_goal_food != None:\n",
    "        if raw_goal_food == \"dontcare\":\n",
    "            goal_food = 1\n",
    "        else:    \n",
    "            goal_food = ontology_informable_food.index(raw_goal_food) + 2\n",
    "    return torch.tensor([goal_food], dtype = torch.long, device = device)\n",
    "\n",
    "def retrieve_output_GoalFood(output_tensor):\n",
    "    output_tensor = output_tensor.view(-1)\n",
    "    output_tensor = torch.exp(output_tensor)\n",
    "    goal_food_dict = {}\n",
    "    \n",
    "    index = torch.argmax(output_tensor).item()\n",
    "    if index != 0:\n",
    "        if index == 1:\n",
    "            goal_food_dict[\"dontcare\"] = output_tensor[index].item() \n",
    "        else:\n",
    "            goal_food_dict[ontology[\"informable\"][\"food\"][index - 2]] = output_tensor[index].item()\n",
    "        \n",
    "    return goal_food_dict\n",
    "\n",
    "def retrieve_gold_GoalPriceRange(raw_Y, ontology, device):\n",
    "    ontology_informable_pricerange = ontology[\"informable\"][\"pricerange\"]\n",
    "    raw_goal_pricerange = raw_Y[\"goal\"][\"pricerange\"]\n",
    "    goal_pricerange = 0\n",
    "    if raw_goal_pricerange != None:\n",
    "        if raw_goal_pricerange == \"dontcare\":\n",
    "            goal_pricerange = 1\n",
    "        else:    \n",
    "            goal_pricerange = ontology_informable_pricerange.index(raw_goal_pricerange) + 2\n",
    "    return torch.tensor([goal_pricerange], dtype = torch.long, device = device)\n",
    "\n",
    "def retrieve_output_GoalPricerange(output_tensor):\n",
    "    output_tensor = output_tensor.view(-1)\n",
    "    output_tensor = torch.exp(output_tensor)\n",
    "    goal_pricerange_dict = {}\n",
    "    \n",
    "    index = torch.argmax(output_tensor).item()\n",
    "    if index != 0:\n",
    "        if index == 1:\n",
    "            goal_pricerange_dict[\"dontcare\"] = output_tensor[index].item()\n",
    "        else:     \n",
    "            goal_pricerange_dict[ontology[\"informable\"][\"pricerange\"][index - 2]] = output_tensor[index].item()\n",
    "        \n",
    "    return goal_pricerange_dict\n",
    "\n",
    "def retrieve_gold_GoalName(raw_Y, ontology, device):\n",
    "    ontology_informable_name = ontology[\"informable\"][\"name\"]\n",
    "    raw_goal_name = raw_Y[\"goal\"][\"name\"]\n",
    "    goal_name = 0\n",
    "    if raw_goal_name != None:\n",
    "        if raw_goal_name == \"dontcare\":\n",
    "            goal_name = 1\n",
    "        else:    \n",
    "            goal_name = ontology_informable_name.index(raw_goal_name) + 2\n",
    "    return torch.tensor([goal_name], dtype = torch.long, device = device)\n",
    "\n",
    "def retrieve_output_GoalName(output_tensor):\n",
    "    output_tensor = output_tensor.view(-1)\n",
    "    output_tensor = torch.exp(output_tensor)\n",
    "    goal_name_dict = {}\n",
    "    \n",
    "    index = torch.argmax(output_tensor).item()\n",
    "    if index != 0:\n",
    "        if index == 1:\n",
    "            goal_name_dict[\"dontcare\"] = output_tensor[index].item()\n",
    "        else:    \n",
    "            goal_name_dict[ontology[\"informable\"][\"name\"][index - 2]] = output_tensor[index].item()\n",
    "        \n",
    "    return goal_name_dict\n",
    "\n",
    "def retrieve_gold_GoalArea(raw_Y, ontology, device):\n",
    "    ontology_informable_area = ontology[\"informable\"][\"area\"]\n",
    "    raw_goal_area = raw_Y[\"goal\"][\"area\"]\n",
    "    goal_area = 0\n",
    "    if raw_goal_area != None:\n",
    "        if raw_goal_area == \"dontcare\":\n",
    "            goal_area = 1\n",
    "        else:    \n",
    "            goal_area = ontology_informable_area.index(raw_goal_area) + 2\n",
    "    return torch.tensor([goal_area], dtype = torch.long, device = device)\n",
    "\n",
    "def retrieve_output_GoalArea(output_tensor):\n",
    "    output_tensor = output_tensor.view(-1)\n",
    "    output_tensor = torch.exp(output_tensor)\n",
    "    goal_area_dict = {}\n",
    "    \n",
    "    index = torch.argmax(output_tensor).item()\n",
    "    if index != 0:\n",
    "        if index == 1:\n",
    "            goal_area_dict[\"dontcare\"] = output_tensor[index].item()\n",
    "        else:\n",
    "            goal_area_dict[ontology[\"informable\"][\"area\"][index - 2]] = output_tensor[index].item()\n",
    "        \n",
    "    return goal_area_dict\n",
    "\n",
    "model_Goal = GoalModel(vocabulary_size = VOCABULARY_SIZE,\n",
    "                       embedding_dim = GOAL_EMBEDDING_DIM,\n",
    "                       altered_embedding_dim = GOAL_ALTERED_EMBEDDING_DIM,\n",
    "                       hidden_dim = GOAL_HIDDEN_DIM,\n",
    "                       goal_food_dim = GOAL_FOOD_DIM,\n",
    "                       goal_pricerange_dim = GOAL_PRICERANGE_DIM,\n",
    "                       goal_name_dim = GOAL_NAME_DIM,\n",
    "                       goal_area_dim = GOAL_AREA_DIM,\n",
    "                       device = DEVICE)\n",
    "\n",
    "model_Goal = model_Goal.to(DEVICE)\n",
    "\n",
    "optimizer_GoalModel = optim.Adam(model_Goal.parameters(), lr = 1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "dev_losses = []\n",
    "goal_early_stopping = EarlyStopping(patience = 1)\n",
    "\n",
    "for epoch in range(GOAL_NUM_EPOCHS):\n",
    "    \n",
    "    logging.info(\"Epoch\\t{}/{}\".format(epoch + 1, GOAL_NUM_EPOCHS))\n",
    "    \n",
    "    train_loss = 0\n",
    "    \n",
    "    model_Goal = model_Goal.train()\n",
    "    \n",
    "    for raw_X_train_dialog, raw_Y_train_dialog in tqdm(zip(raw_X_train, raw_Y_train), total = len(raw_X_train)):\n",
    "\n",
    "        model_Goal.hidden = model_Goal.init_hidden()\n",
    "\n",
    "        for raw_X_train_turn, raw_Y_train_turn in zip(raw_X_train_dialog[\"turns\"], raw_Y_train_dialog[\"turns\"]):\n",
    "            \n",
    "            optimizer_GoalModel.zero_grad()\n",
    "            \n",
    "            indices, scores = get_index_and_score(raw_X_train_turn, token_to_index, device = DEVICE)\n",
    "            \n",
    "            goal_food, goal_pricerange, goal_name, goal_area = model_Goal(indices, scores)\n",
    "            \n",
    "            loss_goal_food = GOAL_LOSS_FUNCTION(goal_food,\n",
    "                                                retrieve_gold_GoalFood(raw_Y_train_turn,\n",
    "                                                                       ontology = ontology,\n",
    "                                                                       device = DEVICE))\n",
    "            \n",
    "            loss_goal_pricerange = GOAL_LOSS_FUNCTION(goal_pricerange,\n",
    "                                                      retrieve_gold_GoalPriceRange(raw_Y_train_turn,\n",
    "                                                                                   ontology = ontology,\n",
    "                                                                                   device = DEVICE))\n",
    "            \n",
    "            loss_goal_name = GOAL_LOSS_FUNCTION(goal_name,\n",
    "                                                retrieve_gold_GoalName(raw_Y_train_turn,\n",
    "                                                                       ontology = ontology,\n",
    "                                                                       device = DEVICE))\n",
    "            \n",
    "            loss_goal_area = GOAL_LOSS_FUNCTION(goal_area,\n",
    "                                                retrieve_gold_GoalArea(raw_Y_train_turn,\n",
    "                                                                       ontology = ontology,\n",
    "                                                                       device = DEVICE))\n",
    "\n",
    "            loss = loss_goal_food + loss_goal_pricerange + loss_goal_name + loss_goal_area\n",
    "            loss.backward(retain_graph = True)\n",
    "            \n",
    "            train_loss += loss\n",
    "\n",
    "            optimizer_GoalModel.step()\n",
    "    \n",
    "    train_losses.append(train_loss.item())\n",
    "    \n",
    "    model_Goal = model_Goal.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        dev_loss = 0\n",
    "        \n",
    "        for raw_X_dev_dialog, raw_Y_dev_dialog in tqdm(zip(raw_X_dev, raw_Y_dev), total = len(raw_X_dev)):\n",
    "            \n",
    "            model_Goal.hidden = model_Goal.init_hidden()\n",
    "            \n",
    "            for raw_X_dev_turn, raw_Y_dev_turn in zip(raw_X_dev_dialog[\"turns\"], raw_Y_dev_dialog[\"turns\"]):\n",
    "                \n",
    "                indices, scores = get_index_and_score(raw_X_dev_turn, token_to_index, device = DEVICE)\n",
    "                \n",
    "                goal_food, goal_pricerange, goal_name, goal_area = model_Goal(indices, scores)\n",
    "            \n",
    "                loss_goal_food = GOAL_LOSS_FUNCTION(goal_food,\n",
    "                                                    retrieve_gold_GoalFood(raw_Y_dev_turn,\n",
    "                                                                           ontology = ontology,\n",
    "                                                                           device = DEVICE))\n",
    "            \n",
    "                loss_goal_pricerange = GOAL_LOSS_FUNCTION(goal_pricerange,\n",
    "                                                          retrieve_gold_GoalPriceRange(raw_Y_dev_turn,\n",
    "                                                                                       ontology = ontology,\n",
    "                                                                                       device = DEVICE))\n",
    "            \n",
    "                loss_goal_name = GOAL_LOSS_FUNCTION(goal_name,\n",
    "                                                    retrieve_gold_GoalName(raw_Y_dev_turn,\n",
    "                                                                           ontology = ontology,\n",
    "                                                                           device = DEVICE))\n",
    "            \n",
    "                loss_goal_area = GOAL_LOSS_FUNCTION(goal_area,\n",
    "                                                    retrieve_gold_GoalArea(raw_Y_dev_turn,\n",
    "                                                                           ontology = ontology,\n",
    "                                                                           device = DEVICE))\n",
    "\n",
    "                loss = loss_goal_food + loss_goal_pricerange + loss_goal_name + loss_goal_area\n",
    "                \n",
    "                dev_loss += loss\n",
    "                \n",
    "        dev_losses.append(dev_loss.item())\n",
    "    \n",
    "    logging.info(\"Epoch train loss\\t{} \\tdev loss\\t{}\".format(train_loss, dev_loss))\n",
    "    \n",
    "    goal_early_stopping.on_epoch_end(epoch = (epoch + 1), current_loss = dev_loss.item())\n",
    "    if goal_early_stopping.stop_training:\n",
    "        break\n",
    "\n",
    "plotly_plot(train_losses, dev_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MethodModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 vocabulary_size,\n",
    "                 embedding_dim,\n",
    "                 altered_embedding_dim,\n",
    "                 hidden_dim,\n",
    "                 method_dim,\n",
    "                 device):\n",
    "        \n",
    "        super(MethodModel, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.method_dim = method_dim\n",
    "        self.device = device\n",
    "        \n",
    "        self.embeddings = nn.Embedding(num_embeddings = vocabulary_size,\n",
    "                                       embedding_dim = embedding_dim)\n",
    "        \n",
    "        self.altered_embeddings = nn.Linear(in_features = (embedding_dim + 1),\n",
    "                                            out_features = altered_embedding_dim)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size = altered_embedding_dim,\n",
    "                            hidden_size = hidden_dim)\n",
    "        \n",
    "        \n",
    "        self.method_classifier = nn.Linear(in_features = hidden_dim,\n",
    "                                           out_features = method_dim)\n",
    "        \n",
    "        self.hidden = self.init_hidden()\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        \n",
    "        return (torch.zeros(1, 1, self.hidden_dim, device = self.device),\n",
    "                torch.zeros(1, 1, self.hidden_dim, device = self.device))\n",
    "        \n",
    "    def forward(self, indices, scores):\n",
    "        \n",
    "        embeddings = self.embeddings(indices)\n",
    "        \n",
    "        embeddings_concat_score = torch.cat((embeddings, scores.unsqueeze(dim = 1)), dim = 1) \n",
    "        \n",
    "        altered_embeddings = F.relu(self.altered_embeddings(embeddings_concat_score))\n",
    "        \n",
    "        lstm_out, self.hidden = self.lstm(altered_embeddings.view(len(indices), 1, -1), self.hidden)\n",
    "        \n",
    "        method = F.log_softmax(self.method_classifier(self.hidden[0]).view(-1, self.method_dim), dim = 1)\n",
    "        \n",
    "        return method\n",
    "\n",
    "def retrieve_gold_Method(raw_Y, ontology, device):\n",
    "    ontology_methods = ontology[\"method\"]\n",
    "    raw_gold_method = raw_Y[\"method\"]\n",
    "    gold_method = ontology_methods.index(raw_gold_method)\n",
    "    return torch.tensor([gold_method], dtype = torch.long, device = device)\n",
    "\n",
    "def retrieve_output_Method(output_tensor, ontology):\n",
    "    output_tensor = output_tensor.view(-1)\n",
    "    output_tensor = torch.exp(output_tensor)\n",
    "    method_dict = {}\n",
    "    \n",
    "    for index in range(len(output_tensor)):\n",
    "        method_dict[ontology[\"method\"][index]] = output_tensor[index].item()\n",
    "    \n",
    "    return method_dict\n",
    "\n",
    "model_Method = MethodModel(vocabulary_size = VOCABULARY_SIZE,\n",
    "                           embedding_dim = METHOD_EMBEDDING_DIM,\n",
    "                           altered_embedding_dim = METHOD_ALTERED_EMBEDDING_DIM,\n",
    "                           hidden_dim = METHOD_HIDDEN_DIM,\n",
    "                           method_dim = METHOD_DIM,\n",
    "                           device = DEVICE)\n",
    "\n",
    "model_Method = model_Method.to(DEVICE)\n",
    "\n",
    "optimizer_MethodModel = optim.Adam(model_Method.parameters(), lr = 1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch\t1/10\n",
      "100%|██████████| 3224/3224 [01:41<00:00, 31.85it/s]\n",
      "100%|██████████| 506/506 [00:02<00:00, 227.77it/s]\n",
      "INFO:root:Epoch train loss\t7479.8837890625 \tdev loss\t1499.3961181640625\n",
      "INFO:root:Epoch\t2/10\n",
      "100%|██████████| 3224/3224 [01:38<00:00, 39.38it/s]\n",
      "100%|██████████| 506/506 [00:02<00:00, 224.26it/s]\n",
      "INFO:root:Epoch train loss\t4581.791015625 \tdev loss\t1509.354736328125\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "marker": {
          "color": "#1abc9c"
         },
         "mode": "lines+markers",
         "name": "Train Loss",
         "type": "scatter",
         "uid": "0a41dd13-4cb2-433c-ba17-75595c99c830",
         "x": [
          0,
          1
         ],
         "y": [
          7479.8837890625,
          4581.791015625
         ]
        },
        {
         "marker": {
          "color": "#3498db"
         },
         "mode": "lines+markers",
         "name": "Dev Loss",
         "type": "scatter",
         "uid": "6fbc24ad-f398-49e4-af5c-37f41e5515f9",
         "x": [
          0,
          1
         ],
         "y": [
          1499.3961181640625,
          1509.354736328125
         ]
        }
       ],
       "layout": {
        "margin": {
         "b": 150
        },
        "title": "<b>Train-Dev Loss</b>",
        "xaxis": {
         "dtick": 1,
         "title": "<b>Epoch</b>",
         "titlefont": {
          "color": "#34495e"
         }
        },
        "yaxis": {
         "title": "<b>Loss</b>",
         "titlefont": {
          "color": "#34495e"
         }
        }
       }
      },
      "text/html": [
       "<div id=\"4c00f5a3-411e-49aa-8212-f4ba891a8520\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"4c00f5a3-411e-49aa-8212-f4ba891a8520\", [{\"marker\": {\"color\": \"#1abc9c\"}, \"mode\": \"lines+markers\", \"name\": \"Train Loss\", \"x\": [0, 1], \"y\": [7479.8837890625, 4581.791015625], \"type\": \"scatter\", \"uid\": \"a43fabe5-abad-4e1d-922f-ec4bd0c0296f\"}, {\"marker\": {\"color\": \"#3498db\"}, \"mode\": \"lines+markers\", \"name\": \"Dev Loss\", \"x\": [0, 1], \"y\": [1499.3961181640625, 1509.354736328125], \"type\": \"scatter\", \"uid\": \"c43c9a42-d830-4e20-bedd-5309b6bcf53e\"}], {\"margin\": {\"b\": 150}, \"title\": \"<b>Train-Dev Loss</b>\", \"xaxis\": {\"dtick\": 1, \"title\": \"<b>Epoch</b>\", \"titlefont\": {\"color\": \"#34495e\"}}, \"yaxis\": {\"title\": \"<b>Loss</b>\", \"titlefont\": {\"color\": \"#34495e\"}}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"4c00f5a3-411e-49aa-8212-f4ba891a8520\"));});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"4c00f5a3-411e-49aa-8212-f4ba891a8520\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"4c00f5a3-411e-49aa-8212-f4ba891a8520\", [{\"marker\": {\"color\": \"#1abc9c\"}, \"mode\": \"lines+markers\", \"name\": \"Train Loss\", \"x\": [0, 1], \"y\": [7479.8837890625, 4581.791015625], \"type\": \"scatter\", \"uid\": \"a43fabe5-abad-4e1d-922f-ec4bd0c0296f\"}, {\"marker\": {\"color\": \"#3498db\"}, \"mode\": \"lines+markers\", \"name\": \"Dev Loss\", \"x\": [0, 1], \"y\": [1499.3961181640625, 1509.354736328125], \"type\": \"scatter\", \"uid\": \"c43c9a42-d830-4e20-bedd-5309b6bcf53e\"}], {\"margin\": {\"b\": 150}, \"title\": \"<b>Train-Dev Loss</b>\", \"xaxis\": {\"dtick\": 1, \"title\": \"<b>Epoch</b>\", \"titlefont\": {\"color\": \"#34495e\"}}, \"yaxis\": {\"title\": \"<b>Loss</b>\", \"titlefont\": {\"color\": \"#34495e\"}}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"4c00f5a3-411e-49aa-8212-f4ba891a8520\"));});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_losses = []\n",
    "dev_losses = []\n",
    "method_early_stopping = EarlyStopping(patience = 0)\n",
    "\n",
    "for epoch in range(METHOD_NUM_EPOCHS):\n",
    "    \n",
    "    logging.info(\"Epoch\\t{}/{}\".format(epoch + 1, METHOD_NUM_EPOCHS))\n",
    "    \n",
    "    train_loss = 0\n",
    "    \n",
    "    model_Method = model_Method.train()\n",
    "    \n",
    "    for raw_X_train_dialog, raw_Y_train_dialog in tqdm(zip(raw_X_train, raw_Y_train), total = len(raw_X_train)):\n",
    "\n",
    "        model_Method.hidden = model_Method.init_hidden()\n",
    "\n",
    "        for raw_X_train_turn, raw_Y_train_turn in zip(raw_X_train_dialog[\"turns\"], raw_Y_train_dialog[\"turns\"]):\n",
    "            \n",
    "            optimizer_MethodModel.zero_grad()\n",
    "            \n",
    "            indices, scores = get_index_and_score(raw_X_train_turn, token_to_index, device = DEVICE)\n",
    "            \n",
    "            method = model_Method(indices, scores)\n",
    "            \n",
    "            loss_method = METHOD_LOSS_FUNCTION(method,\n",
    "                                               retrieve_gold_Method(raw_Y_train_turn,\n",
    "                                                                    ontology = ontology,\n",
    "                                                                    device = DEVICE))\n",
    "\n",
    "            loss = loss_method\n",
    "            loss.backward(retain_graph = True)\n",
    "            \n",
    "            train_loss += loss\n",
    "\n",
    "            optimizer_MethodModel.step()\n",
    "    \n",
    "    train_losses.append(train_loss.item())\n",
    "    \n",
    "    model_Method = model_Method.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        dev_loss = 0\n",
    "        \n",
    "        for raw_X_dev_dialog, raw_Y_dev_dialog in tqdm(zip(raw_X_dev, raw_Y_dev), total = len(raw_X_dev)):\n",
    "            \n",
    "            model_Method.hidden = model_Method.init_hidden()\n",
    "            \n",
    "            for raw_X_dev_turn, raw_Y_dev_turn in zip(raw_X_dev_dialog[\"turns\"], raw_Y_dev_dialog[\"turns\"]):\n",
    "                \n",
    "                indices, scores = get_index_and_score(raw_X_dev_turn, token_to_index, device = DEVICE)\n",
    "                \n",
    "                method = model_Method(indices, scores)\n",
    "            \n",
    "                loss_method = METHOD_LOSS_FUNCTION(method,\n",
    "                                                   retrieve_gold_Method(raw_Y_dev_turn,\n",
    "                                                                        ontology = ontology,\n",
    "                                                                        device = DEVICE))\n",
    "\n",
    "                loss = loss_method\n",
    "                \n",
    "                dev_loss += loss\n",
    "                \n",
    "        dev_losses.append(dev_loss.item())\n",
    "    \n",
    "    logging.info(\"Epoch train loss\\t{} \\tdev loss\\t{}\".format(train_loss, dev_loss))\n",
    "    \n",
    "    method_early_stopping.on_epoch_end(epoch = (epoch + 1), current_loss = dev_loss.item())\n",
    "    if method_early_stopping.stop_training:\n",
    "        break\n",
    "\n",
    "plotly_plot(train_losses, dev_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RequestedModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 vocabulary_size,\n",
    "                 embedding_dim,\n",
    "                 altered_embedding_dim,\n",
    "                 hidden_dim,\n",
    "                 requested_dim,\n",
    "                 device):\n",
    "        \n",
    "        super(RequestedModel, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.requested_dim = requested_dim\n",
    "        self.device = device\n",
    "        \n",
    "        self.embeddings = nn.Embedding(num_embeddings = vocabulary_size,\n",
    "                                       embedding_dim = embedding_dim)\n",
    "        \n",
    "        self.altered_embeddings = nn.Linear(in_features = (embedding_dim + 1),\n",
    "                                            out_features = altered_embedding_dim)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size = altered_embedding_dim,\n",
    "                            hidden_size = hidden_dim)\n",
    "        \n",
    "        \n",
    "        self.requested_classifier = nn.Linear(in_features = hidden_dim,\n",
    "                                              out_features = requested_dim)\n",
    "        \n",
    "        self.hidden = self.init_hidden()\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        \n",
    "        return (torch.zeros(1, 1, self.hidden_dim, device = self.device),\n",
    "                torch.zeros(1, 1, self.hidden_dim, device = self.device))\n",
    "        \n",
    "    def forward(self, indices, scores):\n",
    "        \n",
    "        embeddings = self.embeddings(indices)\n",
    "        \n",
    "        embeddings_concat_score = torch.cat((embeddings, scores.unsqueeze(dim = 1)), dim = 1) \n",
    "        \n",
    "        altered_embeddings = F.relu(self.altered_embeddings(embeddings_concat_score))\n",
    "        \n",
    "        lstm_out, self.hidden = self.lstm(altered_embeddings.view(len(indices), 1, -1), self.hidden)\n",
    "        \n",
    "        #requested = F.log_softmax(self.requested_classifier(self.hidden[0]).view(-1, self.requested_dim), dim = 1)\n",
    "        requested = torch.sigmoid(self.requested_classifier(self.hidden[0]).view(-1, self.requested_dim))\n",
    "        \n",
    "        return requested\n",
    "\n",
    "def retrieve_gold_Requested(raw_Y, ontology, device):\n",
    "    #ontology_requestable = ontology[\"requestable\"]\n",
    "    #raw_gold_requested = raw_Y[\"requested\"]\n",
    "    #binary_representation = np.zeros(len(ontology_requestable), dtype = int)\n",
    "    #if len(raw_gold_requested) != 0:\n",
    "    #    for requested in raw_gold_requested:\n",
    "    #        binary_representation[ontology_requestable.index(requested)] = 1        \n",
    "    #\n",
    "    #gold_requested = binary_representation.dot(2**np.arange(binary_representation.size)[::-1])\n",
    "    #return torch.tensor([gold_requested], dtype = torch.long, device = device)\n",
    "    \n",
    "    ontology_requestable = ontology[\"requestable\"]\n",
    "    raw_gold_requested = raw_Y[\"requested\"]\n",
    "    gold_requested = np.zeros(len(ontology_requestable), dtype = float)\n",
    "    if len(raw_gold_requested) != 0:\n",
    "        for requested in raw_gold_requested:\n",
    "            gold_requested[ontology_requestable.index(requested)] = 1.0\n",
    "    return torch.tensor([gold_requested], dtype = torch.float, device = device)\n",
    "\n",
    "model_Requested = RequestedModel(vocabulary_size = VOCABULARY_SIZE,\n",
    "                                 embedding_dim = REQUESTED_EMBEDDING_DIM,\n",
    "                                 altered_embedding_dim = REQUESTED_ALTERED_EMBEDDING_DIM,\n",
    "                                 hidden_dim = REQUESTED_HIDDEN_DIM,\n",
    "                                 requested_dim = REQUESTED_DIM,\n",
    "                                 device = DEVICE)\n",
    "\n",
    "model_Requested = model_Requested.to(DEVICE)\n",
    "\n",
    "optimizer_RequestedModel = optim.Adam(model_Requested.parameters(), lr = 1e-4)\n",
    "\n",
    "def retrieve_output_Requested(output_tensor, ontology):\n",
    "    #ontology_requestable = ontology[\"requestable\"]\n",
    "    #output_tensor = output_tensor.view(-1)\n",
    "    #output_tensor = torch.exp(output_tensor)\n",
    "    #requested_dict = {}\n",
    "    #binary_representation = get_bin(torch.argmax(output_tensor).item(), len(ontology[\"requestable\"]))\n",
    "    #indices = []\n",
    "    #index = 0\n",
    "    #for value in binary_representation:\n",
    "    #    if int(value) == 1:\n",
    "    #        indices.append(index)\n",
    "    #    index += 1\n",
    "    #for index in indices:\n",
    "    #    requested_dict[ontology_requestable[index]] = (1 / len(indices))\n",
    "    #return requested_dict\n",
    "    ontology_requestable = ontology[\"requestable\"]\n",
    "    output_tensor = output_tensor.view(-1)\n",
    "    requested_dict = {}\n",
    "    for index in range(len(output_tensor)):\n",
    "        probability_value = output_tensor[index].item()\n",
    "        if np.greater_equal(probability_value, 0.5):\n",
    "            requested_dict[ontology_requestable[index]] = probability_value\n",
    "    return requested_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train requested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch\t1/10\n",
      "100%|██████████| 3224/3224 [01:41<00:00, 41.06it/s]\n",
      "100%|██████████| 506/506 [00:02<00:00, 209.62it/s]\n",
      "INFO:root:Epoch train loss\t626.3695678710938 \tdev loss\t532.5632934570312\n",
      "INFO:root:Epoch\t2/10\n",
      "100%|██████████| 3224/3224 [01:41<00:00, 40.13it/s]\n",
      "100%|██████████| 506/506 [00:02<00:00, 197.09it/s]\n",
      "INFO:root:Epoch train loss\t234.8607635498047 \tdev loss\t607.312744140625\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "marker": {
          "color": "#1abc9c"
         },
         "mode": "lines+markers",
         "name": "Train Loss",
         "type": "scatter",
         "uid": "145bdf33-9d36-4b17-bfab-2489a8983d63",
         "x": [
          0,
          1
         ],
         "y": [
          626.3695678710938,
          234.8607635498047
         ]
        },
        {
         "marker": {
          "color": "#3498db"
         },
         "mode": "lines+markers",
         "name": "Dev Loss",
         "type": "scatter",
         "uid": "2a036888-ee75-4e8c-8b36-528686be412d",
         "x": [
          0,
          1
         ],
         "y": [
          532.5632934570312,
          607.312744140625
         ]
        }
       ],
       "layout": {
        "margin": {
         "b": 150
        },
        "title": "<b>Train-Dev Loss</b>",
        "xaxis": {
         "dtick": 1,
         "title": "<b>Epoch</b>",
         "titlefont": {
          "color": "#34495e"
         }
        },
        "yaxis": {
         "title": "<b>Loss</b>",
         "titlefont": {
          "color": "#34495e"
         }
        }
       }
      },
      "text/html": [
       "<div id=\"73741c04-b19d-472b-9f7d-0e7a95f345f7\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"73741c04-b19d-472b-9f7d-0e7a95f345f7\", [{\"marker\": {\"color\": \"#1abc9c\"}, \"mode\": \"lines+markers\", \"name\": \"Train Loss\", \"x\": [0, 1], \"y\": [626.3695678710938, 234.8607635498047], \"type\": \"scatter\", \"uid\": \"698a2c4a-b247-42e6-90bc-5b2bd0a3b9b5\"}, {\"marker\": {\"color\": \"#3498db\"}, \"mode\": \"lines+markers\", \"name\": \"Dev Loss\", \"x\": [0, 1], \"y\": [532.5632934570312, 607.312744140625], \"type\": \"scatter\", \"uid\": \"52d80237-8294-4710-8e27-9855e900fb7d\"}], {\"margin\": {\"b\": 150}, \"title\": \"<b>Train-Dev Loss</b>\", \"xaxis\": {\"dtick\": 1, \"title\": \"<b>Epoch</b>\", \"titlefont\": {\"color\": \"#34495e\"}}, \"yaxis\": {\"title\": \"<b>Loss</b>\", \"titlefont\": {\"color\": \"#34495e\"}}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"73741c04-b19d-472b-9f7d-0e7a95f345f7\"));});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"73741c04-b19d-472b-9f7d-0e7a95f345f7\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"73741c04-b19d-472b-9f7d-0e7a95f345f7\", [{\"marker\": {\"color\": \"#1abc9c\"}, \"mode\": \"lines+markers\", \"name\": \"Train Loss\", \"x\": [0, 1], \"y\": [626.3695678710938, 234.8607635498047], \"type\": \"scatter\", \"uid\": \"698a2c4a-b247-42e6-90bc-5b2bd0a3b9b5\"}, {\"marker\": {\"color\": \"#3498db\"}, \"mode\": \"lines+markers\", \"name\": \"Dev Loss\", \"x\": [0, 1], \"y\": [532.5632934570312, 607.312744140625], \"type\": \"scatter\", \"uid\": \"52d80237-8294-4710-8e27-9855e900fb7d\"}], {\"margin\": {\"b\": 150}, \"title\": \"<b>Train-Dev Loss</b>\", \"xaxis\": {\"dtick\": 1, \"title\": \"<b>Epoch</b>\", \"titlefont\": {\"color\": \"#34495e\"}}, \"yaxis\": {\"title\": \"<b>Loss</b>\", \"titlefont\": {\"color\": \"#34495e\"}}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"73741c04-b19d-472b-9f7d-0e7a95f345f7\"));});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_losses = []\n",
    "dev_losses = []\n",
    "requested_early_stopping = EarlyStopping(patience = 0)\n",
    "\n",
    "for epoch in range(REQUESTED_NUM_EPOCHS):\n",
    "    \n",
    "    logging.info(\"Epoch\\t{}/{}\".format(epoch + 1, REQUESTED_NUM_EPOCHS))\n",
    "    \n",
    "    train_loss = 0\n",
    "    \n",
    "    model_Requested = model_Requested.train()\n",
    "    \n",
    "    for raw_X_train_dialog, raw_Y_train_dialog in tqdm(zip(raw_X_train, raw_Y_train), total = len(raw_X_train)):\n",
    "\n",
    "        model_Requested.hidden = model_Requested.init_hidden()\n",
    "\n",
    "        for raw_X_train_turn, raw_Y_train_turn in zip(raw_X_train_dialog[\"turns\"], raw_Y_train_dialog[\"turns\"]):\n",
    "            \n",
    "            optimizer_RequestedModel.zero_grad()\n",
    "            \n",
    "            indices, scores = get_index_and_score(raw_X_train_turn, token_to_index, device = DEVICE)\n",
    "            \n",
    "            requested = model_Requested(indices, scores)\n",
    "            \n",
    "            loss_requested = REQUESTED_LOSS_FUNCTION(requested,\n",
    "                                                     retrieve_gold_Requested(raw_Y_train_turn,\n",
    "                                                                             ontology = ontology,\n",
    "                                                                             device = DEVICE))\n",
    "\n",
    "            loss = loss_requested\n",
    "            loss.backward(retain_graph = True)\n",
    "            \n",
    "            train_loss += loss\n",
    "\n",
    "            optimizer_RequestedModel.step()\n",
    "    \n",
    "    train_losses.append(train_loss.item())\n",
    "    \n",
    "    model_Requested = model_Requested.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        dev_loss = 0\n",
    "        \n",
    "        for raw_X_dev_dialog, raw_Y_dev_dialog in tqdm(zip(raw_X_dev, raw_Y_dev), total = len(raw_X_dev)):\n",
    "            \n",
    "            model_Requested.hidden = model_Requested.init_hidden()\n",
    "            \n",
    "            for raw_X_dev_turn, raw_Y_dev_turn in zip(raw_X_dev_dialog[\"turns\"], raw_Y_dev_dialog[\"turns\"]):\n",
    "                \n",
    "                indices, scores = get_index_and_score(raw_X_dev_turn, token_to_index, device = DEVICE)\n",
    "                \n",
    "                requested = model_Requested(indices, scores)\n",
    "            \n",
    "                loss_requested = REQUESTED_LOSS_FUNCTION(requested,\n",
    "                                                         retrieve_gold_Requested(raw_Y_train_turn,\n",
    "                                                                                 ontology = ontology,\n",
    "                                                                                 device = DEVICE))\n",
    "\n",
    "                loss = loss_requested\n",
    "                \n",
    "                dev_loss += loss\n",
    "                \n",
    "        dev_losses.append(dev_loss.item())\n",
    "    \n",
    "    logging.info(\"Epoch train loss\\t{} \\tdev loss\\t{}\".format(train_loss, dev_loss))\n",
    "    \n",
    "    requested_early_stopping.on_epoch_end(epoch = (epoch + 1), current_loss = dev_loss.item())\n",
    "    if requested_early_stopping.stop_training:\n",
    "        break\n",
    "\n",
    "plotly_plot(train_losses, dev_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tracker(raw_X, raw_Y, dataset):\n",
    "    with torch.no_grad():\n",
    "        tracker_json = {}\n",
    "        tracker_json[\"dataset\"] = dataset\n",
    "        tracker_json[\"sessions\"] = []\n",
    "\n",
    "        start_time = time.time()\n",
    "        for raw_X_dialog, raw_Y_dialog in tqdm(zip(raw_X, raw_Y), total = len(raw_X)):\n",
    "            \n",
    "            model_Goal.hidden = model_Goal.init_hidden()\n",
    "            model_Method.hidden = model_Method.init_hidden()\n",
    "            model_Requested.hidden = model_Requested.init_hidden()\n",
    "            \n",
    "            session = {}\n",
    "            session[\"session-id\"] = raw_X_dialog[\"session-id\"]\n",
    "            session[\"turns\"] = []\n",
    "\n",
    "            for raw_X_turn, raw_Y_turn in zip(raw_X_dialog[\"turns\"], raw_Y_dialog[\"turns\"]):\n",
    "                turn = {}\n",
    "                turn[\"goal-labels\"] = {}\n",
    "\n",
    "                indices, scores = get_index_and_score(raw_X_turn, token_to_index, device = DEVICE)\n",
    "                \n",
    "                output_MethodModel = model_Method(indices, scores)\n",
    "                turn[\"method-label\"] = retrieve_output_Method(output_MethodModel, ontology)\n",
    "\n",
    "                output_RequestedModel = model_Requested(indices, scores)\n",
    "                turn[\"requested-slots\"] = retrieve_output_Requested(output_RequestedModel, ontology)\n",
    "                #if torch.argmax(output_RequestedModel).item() == 0:\n",
    "                #    turn[\"requested-slots\"] = {}\n",
    "                #else:\n",
    "                #    turn[\"requested-slots\"] = retrieve_output_Requested(output_RequestedModel)\n",
    "\n",
    "                goal_food, goal_pricerange, goal_name, goal_area = model_Goal(indices, scores)\n",
    "                if torch.argmax(goal_food).item() != 0:\n",
    "                    turn[\"goal-labels\"][\"food\"] = retrieve_output_GoalFood(goal_food)\n",
    "                if torch.argmax(goal_pricerange).item() != 0:\n",
    "                    turn[\"goal-labels\"][\"pricerange\"] = retrieve_output_GoalPricerange(goal_pricerange)\n",
    "                if torch.argmax(goal_name).item() != 0:\n",
    "                    turn[\"goal-labels\"][\"name\"] = retrieve_output_GoalName(goal_name)\n",
    "                if torch.argmax(goal_area).item() != 0:\n",
    "                    turn[\"goal-labels\"][\"area\"] = retrieve_output_GoalArea(goal_area)\n",
    "\n",
    "                session[\"turns\"].append(turn)\n",
    "            tracker_json[\"sessions\"].append(session)\n",
    "        end_time = time.time()\n",
    "        tracker_json[\"wall-time\"] = end_time - start_time\n",
    "        return tracker_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 506/506 [00:08<00:00, 56.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    goal.joint                    \r\n",
      "--------------------------------------------------------------------------------------\r\n",
      "              |     eval_1a     |     eval_1b     |     eval_2a     |     eval_2b    |\r\n",
      "--------------------------------------------------------------------------------------\r\n",
      "acc           |    0.0391459    |    0.0124555    |    0.0205944    |    0.0127737   |\r\n",
      "avgp          |    0.0288825    |    0.0099875    |    0.0170870    |    0.0101455   |\r\n",
      "l2            |    1.4773246    |    1.5151146    |    1.5026927    |    1.5165757   |\r\n",
      "l2.binary     |    1.9207173    |    1.9723537    |    1.9527831    |    1.9720059   |\r\n",
      "mrr           |    0.0484875    |    0.0178571    |    0.0299140    |    0.0179875   |\r\n",
      "neglogp       |    8.7204736    |    9.0127590    |    8.8823203    |    9.0131407   |\r\n",
      "roc.v1_ca05   |    0.0005084    |    0.0005084    |    0.0005214    |    0.0005214   |\r\n",
      "roc.v1_ca10   |    0.0015252    |    0.0005084    |    0.0013034    |    0.0005214   |\r\n",
      "roc.v1_ca20   |    0.0035587    |    0.0020336    |    0.0031283    |    0.0018248   |\r\n",
      "roc.v1_eer    |    0.0777834    |    0.0249110    |    0.0406674    |    0.0255474   |\r\n",
      "roc.v2_ca05   |    0.0129870    |    0.0408163    |    0.0253165    |    0.0408163   |\r\n",
      "roc.v2_ca10   |    0.0389610    |    0.0408163    |    0.0632911    |    0.0408163   |\r\n",
      "roc.v2_ca20   |    0.0779221    |    0.1428571    |    0.1392405    |    0.1428571   |\r\n",
      "update.acc    |    0.0000000    |    0.0000000    |    0.0000000    |    0.0000000   |\r\n",
      "update.prec   |        -        |        -        |        -        |        -       |\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "                      method                      \r\n",
      "--------------------------------------------------------------------------------------\r\n",
      "              |     eval_1a     |     eval_1b     |     eval_2a     |     eval_2b    |\r\n",
      "--------------------------------------------------------------------------------------\r\n",
      "acc           |    0.8919675    |    0.5523640    |    0.8929126    |    0.5473357   |\r\n",
      "avgp          |    0.8654858    |    0.5415961    |    0.8674880    |    0.5379014   |\r\n",
      "l2            |    0.1837218    |    0.8315012    |    0.1824082    |    0.8415815   |\r\n",
      "l2.binary     |    0.1888156    |    0.8713455    |    0.1873774    |    0.8819124   |\r\n",
      "mrr           |    0.9422428    |    0.6955982    |    0.9427358    |    0.6917529   |\r\n",
      "neglogp       |    0.3836698    |    2.6192185    |    0.3819579    |    2.6568283   |\r\n",
      "roc.v1_ca05   |    0.7048805    |    0.3612100    |    0.7139162    |    0.3670460   |\r\n",
      "roc.v1_ca10   |    0.8835791    |    0.3952720    |    0.8861873    |    0.4019659   |\r\n",
      "roc.v1_ca20   |    0.8919675    |    0.4339095    |    0.8929126    |    0.4405070   |\r\n",
      "roc.v1_eer    |    0.1372649    |    0.2821556    |    0.1386446    |    0.2664252   |\r\n",
      "roc.v2_ca05   |    0.3308635    |    0.5720202    |    0.3334299    |    0.5874291   |\r\n",
      "roc.v2_ca10   |    0.4508407    |    0.6405890    |    0.4582851    |    0.6578450   |\r\n",
      "roc.v2_ca20   |    0.5802223    |    0.7077773    |    0.5814021    |    0.7268431   |\r\n",
      "update.acc    |    0.7681906    |    0.4058319    |    0.7602649    |    0.3960293   |\r\n",
      "update.prec   |    0.9120795    |    0.9044343    |    0.9140127    |    0.9052548   |\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "                  requested.all                   \r\n",
      "--------------------------------------------------\r\n",
      "              |     eval_1a     |     eval_2a    |\r\n",
      "--------------------------------------------------\r\n",
      "acc           |    0.9945348    |    0.9632167   |\r\n",
      "avgp          |    0.9939708    |    0.9547217   |\r\n",
      "l2            |    0.0099666    |    0.0700473   |\r\n",
      "l2.binary     |    0.0099666    |    0.0700473   |\r\n",
      "mrr           |    0.9972674    |    0.9816084   |\r\n",
      "neglogp       |    0.0396806    |    0.2724498   |\r\n",
      "roc.v1_ca05   |    0.9945348    |    0.9632167   |\r\n",
      "roc.v1_ca10   |    0.9945348    |    0.9632167   |\r\n",
      "roc.v1_ca20   |    0.9945348    |    0.9632167   |\r\n",
      "roc.v1_eer    |    0.0085791    |    0.0605842   |\r\n",
      "roc.v2_ca05   |    0.0000319    |    0.0003744   |\r\n",
      "roc.v2_ca10   |    0.0000319    |    0.0003744   |\r\n",
      "roc.v2_ca20   |    0.0000319    |    0.0003744   |\r\n",
      "update.acc    |    0.9557425    |    0.9383886   |\r\n",
      "update.prec   |    0.9797525    |    0.9603880   |\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "                                    featured metrics\r\n",
      "--------------------------------------------------------------------\r\n",
      "              |   Joint Goals   |    Requested    |      Method    |\r\n",
      "--------------------------------------------------------------------\r\n",
      "Accuracy      |    0.0205944    |    0.9632167    |    0.8929126   |\r\n",
      "l2            |    1.5026927    |    0.0700473    |    0.1824082   |\r\n",
      "roc.v2_ca05   |    0.0253165    |    0.0003744    |    0.3334299   |\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "                                    basic stats\r\n",
      "-----------------------------------------------------------------------------------\r\n",
      "             dataset : dstc2_dev\r\n",
      "            sessions : 506\r\n",
      "     total_wall_time : 8.94807124138\r\n",
      "               turns : 3934\r\n",
      "  wall_time_per_turn : 0.00227454784987\r\n"
     ]
    }
   ],
   "source": [
    "dev_tracker = make_tracker(raw_X_dev, raw_Y_dev, dataset = \"dstc2_dev\")\n",
    "\n",
    "with open(\"dev_tracker.json\", \"w\") as dev_tracker_file:\n",
    "    json.dump(dev_tracker, dev_tracker_file)\n",
    "\n",
    "!python2 dstc2/dstc2_scripts/score.py\\\n",
    "--dataset dstc2_dev\\\n",
    "--dataroot dstc2/dstc2_traindev/data\\\n",
    "--ontology dstc2/dstc2_scripts/config/ontology_dstc2.json\\\n",
    "--trackfile dev_tracker.json\\\n",
    "--scorefile dev_tracker.score.csv\n",
    "\n",
    "!python2 dstc2/dstc2_scripts/report.py --scorefile dev_tracker.score.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
