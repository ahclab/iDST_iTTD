{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Dec 24 10:16:06 2018       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 384.145                Driver Version: 384.145                   |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:02:00.0 Off |                  N/A |\r\n",
      "| 23%   26C    P8    16W / 250W |      0MiB / 11172MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:03:00.0 Off |                  N/A |\r\n",
      "| 23%   44C    P0    62W / 250W |      0MiB / 11172MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/is/andrei-\n",
      "[nltk_data]     cc/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:+--------------------------------+\n",
      "INFO:root:|         _ ____  ___________    |\n",
      "INFO:root:|        (_) __ \\/ ___/_  __/    |\n",
      "INFO:root:|       / / / / /\\__ \\ / /       |\n",
      "INFO:root:|      / / /_/ /___/ // /        |\n",
      "INFO:root:|     /_/_____//____//_/         |\n",
      "INFO:root:|                                |\n",
      "INFO:root:+--------------------------------+\n",
      "INFO:root:|Incremental Dialog State Tracker|\n",
      "INFO:root:+--------------------------------+\n",
      "INFO:root:+--------------------------------+\n",
      "INFO:root:|     Dialog State Tracker 2     |\n",
      "INFO:root:|         Data Checker           |\n",
      "INFO:root:+--------------------------------+\n",
      "INFO:root:Looking for dstc2 directory in .\n",
      "INFO:root:dstc2 was found!\n",
      "INFO:root:Looking for dstc2_traindev directory in ./dstc2\n",
      "INFO:root:dstc2_traindev was found!\n",
      "INFO:root:Looking for dstc2_test directory in ./dstc2\n",
      "INFO:root:dstc2_test was found!\n",
      "INFO:root:Looking for dstc2_scripts directory in ./dstc2\n",
      "INFO:root:dstc2_scripts was found!\n",
      "INFO:root:Done!\n",
      "INFO:root:+--------------------------------+\n",
      "INFO:root:|     Dialog State Tracker 2     |\n",
      "INFO:root:|       Dataset Retrieval        |\n",
      "INFO:root:+--------------------------------+\n",
      "INFO:root:Reading dstc2_train.flist, dstc2_dev.flist and ontology_dstc2.json\n",
      "INFO:root:Asserted 1612 dialogs for dstc2_train.flist\n",
      "INFO:root:Asserted 506 dialogs for dstc2_dev.flist\n",
      "INFO:root:Extracting raw train features\n",
      "100%|██████████| 1612/1612 [00:10<00:00, 149.99it/s]\n",
      "INFO:root:Extracting raw dev features\n",
      "100%|██████████| 506/506 [00:02<00:00, 169.92it/s]\n",
      "INFO:root:Reading dstc2_test.flist\n",
      "INFO:root:Asserted 1117 dialogs for dstc2_test.flist\n",
      "INFO:root:Extracting raw test features\n",
      "100%|██████████| 1117/1117 [00:07<00:00, 149.71it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import plotly\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "from tqdm import tqdm\n",
    "from idst_util import trivial\n",
    "from idst_util import dstc2\n",
    "\n",
    "from plotly.graph_objs import Scatter, Layout\n",
    "from plotly.graph_objs.layout import Margin\n",
    "plotly.offline.init_notebook_mode(connected = True)\n",
    "\n",
    "\n",
    "# Make sure data is available\n",
    "trivial.print_idst()\n",
    "dstc2.check()\n",
    "\n",
    "# Retrieve raw data\n",
    "raw_X_train, raw_Y_train, \\\n",
    "raw_X_dev, raw_Y_dev, \\\n",
    "raw_X_test, raw_Y_test, \\\n",
    "ontology = dstc2.retrieve_raw_datasets(train_data_augmentation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:+--------------------------------+\n",
      "INFO:root:|            Baseline            |\n",
      "INFO:root:+--------------------------------+\n",
      "INFO:root:Running on GPU 1\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"+--------------------------------+\")\n",
    "logging.info(\"|            Baseline            |\")\n",
    "logging.info(\"+--------------------------------+\")\n",
    "\n",
    "GPU_ID = 1\n",
    "DEVICE = torch.device(\"cuda:{}\".format(GPU_ID) if torch.cuda.is_available() else \"cpu\")\n",
    "#DEVICE = \"cpu\"\n",
    "if DEVICE == \"cpu\":\n",
    "    logging.warning(\"Running on CPU\")\n",
    "else:\n",
    "    logging.info(\"Running on GPU {}\".format(GPU_ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:+--------------------------------+\n",
      "INFO:root:|          Vocabulary            |\n",
      "INFO:root:+--------------------------------+\n",
      "INFO:root:Creating token_to_index, index_to_token and token_to_count dictionaries\n",
      "100%|██████████| 3224/3224 [00:00<00:00, 26007.89it/s]\n",
      "INFO:root:Vocabulary length:\t1149\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"+--------------------------------+\")\n",
    "logging.info(\"|          Vocabulary            |\")\n",
    "logging.info(\"+--------------------------------+\")\n",
    "logging.info(\"Creating token_to_index, index_to_token and token_to_count dictionaries\")\n",
    "\n",
    "token_to_index = {\"<unk>\": 0}\n",
    "index_to_token = {0: \"<unk>\"}\n",
    "token_to_count = {\"<unk>\": 1}\n",
    "\n",
    "for raw_train_dialog in tqdm(raw_X_train):\n",
    "    \n",
    "    for raw_train_turn in raw_train_dialog[\"turns\"]:\n",
    "\n",
    "        for system_token in raw_train_turn[\"system\"]:\n",
    "            token = system_token[0]\n",
    "            if token not in token_to_index:\n",
    "                token_to_index[token] = len(token_to_index)\n",
    "                index_to_token[len(token_to_index)] = token\n",
    "                token_to_count[token] = 1\n",
    "            else:\n",
    "                token_to_count[token] += 1\n",
    "        \n",
    "        for user_token in raw_train_turn[\"user\"]:\n",
    "            token = user_token[0]\n",
    "            if token not in token_to_index:\n",
    "                token_to_index[token] = len(token_to_index)\n",
    "                index_to_token[len(token_to_index)] = token\n",
    "                token_to_count[token] = 1\n",
    "            else:\n",
    "                token_to_count[token] += 1\n",
    "                \n",
    "assert len(token_to_index) == len(index_to_token)\n",
    "assert len(token_to_index) == len(token_to_count)\n",
    "\n",
    "logging.info(\"Vocabulary length:\\t{}\".format(len(token_to_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:+--------------------------------+\n",
      "INFO:root:|         Configuration          |\n",
      "INFO:root:+--------------------------------+\n",
      "INFO:root:VOCABULARY_SIZE:\t1149\n",
      "INFO:root:EMBEDDING_DIM:\t170\n",
      "INFO:root:HIDDEN_DIM:\t\t100\n",
      "INFO:root:NUM_NODES:\t\t300\n",
      "INFO:root:NUM_EPOCHS:\t\t150\n",
      "INFO:root:METHOD_DIM:\t\t5\n",
      "INFO:root:REQUESTED_DIM:\t256\n",
      "INFO:root:GOAL_FOOD_DIM:\t93\n",
      "INFO:root:GOAL_PRICERANGE_DIM:\t5\n",
      "INFO:root:GOAL_NAME_DIM:\t115\n",
      "INFO:root:GOAL_AREA_DIM:\t7\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"+--------------------------------+\")\n",
    "logging.info(\"|         Configuration          |\")\n",
    "logging.info(\"+--------------------------------+\")\n",
    "\n",
    "VOCABULARY_SIZE = len(token_to_index)\n",
    "EMBEDDING_DIM = 170\n",
    "HIDDEN_DIM = 100\n",
    "NUM_NODES = 300\n",
    "NUM_EPOCHS = 150\n",
    "\n",
    "METHOD_DIM = len(ontology[\"method\"])\n",
    "REQUESTED_DIM = int(math.pow(2, len(ontology[\"requestable\"])))\n",
    "GOAL_FOOD_DIM = len(ontology[\"informable\"][\"food\"]) + 2 # because of null and dontcare\n",
    "GOAL_PRICERANGE_DIM = len(ontology[\"informable\"][\"pricerange\"]) + 2 # because of null and dontcare\n",
    "GOAL_NAME_DIM = len(ontology[\"informable\"][\"name\"]) + 2 # because of null and dontcare\n",
    "GOAL_AREA_DIM = len(ontology[\"informable\"][\"area\"]) + 2 # because of null and dontcare\n",
    "\n",
    "logging.info(\"VOCABULARY_SIZE:\\t{}\".format(VOCABULARY_SIZE))\n",
    "logging.info(\"EMBEDDING_DIM:\\t{}\".format(EMBEDDING_DIM))\n",
    "logging.info(\"HIDDEN_DIM:\\t\\t{}\".format(HIDDEN_DIM))\n",
    "logging.info(\"NUM_NODES:\\t\\t{}\".format(NUM_NODES))\n",
    "logging.info(\"NUM_EPOCHS:\\t\\t{}\".format(NUM_EPOCHS))\n",
    "logging.info(\"METHOD_DIM:\\t\\t{}\".format(METHOD_DIM))\n",
    "logging.info(\"REQUESTED_DIM:\\t{}\".format(REQUESTED_DIM))\n",
    "logging.info(\"GOAL_FOOD_DIM:\\t{}\".format(GOAL_FOOD_DIM))\n",
    "logging.info(\"GOAL_PRICERANGE_DIM:\\t{}\".format(GOAL_PRICERANGE_DIM))\n",
    "logging.info(\"GOAL_NAME_DIM:\\t{}\".format(GOAL_NAME_DIM))\n",
    "logging.info(\"GOAL_AREA_DIM:\\t{}\".format(GOAL_AREA_DIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LecTrackEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_dim, hidden_dim, vocabulary_size, num_nodes, device):\n",
    "        super(LecTrackEncoder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.device = device\n",
    "        self.token_embeddings = nn.Embedding(num_embeddings = vocabulary_size,\n",
    "                                            embedding_dim = embedding_dim)\n",
    "        self.linear = nn.Linear(in_features = (embedding_dim + 1), # because of score\n",
    "                                out_features = num_nodes)\n",
    "        self.lstm = nn.LSTM(num_nodes, hidden_dim)\n",
    "        \n",
    "        self.hidden = self.init_hidden()\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(1, 1, self.hidden_dim, device = self.device),\n",
    "                torch.zeros(1, 1, self.hidden_dim, device = self.device))\n",
    "        \n",
    "    def forward(self, indexes, scores):\n",
    "        embeddings = self.token_embeddings(indexes)\n",
    "        embeddings_concat_score = torch.cat((embeddings, scores.unsqueeze(dim = 1)), dim = 1) \n",
    "        altered_embeddings = F.relu(self.linear(embeddings_concat_score))\n",
    "        lstm_out, self.hidden = self.lstm(altered_embeddings.view(len(indexes), 1, -1), self.hidden)\n",
    "        return self.hidden\n",
    "    \n",
    "model_LecTrackEncoder = LecTrackEncoder(embedding_dim = EMBEDDING_DIM,\n",
    "                                        hidden_dim = HIDDEN_DIM,\n",
    "                                        vocabulary_size = VOCABULARY_SIZE,\n",
    "                                        num_nodes = NUM_NODES,\n",
    "                                        device = DEVICE)\n",
    "\n",
    "model_LecTrackEncoder = model_LecTrackEncoder.to(DEVICE)\n",
    "\n",
    "optimizer_LecTrackEncoder = optim.Adam(model_LecTrackEncoder.parameters(), lr = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LecTrackMethodClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_dim, method_dim):\n",
    "        super(LecTrackMethodClassifier, self).__init__()\n",
    "        self.method_dim = method_dim\n",
    "        self.linear = nn.Linear(in_features = hidden_dim,\n",
    "                                out_features = method_dim)\n",
    "        \n",
    "    def forward(self, hidden):\n",
    "        return F.log_softmax(self.linear(hidden).view(-1, self.method_dim), dim = 1)\n",
    "\n",
    "    \n",
    "model_LecTrackMethodClassifier = LecTrackMethodClassifier(hidden_dim = HIDDEN_DIM,\n",
    "                                                          method_dim = METHOD_DIM)\n",
    "\n",
    "model_LecTrackMethodClassifier = model_LecTrackMethodClassifier.to(DEVICE)\n",
    "\n",
    "optimizer_LecTrackMethodClassifier = optim.Adam(model_LecTrackMethodClassifier.parameters(), lr = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LecTrackRequestedClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_dim, requested_dim):\n",
    "        super(LecTrackRequestedClassifier, self).__init__()\n",
    "        self.requested_dim = requested_dim\n",
    "        self.linear = nn.Linear(in_features = hidden_dim,\n",
    "                                out_features = requested_dim) \n",
    "        \n",
    "    def forward(self, hidden):\n",
    "        return F.log_softmax(self.linear(hidden).view(-1, self.requested_dim), dim = 1)\n",
    "\n",
    "model_LecTrackRequestedClassifier = LecTrackRequestedClassifier(hidden_dim = HIDDEN_DIM,\n",
    "                                                                requested_dim = REQUESTED_DIM)\n",
    "\n",
    "model_LecTrackRequestedClassifier = model_LecTrackRequestedClassifier.to(DEVICE)\n",
    "\n",
    "optimizer_LecTrackRequestedClassifier = optim.Adam(model_LecTrackRequestedClassifier.parameters(), lr = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LecTrackGoalFoodClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_dim, goal_food_dim):\n",
    "        super(LecTrackGoalFoodClassifier, self).__init__()\n",
    "        self.goal_food_dim = goal_food_dim\n",
    "        self.linear = nn.Linear(in_features = hidden_dim,\n",
    "                                out_features = goal_food_dim)\n",
    "        \n",
    "    def forward(self, hidden):\n",
    "        return F.log_softmax(self.linear(hidden).view(-1, self.goal_food_dim), dim = 1)\n",
    "\n",
    "model_LecTrackGoalFoodClassifier = LecTrackGoalFoodClassifier(hidden_dim = HIDDEN_DIM,\n",
    "                                                              goal_food_dim = GOAL_FOOD_DIM)\n",
    "\n",
    "model_LecTrackGoalFoodClassifier = model_LecTrackGoalFoodClassifier.to(DEVICE)\n",
    "\n",
    "optimizer_LecTrackGoalFoodClassifier = optim.Adam(model_LecTrackGoalFoodClassifier.parameters(), lr = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LecTrackGoalPricerangeClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_dim, goal_pricerange_dim):\n",
    "        super(LecTrackGoalPricerangeClassifier, self).__init__()\n",
    "        self.goal_pricerange_dim = goal_pricerange_dim\n",
    "        self.linear = nn.Linear(in_features = hidden_dim,\n",
    "                                out_features = goal_pricerange_dim)\n",
    "        \n",
    "    def forward(self, hidden):\n",
    "        return F.log_softmax(self.linear(hidden).view(-1, self.goal_pricerange_dim), dim = 1)\n",
    "\n",
    "model_LecTrackGoalPricerangeClassifier = LecTrackGoalPricerangeClassifier(hidden_dim = HIDDEN_DIM,\n",
    "                                                                          goal_pricerange_dim = GOAL_PRICERANGE_DIM)\n",
    "\n",
    "model_LecTrackGoalPricerangeClassifier = model_LecTrackGoalPricerangeClassifier.to(DEVICE)\n",
    "\n",
    "optimizer_LecTrackGoalPricerangeClassifier = optim.Adam(model_LecTrackGoalPricerangeClassifier.parameters(), lr = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LecTrackGoalNameClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_dim, goal_name_dim):\n",
    "        super(LecTrackGoalNameClassifier, self).__init__()\n",
    "        self.goal_name_dim = goal_name_dim\n",
    "        self.linear = nn.Linear(in_features = hidden_dim,\n",
    "                                out_features = goal_name_dim)\n",
    "        \n",
    "    def forward(self, hidden):\n",
    "        return F.log_softmax(self.linear(hidden).view(-1, self.goal_name_dim), dim = 1)\n",
    "    \n",
    "model_LecTrackGoalNameClassifier = LecTrackGoalNameClassifier(hidden_dim = HIDDEN_DIM,\n",
    "                                                             goal_name_dim = GOAL_NAME_DIM)\n",
    "\n",
    "model_LecTrackGoalNameClassifier = model_LecTrackGoalNameClassifier.to(DEVICE)\n",
    "\n",
    "optimizer_LecTrackGoalNameClassifier = optim.Adam(model_LecTrackGoalNameClassifier.parameters(), lr = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LecTrackGoalAreaClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_dim, goal_area_dim):\n",
    "        super(LecTrackGoalAreaClassifier, self).__init__()\n",
    "        self.goal_area_dim = goal_area_dim\n",
    "        self.linear = nn.Linear(in_features = hidden_dim,\n",
    "                                out_features = goal_area_dim)\n",
    "        \n",
    "    def forward(self, hidden):\n",
    "        return F.log_softmax(self.linear(hidden).view(-1, self.goal_area_dim), dim = 1)\n",
    "\n",
    "model_LecTrackGoalAreaClassifier = LecTrackGoalAreaClassifier(hidden_dim = HIDDEN_DIM,\n",
    "                                                             goal_area_dim = GOAL_AREA_DIM)\n",
    "\n",
    "model_LecTrackGoalAreaClassifier = model_LecTrackGoalAreaClassifier.to(DEVICE)\n",
    "\n",
    "optimizer_LecTrackGoalAreaClassifier = optim.Adam(model_LecTrackGoalAreaClassifier.parameters(), lr = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_and_score(turn, token_to_index, device):\n",
    "    indexes = []\n",
    "    scores = []\n",
    "    token_score_list = turn[\"system\"] + turn[\"user\"]\n",
    "    for token, score in token_score_list:\n",
    "        if token not in token_to_index:\n",
    "            indexes.append(token_to_index[\"<unk>\"])\n",
    "        else:\n",
    "            indexes.append(token_to_index[token])\n",
    "        scores.append(score)\n",
    "    assert len(indexes) == len(scores)\n",
    "    return torch.tensor(indexes, dtype = torch.long, device = device), torch.tensor(scores, dtype = torch.float, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_gold_Method(raw_Y, ontology, device):\n",
    "    ontology_methods = ontology[\"method\"]\n",
    "    raw_goal_method = raw_Y[\"method\"]\n",
    "    goal_method = ontology_methods.index(raw_goal_method)\n",
    "    return torch.tensor([goal_method], dtype = torch.long, device = device)\n",
    "\n",
    "def retrieve_gold_Requested(raw_Y, ontology, device):\n",
    "    ontology_requestable = ontology[\"requestable\"]\n",
    "    raw_gold_requested = raw_Y[\"requested\"]\n",
    "    \n",
    "    binary_representation = np.zeros(len(ontology_requestable), dtype = int)\n",
    "    if len(raw_gold_requested) != 0:\n",
    "        for requested in raw_gold_requested:\n",
    "            binary_representation[ontology_requestable.index(requested)] = 1        \n",
    "    \n",
    "    goal_requested = binary_representation.dot(2**np.arange(binary_representation.size)[::-1])\n",
    "    return torch.tensor([goal_requested], dtype = torch.long, device = device)\n",
    "\n",
    "def retrieve_gold_GoalFood(raw_Y, ontology, device):\n",
    "    ontology_informable_food = ontology[\"informable\"][\"food\"]\n",
    "    raw_goal_food = raw_Y[\"goal\"][\"food\"]\n",
    "    goal_food = 0\n",
    "    if raw_goal_food != None:\n",
    "        if raw_goal_food == \"dontcare\":\n",
    "            goal_food = 1\n",
    "        else:    \n",
    "            goal_food = ontology_informable_food.index(raw_goal_food) + 2\n",
    "    return torch.tensor([goal_food], dtype = torch.long, device = device)\n",
    "\n",
    "def retrieve_gold_GoalPriceRange(raw_Y, ontology, device):\n",
    "    ontology_informable_pricerange = ontology[\"informable\"][\"pricerange\"]\n",
    "    raw_goal_pricerange = raw_Y[\"goal\"][\"pricerange\"]\n",
    "    goal_pricerange = 0\n",
    "    if raw_goal_pricerange != None:\n",
    "        if raw_goal_pricerange == \"dontcare\":\n",
    "            goal_pricerange = 1\n",
    "        else:    \n",
    "            goal_pricerange = ontology_informable_pricerange.index(raw_goal_pricerange) + 2\n",
    "    return torch.tensor([goal_pricerange], dtype = torch.long, device = device)\n",
    "\n",
    "def retrieve_gold_GoalName(raw_Y, ontology, device):\n",
    "    ontology_informable_name = ontology[\"informable\"][\"name\"]\n",
    "    raw_goal_name = raw_Y[\"goal\"][\"name\"]\n",
    "    goal_name = 0\n",
    "    if raw_goal_name != None:\n",
    "        if raw_goal_name == \"dontcare\":\n",
    "            goal_name = 1\n",
    "        else:    \n",
    "            goal_name = ontology_informable_name.index(raw_goal_name) + 2\n",
    "    return torch.tensor([goal_name], dtype = torch.long, device = device)\n",
    "\n",
    "def retrieve_gold_GoalArea(raw_Y, ontology, device):\n",
    "    ontology_informable_area = ontology[\"informable\"][\"area\"]\n",
    "    raw_goal_area = raw_Y[\"goal\"][\"area\"]\n",
    "    goal_area = 0\n",
    "    if raw_goal_area != None:\n",
    "        if raw_goal_area == \"dontcare\":\n",
    "            goal_area = 1\n",
    "        else:    \n",
    "            goal_area = ontology_informable_area.index(raw_goal_area) + 2\n",
    "    return torch.tensor([goal_area], dtype = torch.long, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch\t1/150\n",
      "100%|██████████| 3224/3224 [02:27<00:00, 21.87it/s]\n",
      "100%|██████████| 506/506 [00:05<00:00, 100.14it/s]\n",
      "INFO:root:Epoch train loss\t132222.25 \tdev loss\t31473.98828125\n",
      "INFO:root:Epoch\t2/150\n",
      "100%|██████████| 3224/3224 [02:27<00:00, 21.81it/s]\n",
      "100%|██████████| 506/506 [00:04<00:00, 102.25it/s]\n",
      "INFO:root:Epoch train loss\t68159.109375 \tdev loss\t32299.166015625\n",
      "INFO:root:Epoch\t3/150\n",
      "100%|██████████| 3224/3224 [02:25<00:00, 22.15it/s]\n",
      "100%|██████████| 506/506 [00:04<00:00, 102.25it/s]\n",
      "INFO:root:Epoch train loss\t44988.734375 \tdev loss\t27455.037109375\n",
      "INFO:root:Epoch\t4/150\n",
      " 58%|█████▊    | 1874/3224 [01:26<01:01, 22.08it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-38188012b983>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mgold_LecTrackGoalAreaClassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretrieve_gold_GoalArea\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_Y_train_turn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0montology\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mloss_LecTrackMethodClassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_LecTrackMethodClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold_LecTrackMethodClassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0mloss_LecTrackRequestedClassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_LecTrackRequestedClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold_LecTrackRequestedClassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mloss_LecTrackGoalFoodClassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_LecTrackGoalFoodClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold_LecTrackGoalFoodClassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/iDST-PMaBuuf7/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/iDST-PMaBuuf7/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    902\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 904\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/iDST-PMaBuuf7/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1968\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1969\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1970\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/iDST-PMaBuuf7/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1788\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[1;32m   1789\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1790\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1791\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_epoch_losses = []\n",
    "dev_epoch_losses = []\n",
    "\n",
    "# define the loss function\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    logging.info(\"Epoch\\t{}/{}\".format(epoch + 1, NUM_EPOCHS))\n",
    "    \n",
    "    train_epoch_loss = 0\n",
    "    \n",
    "    # for each dialog\n",
    "    for raw_X_train_dialog, raw_Y_train_dialog in tqdm(zip(raw_X_train, raw_Y_train), total = len(raw_X_train)):\n",
    "\n",
    "        model_LecTrackEncoder.hidden = model_LecTrackEncoder.init_hidden()\n",
    "        model_LecTrackEncoder.zero_grad()\n",
    "        model_LecTrackMethodClassifier.zero_grad()\n",
    "        model_LecTrackRequestedClassifier.zero_grad()\n",
    "        model_LecTrackGoalFoodClassifier.zero_grad()\n",
    "        model_LecTrackGoalPricerangeClassifier.zero_grad()\n",
    "        model_LecTrackGoalNameClassifier.zero_grad()\n",
    "        model_LecTrackGoalAreaClassifier.zero_grad()\n",
    "\n",
    "        # for each turn in the dialog\n",
    "        for raw_X_train_turn, raw_Y_train_turn in zip(raw_X_train_dialog[\"turns\"], raw_Y_train_dialog[\"turns\"]):\n",
    "\n",
    "            indexes, scores = get_index_and_score(raw_X_train_turn, token_to_index, device = DEVICE)\n",
    "\n",
    "            output_LecTrackEncoder = model_LecTrackEncoder(indexes, scores)\n",
    "            output_LecTrackMethodClassifier = model_LecTrackMethodClassifier(output_LecTrackEncoder[0])\n",
    "            output_LecTrackRequestedClassifier = model_LecTrackRequestedClassifier(output_LecTrackEncoder[0])\n",
    "            output_LecTrackGoalFoodClassifier = model_LecTrackGoalFoodClassifier(output_LecTrackEncoder[0])\n",
    "            output_LecTrackGoalPricerangeClassifier = model_LecTrackGoalPricerangeClassifier(output_LecTrackEncoder[0])\n",
    "            output_LecTrackGoalNameClassifier = model_LecTrackGoalNameClassifier(output_LecTrackEncoder[0])\n",
    "            output_LecTrackGoalAreaClassifier = model_LecTrackGoalAreaClassifier(output_LecTrackEncoder[0])\n",
    "\n",
    "            gold_LecTrackMethodClassifier = retrieve_gold_Method(raw_Y_train_turn, ontology, device = DEVICE)\n",
    "            gold_LecTrackRequestedClassifier = retrieve_gold_Requested(raw_Y_train_turn, ontology, device = DEVICE)\n",
    "            gold_LecTrackGoalFoodClassifier = retrieve_gold_GoalFood(raw_Y_train_turn, ontology, device = DEVICE)\n",
    "            gold_LecTrackGoalPricerangeClassifier = retrieve_gold_GoalPriceRange(raw_Y_train_turn, ontology, device = DEVICE)\n",
    "            gold_LecTrackGoalNameClassifier = retrieve_gold_GoalName(raw_Y_train_turn, ontology, device = DEVICE)\n",
    "            gold_LecTrackGoalAreaClassifier = retrieve_gold_GoalArea(raw_Y_train_turn, ontology, device = DEVICE)\n",
    "\n",
    "            loss_LecTrackMethodClassifier = loss_function(output_LecTrackMethodClassifier, gold_LecTrackMethodClassifier)\n",
    "            loss_LecTrackRequestedClassifier = loss_function(output_LecTrackRequestedClassifier, gold_LecTrackRequestedClassifier)\n",
    "            loss_LecTrackGoalFoodClassifier = loss_function(output_LecTrackGoalFoodClassifier, gold_LecTrackGoalFoodClassifier)\n",
    "            loss_LecTrackGoalPricerangeClassifier = loss_function(output_LecTrackGoalPricerangeClassifier, gold_LecTrackGoalPricerangeClassifier)\n",
    "            loss_LecTrackGoalNameClassifier = loss_function(output_LecTrackGoalNameClassifier, gold_LecTrackGoalNameClassifier)\n",
    "            loss_LecTrackGoalAreaClassifier = loss_function(output_LecTrackGoalAreaClassifier, gold_LecTrackGoalAreaClassifier)\n",
    "\n",
    "            loss = loss_LecTrackMethodClassifier + \\\n",
    "                    loss_LecTrackRequestedClassifier + \\\n",
    "                    loss_LecTrackGoalFoodClassifier + \\\n",
    "                    loss_LecTrackGoalPricerangeClassifier + \\\n",
    "                    loss_LecTrackGoalNameClassifier + \\\n",
    "                    loss_LecTrackGoalAreaClassifier\n",
    "            loss.backward(retain_graph = True)\n",
    "            \n",
    "            train_epoch_loss += loss\n",
    "\n",
    "            optimizer_LecTrackEncoder.step()\n",
    "            optimizer_LecTrackMethodClassifier.step()\n",
    "            optimizer_LecTrackRequestedClassifier.step()\n",
    "            optimizer_LecTrackGoalFoodClassifier.step()\n",
    "            optimizer_LecTrackGoalPricerangeClassifier.step()\n",
    "            optimizer_LecTrackGoalNameClassifier.step()\n",
    "            optimizer_LecTrackGoalAreaClassifier.step()\n",
    "    \n",
    "    train_epoch_losses.append(train_epoch_loss.item())\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        dev_epoch_loss = 0\n",
    "        \n",
    "        for raw_X_dev_dialog, raw_Y_dev_dialog in tqdm(zip(raw_X_dev, raw_Y_dev), total = len(raw_X_dev)):\n",
    "            \n",
    "            for raw_X_dev_turn, raw_Y_dev_turn in zip(raw_X_dev_dialog[\"turns\"], raw_Y_dev_dialog[\"turns\"]):\n",
    "                \n",
    "                indexes, scores = get_index_and_score(raw_X_dev_turn, token_to_index, device = DEVICE)\n",
    "                \n",
    "                output_LecTrackEncoder = model_LecTrackEncoder(indexes, scores)\n",
    "                output_LecTrackMethodClassifier = model_LecTrackMethodClassifier(output_LecTrackEncoder[0])\n",
    "                output_LecTrackRequestedClassifier = model_LecTrackRequestedClassifier(output_LecTrackEncoder[0])\n",
    "                output_LecTrackGoalFoodClassifier = model_LecTrackGoalFoodClassifier(output_LecTrackEncoder[0])\n",
    "                output_LecTrackGoalPricerangeClassifier = model_LecTrackGoalPricerangeClassifier(output_LecTrackEncoder[0])\n",
    "                output_LecTrackGoalNameClassifier = model_LecTrackGoalNameClassifier(output_LecTrackEncoder[0])\n",
    "                output_LecTrackGoalAreaClassifier = model_LecTrackGoalAreaClassifier(output_LecTrackEncoder[0])\n",
    "                \n",
    "                gold_LecTrackMethodClassifier = retrieve_gold_Method(raw_Y_dev_turn, ontology, device = DEVICE)\n",
    "                gold_LecTrackRequestedClassifier = retrieve_gold_Requested(raw_Y_dev_turn, ontology, device = DEVICE)\n",
    "                gold_LecTrackGoalFoodClassifier = retrieve_gold_GoalFood(raw_Y_dev_turn, ontology, device = DEVICE)\n",
    "                gold_LecTrackGoalPricerangeClassifier = retrieve_gold_GoalPriceRange(raw_Y_dev_turn, ontology, device = DEVICE)\n",
    "                gold_LecTrackGoalNameClassifier = retrieve_gold_GoalName(raw_Y_dev_turn, ontology, device = DEVICE)\n",
    "                gold_LecTrackGoalAreaClassifier = retrieve_gold_GoalArea(raw_Y_dev_turn, ontology, device = DEVICE)\n",
    "\n",
    "                loss_LecTrackMethodClassifier = loss_function(output_LecTrackMethodClassifier, gold_LecTrackMethodClassifier)\n",
    "                loss_LecTrackRequestedClassifier = loss_function(output_LecTrackRequestedClassifier, gold_LecTrackRequestedClassifier)\n",
    "                loss_LecTrackGoalFoodClassifier = loss_function(output_LecTrackGoalFoodClassifier, gold_LecTrackGoalFoodClassifier)\n",
    "                loss_LecTrackGoalPricerangeClassifier = loss_function(output_LecTrackGoalPricerangeClassifier, gold_LecTrackGoalPricerangeClassifier)\n",
    "                loss_LecTrackGoalNameClassifier = loss_function(output_LecTrackGoalNameClassifier, gold_LecTrackGoalNameClassifier)\n",
    "                loss_LecTrackGoalAreaClassifier = loss_function(output_LecTrackGoalAreaClassifier, gold_LecTrackGoalAreaClassifier)\n",
    "                \n",
    "                loss = loss_LecTrackMethodClassifier + \\\n",
    "                        loss_LecTrackRequestedClassifier + \\\n",
    "                        loss_LecTrackGoalFoodClassifier + \\\n",
    "                        loss_LecTrackGoalPricerangeClassifier + \\\n",
    "                        loss_LecTrackGoalNameClassifier + \\\n",
    "                        loss_LecTrackGoalAreaClassifier\n",
    "                \n",
    "                dev_epoch_loss += loss\n",
    "                \n",
    "        dev_epoch_losses.append(dev_epoch_loss.item())\n",
    "            \n",
    "    logging.info(\"Epoch train loss\\t{} \\tdev loss\\t{}\".format(train_epoch_loss, dev_epoch_loss))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "marker": {
          "color": "#1abc9c"
         },
         "mode": "lines+markers",
         "name": "train loss",
         "type": "scatter",
         "uid": "f76cc929-97d2-4019-8855-6c465efa4164",
         "x": [
          0,
          1,
          2
         ],
         "y": [
          132222.25,
          68159.109375,
          44988.734375
         ]
        },
        {
         "marker": {
          "color": "#3498db"
         },
         "mode": "lines+markers",
         "name": "dev loss",
         "type": "scatter",
         "uid": "d7df4fd0-b6a6-4029-98e4-99d8aea722b0",
         "x": [
          0,
          1,
          2
         ],
         "y": [
          31473.98828125,
          32299.166015625,
          27455.037109375
         ]
        }
       ],
       "layout": {
        "margin": {
         "b": 150
        },
        "title": "<b>Train-Dev loss</b>",
        "xaxis": {
         "dtick": 1,
         "title": "<b>Epoch</b>",
         "titlefont": {
          "color": "#34495e"
         }
        },
        "yaxis": {
         "title": "<b>Loss</b>",
         "titlefont": {
          "color": "#34495e"
         }
        }
       }
      },
      "text/html": [
       "<div id=\"f84a13b7-3f12-4243-86c8-d7dff494213e\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"f84a13b7-3f12-4243-86c8-d7dff494213e\", [{\"marker\": {\"color\": \"#1abc9c\"}, \"mode\": \"lines+markers\", \"name\": \"train loss\", \"x\": [0, 1, 2], \"y\": [132222.25, 68159.109375, 44988.734375], \"type\": \"scatter\", \"uid\": \"7bd36ccd-e7d8-4a6b-acbc-efd069bdd562\"}, {\"marker\": {\"color\": \"#3498db\"}, \"mode\": \"lines+markers\", \"name\": \"dev loss\", \"x\": [0, 1, 2], \"y\": [31473.98828125, 32299.166015625, 27455.037109375], \"type\": \"scatter\", \"uid\": \"1ce4726f-177e-4896-944f-88dc10515e25\"}], {\"margin\": {\"b\": 150}, \"title\": \"<b>Train-Dev loss</b>\", \"xaxis\": {\"dtick\": 1, \"title\": \"<b>Epoch</b>\", \"titlefont\": {\"color\": \"#34495e\"}}, \"yaxis\": {\"title\": \"<b>Loss</b>\", \"titlefont\": {\"color\": \"#34495e\"}}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"f84a13b7-3f12-4243-86c8-d7dff494213e\"));});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"f84a13b7-3f12-4243-86c8-d7dff494213e\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"f84a13b7-3f12-4243-86c8-d7dff494213e\", [{\"marker\": {\"color\": \"#1abc9c\"}, \"mode\": \"lines+markers\", \"name\": \"train loss\", \"x\": [0, 1, 2], \"y\": [132222.25, 68159.109375, 44988.734375], \"type\": \"scatter\", \"uid\": \"7bd36ccd-e7d8-4a6b-acbc-efd069bdd562\"}, {\"marker\": {\"color\": \"#3498db\"}, \"mode\": \"lines+markers\", \"name\": \"dev loss\", \"x\": [0, 1, 2], \"y\": [31473.98828125, 32299.166015625, 27455.037109375], \"type\": \"scatter\", \"uid\": \"1ce4726f-177e-4896-944f-88dc10515e25\"}], {\"margin\": {\"b\": 150}, \"title\": \"<b>Train-Dev loss</b>\", \"xaxis\": {\"dtick\": 1, \"title\": \"<b>Epoch</b>\", \"titlefont\": {\"color\": \"#34495e\"}}, \"yaxis\": {\"title\": \"<b>Loss</b>\", \"titlefont\": {\"color\": \"#34495e\"}}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"f84a13b7-3f12-4243-86c8-d7dff494213e\"));});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotly.offline.iplot({\n",
    "    \"data\": [Scatter(\n",
    "                x = list(range(len(train_epoch_losses))),\n",
    "                y = train_epoch_losses,\n",
    "                mode = \"lines+markers\",\n",
    "                name = \"train loss\",\n",
    "                marker = dict(color = \"#1abc9c\")),\n",
    "            Scatter(\n",
    "                x = list(range(len(dev_epoch_losses))),\n",
    "                y = dev_epoch_losses,\n",
    "                mode = \"lines+markers\",\n",
    "                name = \"dev loss\",\n",
    "                marker = dict(color = \"#3498db\"))],\n",
    "    \"layout\": Layout(title = \"<b>Train-Dev Loss</b>\",\n",
    "                     xaxis = dict(title = \"<b>Epoch</b>\", dtick = 1, titlefont = dict(color = \"#34495e\")),\n",
    "                     yaxis = dict(title = \"<b>Loss</b>\", titlefont = dict(color = \"#34495e\")),\n",
    "                     margin = Margin(b = 150)\n",
    "                    )\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_bin = lambda x, n: format(x, \"b\").zfill(n)\n",
    "\n",
    "def retrieve_output_Method(output_tensor):\n",
    "    output_tensor = output_tensor.view(-1)\n",
    "    output_tensor = torch.exp(output_tensor)\n",
    "    method_dict = {}\n",
    "    \n",
    "    index = torch.argmax(output_tensor).item()\n",
    "    method_dict[ontology[\"method\"][index]] = output_tensor[index].item()\n",
    "    \n",
    "    #for index in range(len(output_tensor)):\n",
    "    #    method_dict[ontology[\"method\"][index]] = output_tensor[index].item()\n",
    "    \n",
    "    return method_dict\n",
    "\n",
    "def retrieve_output_Requested(output_tensor):\n",
    "    output_tensor = output_tensor.view(-1)\n",
    "    output_tensor = torch.exp(output_tensor)\n",
    "    requested_dict = {}\n",
    "    binary_representation = get_bin(torch.argmax(output_tensor).item(), len(ontology[\"requestable\"]))\n",
    "    indexes = []\n",
    "    index = 0\n",
    "    for value in binary_representation:\n",
    "        if int(value) == 1:\n",
    "            indexes.append(index)\n",
    "        index += 1\n",
    "    for index in indexes:\n",
    "        requested_dict[ontology[\"requestable\"][index]] = (1 / len(indexes))\n",
    "    return requested_dict\n",
    "\n",
    "def retrieve_output_GoalFood(output_tensor):\n",
    "    output_tensor = output_tensor.view(-1)\n",
    "    output_tensor = torch.exp(output_tensor)\n",
    "    goal_food_dict = {}\n",
    "    \n",
    "    index = torch.argmax(output_tensor).item()\n",
    "    if index != 0:\n",
    "        if index == 1:\n",
    "            goal_food_dict[\"dontcare\"] = output_tensor[index].item() \n",
    "        else:\n",
    "            goal_food_dict[ontology[\"informable\"][\"food\"][index - 2]] = output_tensor[index].item()\n",
    "        \n",
    "    #if torch.argmax(output_tensor).item() != 0:\n",
    "    #    goal_food_dict[\"dontcare\"] = output_tensor[1].item()\n",
    "    #    for index in range(2, len(output_tensor)):\n",
    "    #        goal_food_dict[ontology[\"informable\"][\"food\"][index - 2]] = output_tensor[index].item()\n",
    "    \n",
    "    return goal_food_dict\n",
    "\n",
    "def retrieve_output_GoalPricerange(output_tensor):\n",
    "    output_tensor = output_tensor.view(-1)\n",
    "    output_tensor = torch.exp(output_tensor)\n",
    "    goal_pricerange_dict = {}\n",
    "    \n",
    "    index = torch.argmax(output_tensor).item()\n",
    "    if index != 0:\n",
    "        if index == 1:\n",
    "            goal_pricerange_dict[\"dontcare\"] = output_tensor[index].item()\n",
    "        else:     \n",
    "            goal_pricerange_dict[ontology[\"informable\"][\"pricerange\"][index - 2]] = output_tensor[index].item()\n",
    "        \n",
    "    #if torch.argmax(output_tensor).item() != 0:\n",
    "    #    goal_pricerange_dict[\"dontcare\"] = output_tensor[1].item()\n",
    "    #    for index in range(2, len(output_tensor)):\n",
    "    #        goal_pricerange_dict[ontology[\"informable\"][\"pricerange\"][index - 2]] = output_tensor[index].item()\n",
    "    \n",
    "    return goal_pricerange_dict\n",
    "\n",
    "def retrieve_output_GoalName(output_tensor):\n",
    "    output_tensor = output_tensor.view(-1)\n",
    "    output_tensor = torch.exp(output_tensor)\n",
    "    goal_name_dict = {}\n",
    "    \n",
    "    index = torch.argmax(output_tensor).item()\n",
    "    if index != 0:\n",
    "        if index == 1:\n",
    "            goal_name_dict[\"dontcare\"] = output_tensor[index].item()\n",
    "        else:    \n",
    "            goal_name_dict[ontology[\"informable\"][\"name\"][index - 2]] = output_tensor[index].item()\n",
    "        \n",
    "    #if torch.argmax(output_tensor).item() != 0:\n",
    "    #    goal_name_dict[\"dontcare\"] = output_tensor[1].item()\n",
    "    #    for index in range(2, len(output_tensor)):\n",
    "    #        goal_name_dict[ontology[\"informable\"][\"name\"][index - 2]] = output_tensor[index].item()\n",
    "    \n",
    "    return goal_name_dict\n",
    "\n",
    "def retrieve_output_GoalArea(output_tensor):\n",
    "    output_tensor = output_tensor.view(-1)\n",
    "    output_tensor = torch.exp(output_tensor)\n",
    "    goal_area_dict = {}\n",
    "    \n",
    "    index = torch.argmax(output_tensor).item()\n",
    "    if index != 0:\n",
    "        if index == 1:\n",
    "            goal_area_dict[\"dontcare\"] = output_tensor[index].item()\n",
    "        else:\n",
    "            goal_area_dict[ontology[\"informable\"][\"area\"][index - 2]] = output_tensor[index].item()\n",
    "        \n",
    "    #if torch.argmax(output_tensor).item() != 0:\n",
    "    #    goal_area_dict[\"dontcare\"] = output_tensor[1].item()\n",
    "    #    for index in range(2, len(output_tensor)):\n",
    "    #        goal_area_dict[ontology[\"informable\"][\"area\"][index - 2]] = output_tensor[index].item()\n",
    "    \n",
    "    return goal_area_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tracker(raw_X, raw_Y, dataset):\n",
    "    with torch.no_grad():\n",
    "        tracker_json = {}\n",
    "        tracker_json[\"dataset\"] = dataset\n",
    "        tracker_json[\"sessions\"] = []\n",
    "\n",
    "        start_time = time.time()\n",
    "        for raw_X_dialog, raw_Y_dialog in tqdm(zip(raw_X, raw_Y), total = len(raw_X)):\n",
    "\n",
    "            session = {}\n",
    "            session[\"session-id\"] = raw_X_dialog[\"session-id\"]\n",
    "            session[\"turns\"] = []\n",
    "\n",
    "            for raw_X_turn, raw_Y_turn in zip(raw_X_dialog[\"turns\"], raw_Y_dialog[\"turns\"]):\n",
    "                turn = {}\n",
    "                turn[\"goal-labels\"] = {}\n",
    "\n",
    "                indexes, scores = get_index_and_score(raw_X_turn, token_to_index, device = DEVICE)\n",
    "\n",
    "                output_LecTrackEncoder = model_LecTrackEncoder(indexes, scores)\n",
    "\n",
    "                output_LecTrackMethodClassifier = model_LecTrackMethodClassifier(output_LecTrackEncoder[0])\n",
    "                turn[\"method-label\"] = retrieve_output_Method(output_LecTrackMethodClassifier)\n",
    "\n",
    "                output_LecTrackRequestedClassifier = model_LecTrackRequestedClassifier(output_LecTrackEncoder[0])\n",
    "                if torch.argmax(output_LecTrackRequestedClassifier).item() == 0:\n",
    "                    turn[\"requested-slots\"] = {}\n",
    "                else:\n",
    "                    turn[\"requested-slots\"] = retrieve_output_Requested(output_LecTrackRequestedClassifier)\n",
    "\n",
    "                output_LecTrackGoalFoodClassifier = model_LecTrackGoalFoodClassifier(output_LecTrackEncoder[0])\n",
    "                if torch.argmax(output_LecTrackGoalFoodClassifier).item() != 0:\n",
    "                    turn[\"goal-labels\"][\"food\"] = retrieve_output_GoalFood(output_LecTrackGoalFoodClassifier)\n",
    "\n",
    "                output_LecTrackGoalPricerangeClassifier = model_LecTrackGoalPricerangeClassifier(output_LecTrackEncoder[0])\n",
    "                if torch.argmax(output_LecTrackGoalPricerangeClassifier).item() != 0:\n",
    "                    turn[\"goal-labels\"][\"pricerange\"] = retrieve_output_GoalPricerange(output_LecTrackGoalPricerangeClassifier)\n",
    "\n",
    "                output_LecTrackGoalNameClassifier = model_LecTrackGoalNameClassifier(output_LecTrackEncoder[0])\n",
    "                if torch.argmax(output_LecTrackGoalNameClassifier).item() != 0:\n",
    "                    turn[\"goal-labels\"][\"name\"] = retrieve_output_GoalName(output_LecTrackGoalNameClassifier)\n",
    "\n",
    "                output_LecTrackGoalAreaClassifier = model_LecTrackGoalAreaClassifier(output_LecTrackEncoder[0])\n",
    "                if torch.argmax(output_LecTrackGoalAreaClassifier).item() != 0:\n",
    "                    turn[\"goal-labels\"][\"area\"] = retrieve_output_GoalArea(output_LecTrackGoalAreaClassifier)\n",
    "\n",
    "                session[\"turns\"].append(turn)\n",
    "            tracker_json[\"sessions\"].append(session)\n",
    "        end_time = time.time()\n",
    "        tracker_json[\"wall-time\"] = end_time - start_time\n",
    "        return tracker_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_tracker = make_tracker(raw_X_dev, raw_Y_dev, dataset = \"dstc2_dev\")\n",
    "\n",
    "with open(\"dev_tracker.json\", \"w\") as dev_tracker_file:\n",
    "    json.dump(dev_tracker, dev_tracker_file)\n",
    "\n",
    "!python2 dstc2/dstc2_scripts/score.py\\\n",
    "--dataset dstc2_dev\\\n",
    "--dataroot dstc2/dstc2_traindev/data\\\n",
    "--ontology dstc2/dstc2_scripts/config/ontology_dstc2.json\\\n",
    "--trackfile dev_tracker.json\\\n",
    "--scorefile dev_tracker.score.csv\n",
    "\n",
    "!python2 dstc2/dstc2_scripts/report.py --scorefile dev_tracker.score.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
