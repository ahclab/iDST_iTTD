{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check GPU availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jan  8 16:14:10 2019       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 384.145                Driver Version: 384.145                   |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:02:00.0 Off |                  N/A |\r\n",
      "| 23%   33C    P8    17W / 250W |      0MiB / 11172MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:03:00.0 Off |                  N/A |\r\n",
      "| 23%   31C    P8    17W / 250W |      0MiB / 11172MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/is/andrei-\n",
      "[nltk_data]     cc/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import plotly\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "from idst_util import trivial\n",
    "from idst_util import dstc2\n",
    "\n",
    "from plotly.graph_objs import Scatter, Layout\n",
    "from plotly.graph_objs.layout import Margin\n",
    "plotly.offline.init_notebook_mode(connected = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check DSTC2 availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:+--------------------------------+\n",
      "INFO:root:|         _ ____  ___________    |\n",
      "INFO:root:|        (_) __ \\/ ___/_  __/    |\n",
      "INFO:root:|       / / / / /\\__ \\ / /       |\n",
      "INFO:root:|      / / /_/ /___/ // /        |\n",
      "INFO:root:|     /_/_____//____//_/         |\n",
      "INFO:root:|                                |\n",
      "INFO:root:+--------------------------------+\n",
      "INFO:root:|Incremental Dialog State Tracker|\n",
      "INFO:root:+--------------------------------+\n",
      "INFO:root:+--------------------------------+\n",
      "INFO:root:|     Dialog State Tracker 2     |\n",
      "INFO:root:|         Data Checker           |\n",
      "INFO:root:+--------------------------------+\n",
      "INFO:root:Looking for dstc2 directory in .\n",
      "INFO:root:dstc2 was found!\n",
      "INFO:root:Looking for dstc2_traindev directory in ./dstc2\n",
      "INFO:root:dstc2_traindev was found!\n",
      "INFO:root:Looking for dstc2_test directory in ./dstc2\n",
      "INFO:root:dstc2_test was found!\n",
      "INFO:root:Looking for dstc2_scripts directory in ./dstc2\n",
      "INFO:root:dstc2_scripts was found!\n",
      "INFO:root:Done!\n"
     ]
    }
   ],
   "source": [
    "trivial.print_idst()\n",
    "dstc2.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:+--------------------------------+\n",
      "INFO:root:|     Dialog State Tracker 2     |\n",
      "INFO:root:|       Dataset Retrieval        |\n",
      "INFO:root:+--------------------------------+\n",
      "INFO:root:Reading dstc2_train.flist, dstc2_dev.flist and ontology_dstc2.json\n",
      "INFO:root:Asserted 1612 dialogs for dstc2_train.flist\n",
      "INFO:root:Asserted 506 dialogs for dstc2_dev.flist\n",
      "INFO:root:Extracting raw train features\n",
      "100%|██████████| 1612/1612 [00:11<00:00, 145.25it/s]\n",
      "INFO:root:Extracting raw dev features\n",
      "100%|██████████| 506/506 [00:02<00:00, 168.86it/s]\n",
      "INFO:root:Reading dstc2_test.flist\n",
      "INFO:root:Asserted 1117 dialogs for dstc2_test.flist\n",
      "INFO:root:Extracting raw test features\n",
      "100%|██████████| 1117/1117 [00:07<00:00, 147.12it/s]\n"
     ]
    }
   ],
   "source": [
    "raw_X_train, raw_Y_train, \\\n",
    "raw_X_dev, raw_Y_dev, \\\n",
    "raw_X_test, raw_Y_test, \\\n",
    "ontology = dstc2.retrieve_raw_datasets(train_data_augmentation = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:+--------------------------------+\n",
      "INFO:root:|            Baseline            |\n",
      "INFO:root:+--------------------------------+\n",
      "INFO:root:Running on GPU 0\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"+--------------------------------+\")\n",
    "logging.info(\"|            Baseline            |\")\n",
    "logging.info(\"+--------------------------------+\")\n",
    "\n",
    "GPU_ID = 0\n",
    "DEVICE = torch.device(\"cuda:{}\".format(GPU_ID) if torch.cuda.is_available() else \"cpu\")\n",
    "#DEVICE = \"cpu\"\n",
    "if DEVICE == \"cpu\":\n",
    "    logging.warning(\"Running on CPU\")\n",
    "else:\n",
    "    logging.info(\"Running on GPU {}\".format(GPU_ID))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create vocabularies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:+--------------------------------+\n",
      "INFO:root:|          Vocabulary            |\n",
      "INFO:root:+--------------------------------+\n",
      "INFO:root:Creating token_to_index, index_to_token and token_to_count dictionaries\n",
      "100%|██████████| 3224/3224 [00:00<00:00, 34257.00it/s]\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"+--------------------------------+\")\n",
    "logging.info(\"|          Vocabulary            |\")\n",
    "logging.info(\"+--------------------------------+\")\n",
    "logging.info(\"Creating token_to_index, index_to_token and token_to_count dictionaries\")\n",
    "\n",
    "token_to_index = {\"<unk>\": 0}\n",
    "index_to_token = {0: \"<unk>\"}\n",
    "token_to_count = {\"<unk>\": 1}\n",
    "\n",
    "for raw_train_dialog in tqdm(raw_X_train):\n",
    "    \n",
    "    for raw_train_turn in raw_train_dialog[\"turns\"]:\n",
    "        \n",
    "        tokens_scores = raw_train_turn[\"system\"] + raw_train_turn[\"user\"]\n",
    "        \n",
    "        for token_score in tokens_scores:\n",
    "            token = token_score[0]\n",
    "            if token not in token_to_index:\n",
    "                token_to_index[token] = len(token_to_index)\n",
    "                index_to_token[len(token_to_index)] = token\n",
    "                token_to_count[token] = 1\n",
    "            else:\n",
    "                token_to_count[token] += 1\n",
    "                \n",
    "assert len(token_to_index) == len(index_to_token)\n",
    "assert len(token_to_index) == len(token_to_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:+--------------------------------+\n",
      "INFO:root:|         Configuration          |\n",
      "INFO:root:+--------------------------------+\n",
      "INFO:root:VOCABULARY_SIZE:\t\t1149\n",
      "INFO:root:GOAL_FOOD_DIM:\t\t93\n",
      "INFO:root:GOAL_PRICERANGE_DIM:\t\t5\n",
      "INFO:root:GOAL_NAME_DIM:\t\t115\n",
      "INFO:root:GOAL_AREA_DIM:\t\t7\n",
      "INFO:root:METHOD_DIM:\t\t\t5\n",
      "INFO:root:REQUESTED_DIM:\t\t8\n",
      "INFO:root:EMBEDDING_DIM:\t\t170\n",
      "INFO:root:ALTERED_EMBEDDING_DIM:\t300\n",
      "INFO:root:HIDDEN_DIM:\t\t\t100\n",
      "INFO:root:NUM_EPOCHS:\t\t\t30\n",
      "INFO:root:GOAL_LOSS_FUNCTION:\t\tCrossEntropyLoss()\n",
      "INFO:root:METHOD_LOSS_FUNCTION:\t\tCrossEntropyLoss()\n",
      "INFO:root:REQUESTED_LOSS_FUNCTION:\tBCELoss()\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"+--------------------------------+\")\n",
    "logging.info(\"|         Configuration          |\")\n",
    "logging.info(\"+--------------------------------+\")\n",
    "\n",
    "VOCABULARY_SIZE = len(token_to_index)\n",
    "logging.info(\"VOCABULARY_SIZE:\\t\\t{}\".format(VOCABULARY_SIZE))\n",
    "\n",
    "# NOTE: +2 because of null and dontcare\n",
    "GOAL_FOOD_DIM = len(ontology[\"informable\"][\"food\"]) + 2 \n",
    "GOAL_PRICERANGE_DIM = len(ontology[\"informable\"][\"pricerange\"]) + 2\n",
    "GOAL_NAME_DIM = len(ontology[\"informable\"][\"name\"]) + 2\n",
    "GOAL_AREA_DIM = len(ontology[\"informable\"][\"area\"]) + 2\n",
    "METHOD_DIM = len(ontology[\"method\"])\n",
    "REQUESTED_DIM = len(ontology[\"requestable\"])\n",
    "EMBEDDING_DIM = 170\n",
    "ALTERED_EMBEDDING_DIM = 300\n",
    "HIDDEN_DIM = 100\n",
    "NUM_EPOCHS = 30\n",
    "GOAL_LOSS_FUNCTION = nn.CrossEntropyLoss()\n",
    "METHOD_LOSS_FUNCTION = nn.CrossEntropyLoss()\n",
    "REQUESTED_LOSS_FUNCTION = nn.BCELoss()\n",
    "logging.info(\"GOAL_FOOD_DIM:\\t\\t{}\".format(GOAL_FOOD_DIM))\n",
    "logging.info(\"GOAL_PRICERANGE_DIM:\\t\\t{}\".format(GOAL_PRICERANGE_DIM))\n",
    "logging.info(\"GOAL_NAME_DIM:\\t\\t{}\".format(GOAL_NAME_DIM))\n",
    "logging.info(\"GOAL_AREA_DIM:\\t\\t{}\".format(GOAL_AREA_DIM))\n",
    "logging.info(\"METHOD_DIM:\\t\\t\\t{}\".format(METHOD_DIM))\n",
    "logging.info(\"REQUESTED_DIM:\\t\\t{}\".format(REQUESTED_DIM))\n",
    "logging.info(\"EMBEDDING_DIM:\\t\\t{}\".format(EMBEDDING_DIM))\n",
    "logging.info(\"ALTERED_EMBEDDING_DIM:\\t{}\".format(ALTERED_EMBEDDING_DIM))\n",
    "logging.info(\"HIDDEN_DIM:\\t\\t\\t{}\".format(HIDDEN_DIM))\n",
    "logging.info(\"NUM_EPOCHS:\\t\\t\\t{}\".format(NUM_EPOCHS))\n",
    "logging.info(\"GOAL_LOSS_FUNCTION:\\t\\t{}\".format(GOAL_LOSS_FUNCTION))\n",
    "logging.info(\"METHOD_LOSS_FUNCTION:\\t\\t{}\".format(METHOD_LOSS_FUNCTION))\n",
    "logging.info(\"REQUESTED_LOSS_FUNCTION:\\t{}\".format(REQUESTED_LOSS_FUNCTION))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_and_score(turn, token_to_index, mode, device):\n",
    "    indices = []\n",
    "    scores = []\n",
    "    if mode == \"train\":\n",
    "        for system_token, system_token_score in turn[\"system\"]:\n",
    "            indices.append(token_to_index[system_token])\n",
    "            scores.append(system_token_score)\n",
    "        for user_token, user_token_score in turn[\"user\"]:\n",
    "            if np.random.binomial(n = 1, p = 0.1) == 1:\n",
    "                indices.append(token_to_index[\"<unk>\"])\n",
    "            else:\n",
    "                indices.append(token_to_index[user_token])\n",
    "            scores.append(user_token_score)\n",
    "    else:\n",
    "        tokens_scores = turn[\"system\"] + turn[\"user\"]\n",
    "        for token, score in tokens_scores:\n",
    "            if token not in token_to_index:\n",
    "                indices.append(token_to_index[\"<unk>\"])\n",
    "            else:\n",
    "                indices.append(token_to_index[token])\n",
    "            scores.append(score)\n",
    "    assert len(indices) == len(scores)\n",
    "    return torch.tensor(indices, dtype = torch.long, device = device), torch.tensor(scores, dtype = torch.float, device = device)\n",
    "\n",
    "def plotly_plot(dev_accuracies, test_accuracies, accuracy_type):\n",
    "    plotly.offline.iplot({\n",
    "                            \"data\": [Scatter(\n",
    "                                            x = list(range(len(dev_accuracies))),\n",
    "                                            y = dev_accuracies,\n",
    "                                            mode = \"lines+markers\",\n",
    "                                            name = \"Dev {} Accuracy\".format(accuracy_type),\n",
    "                                            marker = dict(color = \"#3498db\")),\n",
    "                                    Scatter(\n",
    "                                            x = list(range(len(test_accuracies))),\n",
    "                                            y = test_accuracies,\n",
    "                                            mode = \"lines+markers\",\n",
    "                                            name = \"Test {} Accuracy\".format(accuracy_type),\n",
    "                                            marker = dict(color = \"#9b59b6\"))],\n",
    "                            \"layout\": Layout(\n",
    "                                             title = \"<b>Dev-Test {} Accuracy</b>\".format(accuracy_type),\n",
    "                                             xaxis = dict(title = \"<b>Epoch</b>\",\n",
    "                                                          dtick = 1,\n",
    "                                                          titlefont = dict(color = \"#34495e\")),\n",
    "                                             yaxis = dict(title = \"<b>Accuracy</b>\",\n",
    "                                                          titlefont = dict(color = \"#34495e\")),\n",
    "                                             margin = Margin(b = 150))\n",
    "                        })\n",
    "\n",
    "class EarlyStopping():\n",
    "    \n",
    "    def __init__(self, min_delta = 0, patience = 1):\n",
    "        \n",
    "        self.min_delta = min_delta\n",
    "        self.patience = patience\n",
    "        self.wait = 0\n",
    "        self.stopped_epoch = 0\n",
    "        self.best = -np.Inf\n",
    "        self.stop_training = False\n",
    "    \n",
    "    def on_epoch_end(self, epoch, current_value):\n",
    "        if np.greater((current_value - self.min_delta), self.best):\n",
    "            self.best = current_value\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait > self.patience:\n",
    "                self.stopped_epoch = epoch\n",
    "                self.stop_training = True\n",
    "        return self.stop_training\n",
    "\n",
    "get_bin = lambda x, n: format(x, \"b\").zfill(n)\n",
    "\n",
    "def make_tracker(model_All, raw_X, raw_Y, dataset):\n",
    "    \n",
    "    model_All = model_All.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        tracker_json = {}\n",
    "        tracker_json[\"dataset\"] = dataset\n",
    "        tracker_json[\"sessions\"] = []\n",
    "\n",
    "        start_time = time.time()\n",
    "        for raw_X_dialog, raw_Y_dialog in tqdm(zip(raw_X, raw_Y), total = len(raw_X)):\n",
    "            \n",
    "            model_All.hidden = model_All.init_hidden()\n",
    "            \n",
    "            session = {}\n",
    "            session[\"session-id\"] = raw_X_dialog[\"session-id\"]\n",
    "            session[\"turns\"] = []\n",
    "\n",
    "            for raw_X_turn, raw_Y_turn in zip(raw_X_dialog[\"turns\"], raw_Y_dialog[\"turns\"]):\n",
    "                turn = {}\n",
    "                turn[\"goal-labels\"] = {}\n",
    "\n",
    "                indices, scores = get_index_and_score(raw_X_turn, token_to_index, mode = \"eval\", device = DEVICE)\n",
    "                \n",
    "                goal_food, goal_pricerange, goal_name, goal_area, method, requested = model_All(indices, scores)\n",
    "                turn[\"goal-labels\"][\"food\"] = retrieve_output_GoalFood(goal_food, ontology)\n",
    "                turn[\"goal-labels\"][\"pricerange\"] = retrieve_output_GoalPricerange(goal_pricerange, ontology)\n",
    "                turn[\"goal-labels\"][\"name\"] = retrieve_output_GoalName(goal_name, ontology)\n",
    "                turn[\"goal-labels\"][\"area\"] = retrieve_output_GoalArea(goal_area, ontology)\n",
    "                turn[\"requested-slots\"] = retrieve_output_Requested(requested, ontology)\n",
    "                turn[\"method-label\"] = retrieve_output_Method(method, ontology)\n",
    "                \n",
    "                session[\"turns\"].append(turn)\n",
    "            tracker_json[\"sessions\"].append(session)\n",
    "        end_time = time.time()\n",
    "        tracker_json[\"wall-time\"] = end_time - start_time\n",
    "        \n",
    "        return tracker_json\n",
    "\n",
    "def get_scores(model_All, raw_X, raw_Y, dataset):\n",
    "    goal_accuracy = 0\n",
    "    goal_l2 = 0\n",
    "    requested_accuracy = 0\n",
    "    requested_l2 = 0\n",
    "    method_accuracy = 0\n",
    "    method_l2 = 0\n",
    "    \n",
    "    tracker = make_tracker(model_All, raw_X, raw_Y, dataset = dataset)\n",
    "    \n",
    "    with open(\"tracker_all.json\", \"w\") as tracker_file:\n",
    "        json.dump(tracker, tracker_file)\n",
    "    \n",
    "    if dataset == \"dstc2_train\":\n",
    "        !python2 dstc2/dstc2_scripts/score.py\\\n",
    "        --dataset dstc2_train\\\n",
    "        --dataroot dstc2/dstc2_traindev/data\\\n",
    "        --ontology dstc2/dstc2_scripts/config/ontology_dstc2.json\\\n",
    "        --trackfile tracker_all.json\\\n",
    "        --scorefile tracker_all.score.csv\n",
    "    elif dataset == \"dstc2_dev\":\n",
    "        !python2 dstc2/dstc2_scripts/score.py\\\n",
    "        --dataset dstc2_dev\\\n",
    "        --dataroot dstc2/dstc2_traindev/data\\\n",
    "        --ontology dstc2/dstc2_scripts/config/ontology_dstc2.json\\\n",
    "        --trackfile tracker_all.json\\\n",
    "        --scorefile tracker_all.score.csv\n",
    "    else:\n",
    "        !python2 dstc2/dstc2_scripts/score.py\\\n",
    "        --dataset dstc2_test\\\n",
    "        --dataroot dstc2/dstc2_test/data\\\n",
    "        --ontology dstc2/dstc2_scripts/config/ontology_dstc2.json\\\n",
    "        --trackfile tracker_all.json\\\n",
    "        --scorefile tracker_all.score.csv\n",
    "\n",
    "    file_cat = !python2 dstc2/dstc2_scripts/report.py --scorefile tracker_all.score.csv\n",
    "    \n",
    "    found_accuracies = False\n",
    "    for line in file_cat:\n",
    "        if line.startswith(\"Accuracy\"):\n",
    "            accuracies = line.split(\"|\")\n",
    "            goal_accuracy = float(accuracies[1])\n",
    "            requested_accuracy = float(accuracies[2])\n",
    "            method_accuracy = float(accuracies[3])\n",
    "            found_accuracies = True\n",
    "        if found_accuracies and line.startswith(\"l2\"):\n",
    "            l2s = line.split(\"|\")\n",
    "            goal_l2 = float(l2s[1])\n",
    "            method_l2 = float(l2s[2])\n",
    "            requested_l2 = float(l2s[3])\n",
    "    \n",
    "    return goal_accuracy, goal_l2, requested_accuracy, requested_l2, method_accuracy, method_l2\n",
    "\n",
    "def retrieve_gold_GoalFood(raw_Y, ontology, device):\n",
    "    ontology_informable_food = ontology[\"informable\"][\"food\"]\n",
    "    raw_goal_food = raw_Y[\"goal\"][\"food\"]\n",
    "    goal_food = 0\n",
    "    if raw_goal_food != None:\n",
    "        if raw_goal_food == \"dontcare\":\n",
    "            goal_food = 1\n",
    "        else:    \n",
    "            goal_food = ontology_informable_food.index(raw_goal_food) + 2\n",
    "    return torch.tensor([goal_food], dtype = torch.long, device = device)\n",
    "\n",
    "def retrieve_output_GoalFood(output_tensor, ontology):\n",
    "    ontology_informable_food = ontology[\"informable\"][\"food\"]\n",
    "    output_tensor = output_tensor.view(-1)\n",
    "    output_tensor = torch.exp(output_tensor)\n",
    "    goal_food_dict = {}\n",
    "    \n",
    "    index = torch.argmax(output_tensor).item()\n",
    "    if index != 0:\n",
    "        goal_food_dict[\"dontcare\"] = output_tensor[1].item() \n",
    "        for index in range(len(output_tensor) - 2):\n",
    "            goal_food_dict[ontology_informable_food[index]] = output_tensor[index + 2].item()\n",
    "    return goal_food_dict\n",
    "\n",
    "def retrieve_gold_GoalPriceRange(raw_Y, ontology, device):\n",
    "    ontology_informable_pricerange = ontology[\"informable\"][\"pricerange\"]\n",
    "    raw_goal_pricerange = raw_Y[\"goal\"][\"pricerange\"]\n",
    "    goal_pricerange = 0\n",
    "    if raw_goal_pricerange != None:\n",
    "        if raw_goal_pricerange == \"dontcare\":\n",
    "            goal_pricerange = 1\n",
    "        else:    \n",
    "            goal_pricerange = ontology_informable_pricerange.index(raw_goal_pricerange) + 2\n",
    "    return torch.tensor([goal_pricerange], dtype = torch.long, device = device)\n",
    "\n",
    "def retrieve_output_GoalPricerange(output_tensor, ontology):\n",
    "    ontology_informable_pricerange = ontology[\"informable\"][\"pricerange\"]\n",
    "    output_tensor = output_tensor.view(-1)\n",
    "    output_tensor = torch.exp(output_tensor)\n",
    "    goal_pricerange_dict = {}\n",
    "    \n",
    "    index = torch.argmax(output_tensor).item()\n",
    "    if index != 0:\n",
    "        goal_pricerange_dict[\"dontcare\"] = output_tensor[1].item()\n",
    "        for index in range(len(output_tensor) - 2):     \n",
    "            goal_pricerange_dict[ontology_informable_pricerange[index]] = output_tensor[index + 2].item()\n",
    "    return goal_pricerange_dict\n",
    "\n",
    "def retrieve_gold_GoalName(raw_Y, ontology, device):\n",
    "    ontology_informable_name = ontology[\"informable\"][\"name\"]\n",
    "    raw_goal_name = raw_Y[\"goal\"][\"name\"]\n",
    "    goal_name = 0\n",
    "    if raw_goal_name != None:\n",
    "        if raw_goal_name == \"dontcare\":\n",
    "            goal_name = 1\n",
    "        else:    \n",
    "            goal_name = ontology_informable_name.index(raw_goal_name) + 2\n",
    "    return torch.tensor([goal_name], dtype = torch.long, device = device)\n",
    "\n",
    "def retrieve_output_GoalName(output_tensor, ontology):\n",
    "    ontology_informable_name = ontology[\"informable\"][\"name\"]\n",
    "    output_tensor = output_tensor.view(-1)\n",
    "    output_tensor = torch.exp(output_tensor)\n",
    "    goal_name_dict = {}\n",
    "    \n",
    "    index = torch.argmax(output_tensor).item()\n",
    "    if index != 0:\n",
    "        goal_name_dict[\"dontcare\"] = output_tensor[1].item()\n",
    "        for index in range(len(output_tensor) - 2):\n",
    "            goal_name_dict[ontology_informable_name[index]] = output_tensor[index + 2].item()\n",
    "        \n",
    "    return goal_name_dict\n",
    "\n",
    "def retrieve_gold_GoalArea(raw_Y, ontology, device):\n",
    "    ontology_informable_area = ontology[\"informable\"][\"area\"]\n",
    "    raw_goal_area = raw_Y[\"goal\"][\"area\"]\n",
    "    goal_area = 0\n",
    "    if raw_goal_area != None:\n",
    "        if raw_goal_area == \"dontcare\":\n",
    "            goal_area = 1\n",
    "        else:    \n",
    "            goal_area = ontology_informable_area.index(raw_goal_area) + 2\n",
    "    return torch.tensor([goal_area], dtype = torch.long, device = device)\n",
    "\n",
    "def retrieve_output_GoalArea(output_tensor, ontology):\n",
    "    ontology_informable_area = ontology[\"informable\"][\"area\"]\n",
    "    output_tensor = output_tensor.view(-1)\n",
    "    output_tensor = torch.exp(output_tensor)\n",
    "    goal_area_dict = {}\n",
    "    \n",
    "    index = torch.argmax(output_tensor).item()\n",
    "    if index != 0:\n",
    "        goal_area_dict[\"dontcare\"] = output_tensor[1].item()\n",
    "        for index in range(len(output_tensor) - 2):\n",
    "            goal_area_dict[ontology_informable_area[index]] = output_tensor[index + 2].item()\n",
    "        \n",
    "    return goal_area_dict\n",
    "\n",
    "def retrieve_gold_Method(raw_Y, ontology, device):\n",
    "    ontology_method = ontology[\"method\"]\n",
    "    raw_gold_method = raw_Y[\"method\"]\n",
    "    gold_method = ontology_method.index(raw_gold_method)\n",
    "    return torch.tensor([gold_method], dtype = torch.long, device = device)\n",
    "\n",
    "def retrieve_output_Method(output_tensor, ontology):\n",
    "    ontology_method = ontology[\"method\"]\n",
    "    output_tensor = output_tensor.view(-1)\n",
    "    output_tensor = torch.exp(output_tensor)\n",
    "    method_dict = {}\n",
    "    \n",
    "    for index in range(len(output_tensor)):\n",
    "        method_dict[ontology_method[index]] = output_tensor[index].item()\n",
    "    \n",
    "    return method_dict\n",
    "\n",
    "def retrieve_gold_Requested(raw_Y, ontology, device):\n",
    "    ontology_requestable = ontology[\"requestable\"]\n",
    "    raw_gold_requested = raw_Y[\"requested\"]\n",
    "    gold_requested = np.zeros(len(ontology_requestable), dtype = float)\n",
    "    if len(raw_gold_requested) != 0:\n",
    "        for requested in raw_gold_requested:\n",
    "            gold_requested[ontology_requestable.index(requested)] = 1.0\n",
    "    return torch.tensor([gold_requested], dtype = torch.float, device = device)\n",
    "\n",
    "def retrieve_output_Requested(output_tensor, ontology):\n",
    "    ontology_requestable = ontology[\"requestable\"]\n",
    "    output_tensor = output_tensor.view(-1)\n",
    "    requested_dict = {}\n",
    "    for index in range(len(output_tensor)):\n",
    "        probability_value = output_tensor[index].item()\n",
    "        if np.greater_equal(probability_value, 0.5):\n",
    "            requested_dict[ontology_requestable[index]] = probability_value\n",
    "    return requested_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AllModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 vocabulary_size,\n",
    "                 embedding_dim,\n",
    "                 altered_embedding_dim,\n",
    "                 hidden_dim,\n",
    "                 goal_food_dim,\n",
    "                 goal_pricerange_dim,\n",
    "                 goal_name_dim,\n",
    "                 goal_area_dim,\n",
    "                 method_dim,\n",
    "                 requested_dim,\n",
    "                 device):\n",
    "        \n",
    "        super(AllModel, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.goal_food_dim = goal_food_dim\n",
    "        self.goal_pricerange_dim = goal_pricerange_dim\n",
    "        self.goal_name_dim = goal_name_dim\n",
    "        self.goal_area_dim = goal_area_dim\n",
    "        self.method_dim = method_dim\n",
    "        self.requested_dim = requested_dim\n",
    "        self.device = device\n",
    "        \n",
    "        self.embeddings = nn.Embedding(num_embeddings = vocabulary_size,\n",
    "                                       embedding_dim = embedding_dim)\n",
    "        \n",
    "        self.altered_embeddings = nn.Linear(in_features = (embedding_dim + 1),\n",
    "                                            out_features = altered_embedding_dim)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size = altered_embedding_dim,\n",
    "                            hidden_size = hidden_dim)\n",
    "        \n",
    "        self.goal_food_classifier = nn.Linear(in_features = hidden_dim,\n",
    "                                              out_features = goal_food_dim)\n",
    "        \n",
    "        self.goal_pricerange_classifier = nn.Linear(in_features = hidden_dim,\n",
    "                                                    out_features = goal_pricerange_dim)\n",
    "        \n",
    "        self.goal_name_classifier = nn.Linear(in_features = hidden_dim,\n",
    "                                              out_features = goal_name_dim)\n",
    "        \n",
    "        self.goal_area_classifier = nn.Linear(in_features = hidden_dim,\n",
    "                                              out_features = goal_area_dim)\n",
    "        \n",
    "        self.method_classifier = nn.Linear(in_features = hidden_dim,\n",
    "                                           out_features = method_dim)\n",
    "        \n",
    "        self.requested_classifier = nn.Linear(in_features = hidden_dim,\n",
    "                                              out_features = requested_dim)\n",
    "        \n",
    "        self.hidden = self.init_hidden()\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        \n",
    "        return (torch.zeros(1, 1, self.hidden_dim, device = self.device),\n",
    "                torch.zeros(1, 1, self.hidden_dim, device = self.device))\n",
    "        \n",
    "    def forward(self, indices, scores):\n",
    "    \n",
    "        embeddings = self.embeddings(indices)\n",
    "        \n",
    "        embeddings_concat_score = torch.cat((embeddings, scores.unsqueeze(dim = 1)), dim = 1) \n",
    "        \n",
    "        altered_embeddings = F.relu(self.altered_embeddings(embeddings_concat_score))\n",
    "        \n",
    "        lstm_out, self.hidden = self.lstm(altered_embeddings.view(len(indices), 1, -1), self.hidden)\n",
    "        \n",
    "        goal_food = F.log_softmax(self.goal_food_classifier(self.hidden[0]).view(-1, self.goal_food_dim), dim = 1)        \n",
    "        \n",
    "        goal_pricerange = F.log_softmax(self.goal_pricerange_classifier(self.hidden[0]).view(-1, self.goal_pricerange_dim), dim = 1) \n",
    "        \n",
    "        goal_name = F.log_softmax(self.goal_name_classifier(self.hidden[0]).view(-1, self.goal_name_dim), dim = 1)\n",
    "        \n",
    "        goal_area = F.log_softmax(self.goal_area_classifier(self.hidden[0]).view(-1, self.goal_area_dim), dim = 1)\n",
    "        \n",
    "        method = F.log_softmax(self.method_classifier(self.hidden[0]).view(-1, self.method_dim), dim = 1)\n",
    "        \n",
    "        requested = torch.sigmoid(self.requested_classifier(self.hidden[0]).view(-1, self.requested_dim))\n",
    "        \n",
    "        return goal_food, goal_pricerange, goal_name, goal_area, method, requested\n",
    "\n",
    "model_All = AllModel(vocabulary_size = VOCABULARY_SIZE,\n",
    "                               embedding_dim = EMBEDDING_DIM,\n",
    "                               altered_embedding_dim = ALTERED_EMBEDDING_DIM,\n",
    "                               hidden_dim = HIDDEN_DIM,\n",
    "                               goal_food_dim = GOAL_FOOD_DIM,\n",
    "                               goal_pricerange_dim = GOAL_PRICERANGE_DIM,\n",
    "                               goal_name_dim = GOAL_NAME_DIM,\n",
    "                               goal_area_dim = GOAL_AREA_DIM,\n",
    "                               method_dim = METHOD_DIM,\n",
    "                               requested_dim = REQUESTED_DIM,\n",
    "                               device = DEVICE)\n",
    "\n",
    "model_All = model_All.to(DEVICE)\n",
    "\n",
    "optimizer_AllModel = optim.Adam(model_All.parameters(), lr = 1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train All Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch\t1/30\n",
      "100%|██████████| 3224/3224 [01:09<00:00, 46.44it/s]\n",
      "100%|██████████| 506/506 [00:07<00:00, 68.13it/s]\n",
      "INFO:root:DEV Acc:\t\t0.0959333(0.1)\t\t0.6004327(0.6)\t\t0.8329022(0.83)\n",
      "INFO:root:DEV L2:\t\t1.1575627(1.16)\t\t0.2502963(0.25)\t\t0.7991345(0.8)\n",
      "100%|██████████| 1117/1117 [00:20<00:00, 55.32it/s]\n",
      "INFO:root:TEST Acc:\t\t0.0795748(0.08)\t\t0.5813509(0.58)\t\t0.8709975(0.87)\n",
      "INFO:root:TEST L2:\t\t1.112589(1.11)\t\t0.2133332(0.21)\t\t0.8372981(0.84)\n",
      "INFO:root:Epoch\t2/30\n",
      "100%|██████████| 3224/3224 [01:09<00:00, 46.32it/s]\n",
      "100%|██████████| 506/506 [00:07<00:00, 67.61it/s]\n",
      "INFO:root:DEV Acc:\t\t0.2507821(0.25)\t\t0.6419041(0.64)\t\t0.8463528(0.85)\n",
      "INFO:root:DEV L2:\t\t0.9918648(0.99)\t\t0.2230793(0.22)\t\t0.7308751(0.73)\n",
      "100%|██████████| 1117/1117 [00:20<00:00, 53.44it/s]\n",
      "INFO:root:TEST Acc:\t\t0.2225204(0.22)\t\t0.6541066(0.65)\t\t0.8815681(0.88)\n",
      "INFO:root:TEST L2:\t\t0.9966232(1.0)\t\t0.190339(0.19)\t\t0.7174347(0.72)\n",
      "INFO:root:Epoch\t3/30\n",
      "100%|██████████| 3224/3224 [01:09<00:00, 46.38it/s]\n",
      "100%|██████████| 506/506 [00:07<00:00, 64.86it/s]\n",
      "INFO:root:DEV Acc:\t\t0.3164755(0.32)\t\t0.701767(0.7)\t\t0.8517848(0.85)\n",
      "INFO:root:DEV L2:\t\t0.9055028(0.91)\t\t0.2157698(0.22)\t\t0.6221856(0.62)\n",
      "100%|██████████| 1117/1117 [00:22<00:00, 50.45it/s]\n",
      "INFO:root:TEST Acc:\t\t0.3093198(0.31)\t\t0.722174(0.72)\t\t0.8859811(0.89)\n",
      "INFO:root:TEST L2:\t\t0.9084858(0.91)\t\t0.1806478(0.18)\t\t0.5894751(0.59)\n",
      "INFO:root:Epoch\t4/30\n",
      "100%|██████████| 3224/3224 [01:09<00:00, 46.17it/s]\n",
      "100%|██████████| 506/506 [00:08<00:00, 61.99it/s]\n",
      "INFO:root:DEV Acc:\t\t0.3454119(0.35)\t\t0.7486477(0.75)\t\t0.8517848(0.85)\n",
      "INFO:root:DEV L2:\t\t0.8516874(0.85)\t\t0.21128(0.21)\t\t0.5350642(0.54)\n",
      "100%|██████████| 1117/1117 [00:22<00:00, 50.25it/s]\n",
      "INFO:root:TEST Acc:\t\t0.3559707(0.36)\t\t0.7612433(0.76)\t\t0.8927545(0.89)\n",
      "INFO:root:TEST L2:\t\t0.8428053(0.84)\t\t0.1710126(0.17)\t\t0.5151266(0.52)\n",
      "INFO:root:Epoch\t5/30\n",
      "100%|██████████| 3224/3224 [01:09<00:00, 46.63it/s]\n",
      "100%|██████████| 506/506 [00:08<00:00, 60.77it/s]\n",
      "INFO:root:DEV Acc:\t\t0.4105839(0.41)\t\t0.782546(0.78)\t\t0.869374(0.87)\n",
      "INFO:root:DEV L2:\t\t0.8155124(0.82)\t\t0.1931123(0.19)\t\t0.4627083(0.46)\n",
      "100%|██████████| 1117/1117 [00:22<00:00, 49.76it/s]\n",
      "INFO:root:TEST Acc:\t\t0.4279079(0.43)\t\t0.794756(0.79)\t\t0.8977833(0.9)\n",
      "INFO:root:TEST L2:\t\t0.7921944(0.79)\t\t0.1609222(0.16)\t\t0.443317(0.44)\n",
      "INFO:root:Epoch\t6/30\n",
      "100%|██████████| 3224/3224 [01:09<00:00, 46.17it/s]\n",
      "100%|██████████| 506/506 [00:08<00:00, 61.69it/s]\n",
      "INFO:root:DEV Acc:\t\t0.4567258(0.46)\t\t0.8012982(0.8)\t\t0.880238(0.88)\n",
      "INFO:root:DEV L2:\t\t0.7885988(0.79)\t\t0.1869966(0.19)\t\t0.4211234(0.42)\n",
      "100%|██████████| 1117/1117 [00:22<00:00, 49.20it/s]\n",
      "INFO:root:TEST Acc:\t\t0.4842605(0.48)\t\t0.8197604(0.82)\t\t0.9041461(0.9)\n",
      "INFO:root:TEST L2:\t\t0.7453246(0.75)\t\t0.1532583(0.15)\t\t0.3922906(0.39)\n",
      "INFO:root:Epoch\t7/30\n",
      "100%|██████████| 3224/3224 [01:09<00:00, 46.29it/s]\n",
      "100%|██████████| 506/506 [00:08<00:00, 61.76it/s]\n",
      "INFO:root:DEV Acc:\t\t0.4697602(0.47)\t\t0.8236567(0.82)\t\t0.8776513(0.88)\n",
      "INFO:root:DEV L2:\t\t0.7673198(0.77)\t\t0.1849574(0.18)\t\t0.3752516(0.38)\n",
      "100%|██████████| 1117/1117 [00:22<00:00, 50.02it/s]\n",
      "INFO:root:TEST Acc:\t\t0.5156363(0.52)\t\t0.8326098(0.83)\t\t0.9076355(0.91)\n",
      "INFO:root:TEST L2:\t\t0.7102314(0.71)\t\t0.1491173(0.15)\t\t0.3599203(0.36)\n",
      "INFO:root:Epoch\t8/30\n",
      "100%|██████████| 3224/3224 [01:09<00:00, 46.43it/s]\n",
      "100%|██████████| 506/506 [00:08<00:00, 62.33it/s]\n",
      "INFO:root:DEV Acc:\t\t0.4854015(0.49)\t\t0.8380815(0.84)\t\t0.8882566(0.89)\n",
      "INFO:root:DEV L2:\t\t0.7689481(0.77)\t\t0.1780027(0.18)\t\t0.3418163(0.34)\n",
      "100%|██████████| 1117/1117 [00:22<00:00, 49.71it/s]\n",
      "INFO:root:TEST Acc:\t\t0.5156363(0.52)\t\t0.8482375(0.85)\t\t0.910509(0.91)\n",
      "INFO:root:TEST L2:\t\t0.7181307(0.72)\t\t0.1464744(0.15)\t\t0.320052(0.32)\n",
      "INFO:root:Epoch\t9/30\n",
      "100%|██████████| 3224/3224 [01:10<00:00, 45.91it/s]\n",
      "100%|██████████| 506/506 [00:08<00:00, 62.32it/s]\n",
      "INFO:root:DEV Acc:\t\t0.5310219(0.53)\t\t0.8503426(0.85)\t\t0.8867046(0.89)\n",
      "INFO:root:DEV L2:\t\t0.7098015(0.71)\t\t0.1827446(0.18)\t\t0.3144376(0.31)\n",
      "100%|██████████| 1117/1117 [00:22<00:00, 49.76it/s]\n",
      "INFO:root:TEST Acc:\t\t0.5624935(0.56)\t\t0.862997(0.86)\t\t0.9183087(0.92)\n",
      "INFO:root:TEST L2:\t\t0.6549891(0.65)\t\t0.1326472(0.13)\t\t0.2884262(0.29)\n",
      "INFO:root:Epoch\t10/30\n",
      "100%|██████████| 3224/3224 [01:09<00:00, 46.49it/s]\n",
      "100%|██████████| 506/506 [00:08<00:00, 61.08it/s]\n",
      "INFO:root:DEV Acc:\t\t0.5424922(0.54)\t\t0.8478182(0.85)\t\t0.8872219(0.89)\n",
      "INFO:root:DEV L2:\t\t0.692943(0.69)\t\t0.1801942(0.18)\t\t0.3220659(0.32)\n",
      "100%|██████████| 1117/1117 [00:22<00:00, 49.97it/s]\n",
      "INFO:root:TEST Acc:\t\t0.5656931(0.57)\t\t0.8609134(0.86)\t\t0.9178982(0.92)\n",
      "INFO:root:TEST L2:\t\t0.6500008(0.65)\t\t0.1322362(0.13)\t\t0.2959449(0.3)\n",
      "INFO:root:Epoch\t11/30\n",
      "100%|██████████| 3224/3224 [01:09<00:00, 46.26it/s]\n",
      "100%|██████████| 506/506 [00:08<00:00, 61.36it/s]\n",
      "INFO:root:DEV Acc:\t\t0.5477059(0.55)\t\t0.8636855(0.86)\t\t0.8913606(0.89)\n",
      "INFO:root:DEV L2:\t\t0.6584444(0.66)\t\t0.1774054(0.18)\t\t0.2866792(0.29)\n",
      "100%|██████████| 1117/1117 [00:22<00:00, 49.33it/s]\n",
      "INFO:root:TEST Acc:\t\t0.5895345(0.59)\t\t0.8767147(0.88)\t\t0.9162562(0.92)\n",
      "INFO:root:TEST L2:\t\t0.5969135(0.6)\t\t0.1344893(0.13)\t\t0.2601(0.26)\n",
      "INFO:root:Epoch\t12/30\n",
      "100%|██████████| 3224/3224 [01:09<00:00, 46.61it/s]\n",
      "100%|██████████| 506/506 [00:08<00:00, 60.13it/s]\n",
      "INFO:root:DEV Acc:\t\t0.5542231(0.55)\t\t0.8708979(0.87)\t\t0.8898086(0.89)\n",
      "INFO:root:DEV L2:\t\t0.6583426(0.66)\t\t0.176794(0.18)\t\t0.2635919(0.26)\n",
      "100%|██████████| 1117/1117 [00:22<00:00, 49.30it/s]\n",
      "INFO:root:TEST Acc:\t\t0.5881928(0.59)\t\t0.8892169(0.89)\t\t0.9148194(0.91)\n",
      "INFO:root:TEST L2:\t\t0.6116085(0.61)\t\t0.1325473(0.13)\t\t0.2278797(0.23)\n",
      "INFO:root:Epoch\t13/30\n",
      "100%|██████████| 3224/3224 [01:09<00:00, 46.35it/s]\n",
      "100%|██████████| 506/506 [00:08<00:00, 60.93it/s]\n",
      "INFO:root:DEV Acc:\t\t0.5573514(0.56)\t\t0.8817166(0.88)\t\t0.8923952(0.89)\n",
      "INFO:root:DEV L2:\t\t0.6583459(0.66)\t\t0.1779051(0.18)\t\t0.2457729(0.25)\n",
      "100%|██████████| 1117/1117 [00:23<00:00, 48.55it/s]\n",
      "INFO:root:TEST Acc:\t\t0.590773(0.59)\t\t0.8935579(0.89)\t\t0.9166667(0.92)\n",
      "INFO:root:TEST L2:\t\t0.6058746(0.61)\t\t0.1320781(0.13)\t\t0.219612(0.22)\n",
      "INFO:root:Epoch\t14/30\n",
      "100%|██████████| 3224/3224 [01:09<00:00, 46.26it/s]\n",
      "100%|██████████| 506/506 [00:08<00:00, 61.65it/s]\n",
      "INFO:root:DEV Acc:\t\t0.5599583(0.56)\t\t0.8993869(0.9)\t\t0.8838593(0.88)\n",
      "INFO:root:DEV L2:\t\t0.6388094(0.64)\t\t0.1868407(0.19)\t\t0.2067402(0.21)\n",
      "100%|██████████| 1117/1117 [00:23<00:00, 48.41it/s]\n",
      "INFO:root:TEST Acc:\t\t0.5862318(0.59)\t\t0.9060601(0.91)\t\t0.9158456(0.92)\n",
      "INFO:root:TEST L2:\t\t0.6149089(0.61)\t\t0.1303973(0.13)\t\t0.1897227(0.19)\n",
      "INFO:root:Epoch\t15/30\n",
      "100%|██████████| 3224/3224 [01:09<00:00, 46.47it/s]\n",
      "100%|██████████| 506/506 [00:08<00:00, 61.19it/s]\n",
      "INFO:root:DEV Acc:\t\t0.5641293(0.56)\t\t0.8975838(0.9)\t\t0.883342(0.88)\n",
      "INFO:root:DEV L2:\t\t0.6422716(0.64)\t\t0.1891734(0.19)\t\t0.2106666(0.21)\n",
      "100%|██████████| 1117/1117 [00:22<00:00, 48.92it/s]\n",
      "INFO:root:TEST Acc:\t\t0.5956239(0.6)\t\t0.9116166(0.91)\t\t0.9228243(0.92)\n",
      "INFO:root:TEST L2:\t\t0.5932886(0.59)\t\t0.1254823(0.13)\t\t0.1821747(0.18)\n",
      "INFO:root:Epoch\t16/30\n",
      "100%|██████████| 3224/3224 [01:09<00:00, 46.37it/s]\n",
      "100%|██████████| 506/506 [00:08<00:00, 60.63it/s]\n",
      "INFO:root:DEV Acc:\t\t0.5724713(0.57)\t\t0.8943383(0.89)\t\t0.8807553(0.88)\n",
      "INFO:root:DEV L2:\t\t0.6468078(0.65)\t\t0.1904919(0.19)\t\t0.2152915(0.22)\n",
      "100%|██████████| 1117/1117 [00:22<00:00, 49.52it/s]\n",
      "INFO:root:TEST Acc:\t\t0.5965528(0.6)\t\t0.9091856(0.91)\t\t0.9187192(0.92)\n",
      "INFO:root:TEST L2:\t\t0.6105262(0.61)\t\t0.1271563(0.13)\t\t0.1855334(0.19)\n",
      "INFO:root:Epoch\t17/30\n",
      "100%|██████████| 3224/3224 [01:09<00:00, 45.46it/s]\n",
      "100%|██████████| 506/506 [00:08<00:00, 61.71it/s]\n",
      "INFO:root:DEV Acc:\t\t0.5683003(0.57)\t\t0.8983051(0.9)\t\t0.8879979(0.89)\n",
      "INFO:root:DEV L2:\t\t0.6402981(0.64)\t\t0.1876481(0.19)\t\t0.2060233(0.21)\n",
      "100%|██████████| 1117/1117 [00:22<00:00, 49.35it/s]\n",
      "INFO:root:TEST Acc:\t\t0.6134792(0.61)\t\t0.9123112(0.91)\t\t0.9219007(0.92)\n",
      "INFO:root:TEST L2:\t\t0.5730531(0.57)\t\t0.1261685(0.13)\t\t0.1802922(0.18)\n",
      "INFO:root:Epoch\t18/30\n",
      "100%|██████████| 3224/3224 [01:09<00:00, 46.31it/s]\n",
      "100%|██████████| 506/506 [00:08<00:00, 59.95it/s]\n",
      "INFO:root:DEV Acc:\t\t0.5782065(0.58)\t\t0.9062387(0.91)\t\t0.8885153(0.89)\n",
      "INFO:root:DEV L2:\t\t0.6364325(0.64)\t\t0.1824523(0.18)\t\t0.1939667(0.19)\n",
      "100%|██████████| 1117/1117 [00:22<00:00, 49.03it/s]\n",
      "INFO:root:TEST Acc:\t\t0.6171948(0.62)\t\t0.9194305(0.92)\t\t0.9211823(0.92)\n",
      "INFO:root:TEST L2:\t\t0.5767397(0.58)\t\t0.1251223(0.13)\t\t0.1661087(0.17)\n",
      "INFO:root:Epoch\t19/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3224/3224 [01:09<00:00, 44.12it/s]\n",
      "100%|██████████| 506/506 [00:08<00:00, 60.35it/s]\n",
      "INFO:root:DEV Acc:\t\t0.5849844(0.58)\t\t0.9105662(0.91)\t\t0.8867046(0.89)\n",
      "INFO:root:DEV L2:\t\t0.6391163(0.64)\t\t0.18338(0.18)\t\t0.1801215(0.18)\n",
      "100%|██████████| 1117/1117 [00:22<00:00, 48.61it/s]\n",
      "INFO:root:TEST Acc:\t\t0.6190525(0.62)\t\t0.9241188(0.92)\t\t0.9251847(0.93)\n",
      "INFO:root:TEST L2:\t\t0.5867957(0.59)\t\t0.1212974(0.12)\t\t0.1524852(0.15)\n",
      "INFO:root:Epoch\t20/30\n",
      "100%|██████████| 3224/3224 [01:09<00:00, 46.51it/s]\n",
      "100%|██████████| 506/506 [00:08<00:00, 61.78it/s]\n",
      "INFO:root:DEV Acc:\t\t0.5808133(0.58)\t\t0.9112874(0.91)\t\t0.8828246(0.88)\n",
      "INFO:root:DEV L2:\t\t0.6428512(0.64)\t\t0.1891195(0.19)\t\t0.1831974(0.18)\n",
      "100%|██████████| 1117/1117 [00:22<00:00, 49.53it/s]\n",
      "INFO:root:TEST Acc:\t\t0.6169883(0.62)\t\t0.9255079(0.93)\t\t0.9138957(0.91)\n",
      "INFO:root:TEST L2:\t\t0.5902578(0.59)\t\t0.1364095(0.14)\t\t0.1541084(0.15)\n",
      "INFO:root:Epoch\t21/30\n",
      "100%|██████████| 3224/3224 [01:09<00:00, 46.56it/s]\n",
      "100%|██████████| 506/506 [00:08<00:00, 61.96it/s]\n",
      "INFO:root:DEV Acc:\t\t0.5899374(0.59)\t\t0.9087631(0.91)\t\t0.8885153(0.89)\n",
      "INFO:root:DEV L2:\t\t0.6361393(0.64)\t\t0.1831853(0.18)\t\t0.1882782(0.19)\n",
      "100%|██████████| 1117/1117 [00:22<00:00, 50.22it/s]\n",
      "INFO:root:TEST Acc:\t\t0.6121375(0.61)\t\t0.9281125(0.93)\t\t0.920156(0.92)\n",
      "INFO:root:TEST L2:\t\t0.6027672(0.6)\t\t0.1272649(0.13)\t\t0.1481701(0.15)\n",
      "INFO:root:Epoch\t22/30\n",
      "100%|██████████| 3224/3224 [01:09<00:00, 46.23it/s]\n",
      "100%|██████████| 506/506 [00:08<00:00, 58.55it/s]\n",
      "INFO:root:DEV Acc:\t\t0.5909802(0.59)\t\t0.9148936(0.91)\t\t0.883342(0.88)\n",
      "INFO:root:DEV L2:\t\t0.6260865(0.63)\t\t0.1868203(0.19)\t\t0.1691751(0.17)\n",
      "100%|██████████| 1117/1117 [00:22<00:00, 48.81it/s]\n",
      "INFO:root:TEST Acc:\t\t0.6189493(0.62)\t\t0.9298489(0.93)\t\t0.9126642(0.91)\n",
      "INFO:root:TEST L2:\t\t0.5851253(0.59)\t\t0.1363571(0.14)\t\t0.1390016(0.14)\n",
      "INFO:root:Epoch\t23/30\n",
      "100%|██████████| 3224/3224 [01:10<00:00, 45.98it/s]\n",
      "100%|██████████| 506/506 [00:08<00:00, 60.28it/s]\n",
      "INFO:root:DEV Acc:\t\t0.5878519(0.59)\t\t0.9181392(0.92)\t\t0.883342(0.88)\n",
      "INFO:root:DEV L2:\t\t0.6206507(0.62)\t\t0.1936153(0.19)\t\t0.1656785(0.17)\n",
      "100%|██████████| 1117/1117 [00:22<00:00, 48.81it/s]\n",
      "INFO:root:TEST Acc:\t\t0.6188461(0.62)\t\t0.9303699(0.93)\t\t0.9130747(0.91)\n",
      "INFO:root:TEST L2:\t\t0.5813839(0.58)\t\t0.1402784(0.14)\t\t0.1380237(0.14)\n",
      "INFO:root:Epoch\t24/30\n",
      "100%|██████████| 3224/3224 [01:10<00:00, 46.02it/s]\n",
      "100%|██████████| 506/506 [00:08<00:00, 58.50it/s]\n",
      "INFO:root:DEV Acc:\t\t0.5948905(0.59)\t\t0.9188604(0.92)\t\t0.8861873(0.89)\n",
      "INFO:root:DEV L2:\t\t0.6130693(0.61)\t\t0.1867336(0.19)\t\t0.1652637(0.17)\n",
      "100%|██████████| 1117/1117 [00:22<00:00, 49.46it/s]\n",
      "INFO:root:TEST Acc:\t\t0.6147177(0.61)\t\t0.9322799(0.93)\t\t0.9234401(0.92)\n",
      "INFO:root:TEST L2:\t\t0.6035763(0.6)\t\t0.1235233(0.12)\t\t0.1371209(0.14)\n",
      "INFO:root:Epoch\t25/30\n",
      "100%|██████████| 3224/3224 [01:10<00:00, 49.59it/s]\n",
      "100%|██████████| 506/506 [00:08<00:00, 60.14it/s]\n",
      "INFO:root:DEV Acc:\t\t0.5855057(0.59)\t\t0.9181392(0.92)\t\t0.8882566(0.89)\n",
      "INFO:root:DEV L2:\t\t0.6103104(0.61)\t\t0.186931(0.19)\t\t0.1661357(0.17)\n",
      "100%|██████████| 1117/1117 [00:23<00:00, 48.32it/s]\n",
      "INFO:root:TEST Acc:\t\t0.6307152(0.63)\t\t0.9331481(0.93)\t\t0.9235427(0.92)\n",
      "INFO:root:TEST L2:\t\t0.5582822(0.56)\t\t0.1231963(0.12)\t\t0.1352051(0.14)\n",
      "INFO:root:Epoch\t26/30\n",
      "100%|██████████| 3224/3224 [01:09<00:00, 46.35it/s]\n",
      "100%|██████████| 506/506 [00:08<00:00, 59.21it/s]\n",
      "INFO:root:DEV Acc:\t\t0.5899374(0.59)\t\t0.9203029(0.92)\t\t0.8892913(0.89)\n",
      "INFO:root:DEV L2:\t\t0.6236001(0.62)\t\t0.1835922(0.18)\t\t0.1605846(0.16)\n",
      "100%|██████████| 1117/1117 [00:22<00:00, 49.37it/s]\n",
      "INFO:root:TEST Acc:\t\t0.6211167(0.62)\t\t0.9359264(0.94)\t\t0.924569(0.92)\n",
      "INFO:root:TEST L2:\t\t0.5919801(0.59)\t\t0.1229723(0.12)\t\t0.1292887(0.13)\n",
      "INFO:root:Epoch\t27/30\n",
      "100%|██████████| 3224/3224 [01:09<00:00, 46.23it/s]\n",
      "100%|██████████| 506/506 [00:08<00:00, 59.92it/s]\n",
      "INFO:root:DEV Acc:\t\t0.5972367(0.6)\t\t0.9282366(0.93)\t\t0.8843766(0.88)\n",
      "INFO:root:DEV L2:\t\t0.6030241(0.6)\t\t0.1887856(0.19)\t\t0.1451444(0.15)\n",
      "100%|██████████| 1117/1117 [00:22<00:00, 48.93it/s]\n",
      "INFO:root:TEST Acc:\t\t0.6177108(0.62)\t\t0.9378364(0.94)\t\t0.9246716(0.92)\n",
      "INFO:root:TEST L2:\t\t0.5766026(0.58)\t\t0.1225472(0.12)\t\t0.1224632(0.12)\n",
      "INFO:root:Epoch\t28/30\n",
      "100%|██████████| 3224/3224 [01:10<00:00, 45.43it/s]\n",
      "100%|██████████| 506/506 [00:08<00:00, 59.41it/s]\n",
      "INFO:root:DEV Acc:\t\t0.5904588(0.59)\t\t0.9231879(0.92)\t\t0.8856699(0.89)\n",
      "INFO:root:DEV L2:\t\t0.6154977(0.62)\t\t0.1913166(0.19)\t\t0.1547651(0.15)\n",
      "100%|██████████| 1117/1117 [00:23<00:00, 47.95it/s]\n",
      "INFO:root:TEST Acc:\t\t0.6316441(0.63)\t\t0.9383574(0.94)\t\t0.9235427(0.92)\n",
      "INFO:root:TEST L2:\t\t0.5750852(0.58)\t\t0.1243888(0.12)\t\t0.1225425(0.12)\n",
      "INFO:root:Epoch\t29/30\n",
      "100%|██████████| 3224/3224 [01:09<00:00, 46.28it/s]\n",
      "100%|██████████| 506/506 [00:08<00:00, 61.99it/s]\n",
      "INFO:root:DEV Acc:\t\t0.5959333(0.6)\t\t0.9264335(0.93)\t\t0.8867046(0.89)\n",
      "INFO:root:DEV L2:\t\t0.6170142(0.62)\t\t0.1910743(0.19)\t\t0.1475067(0.15)\n",
      "100%|██████████| 1117/1117 [00:22<00:00, 49.07it/s]\n",
      "INFO:root:TEST Acc:\t\t0.6238002(0.62)\t\t0.938531(0.94)\t\t0.9227217(0.92)\n",
      "INFO:root:TEST L2:\t\t0.5919147(0.59)\t\t0.1253462(0.13)\t\t0.1214351(0.12)\n",
      "INFO:root:Epoch\t30/30\n",
      " 28%|██▊       | 887/3224 [00:19<00:58, 39.76it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-fad048de78cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mdialog_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_goal_food\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_goal_pricerange\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_goal_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_goal_area\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_method\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_requested\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mdialog_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0moptimizer_AllModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/iDST-PMaBuuf7/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/iDST-PMaBuuf7/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dev_goal_accuracies = []\n",
    "dev_requested_accuracies = []\n",
    "dev_method_accuracies = []\n",
    "\n",
    "test_goal_accuracies = []\n",
    "test_requested_accuracies = []\n",
    "test_method_accuracies = []\n",
    "\n",
    "all_early_stopping = EarlyStopping(patience = 2)\n",
    "\n",
    "train_indices = np.arange(raw_X_train.shape[0])\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    np.random.shuffle(train_indices)\n",
    "    \n",
    "    logging.info(\"Epoch\\t{}/{}\".format(epoch + 1, NUM_EPOCHS))\n",
    "    \n",
    "    model_All = model_All.train()\n",
    "    \n",
    "    for raw_X_train_dialog, raw_Y_train_dialog in tqdm(zip(raw_X_train[train_indices], raw_Y_train[train_indices]), total = len(raw_X_train)):\n",
    "\n",
    "        model_All.hidden = model_All.init_hidden()\n",
    "\n",
    "        for raw_X_train_turn, raw_Y_train_turn in zip(raw_X_train_dialog[\"turns\"], raw_Y_train_dialog[\"turns\"]):\n",
    "            \n",
    "            optimizer_AllModel.zero_grad()\n",
    "            \n",
    "            indices, scores = get_index_and_score(raw_X_train_turn, token_to_index, mode = \"train\", device = DEVICE)\n",
    "            \n",
    "            goal_food, goal_pricerange, goal_name, goal_area, method, requested = model_All(indices, scores)\n",
    "            \n",
    "            loss_goal_food = GOAL_LOSS_FUNCTION(goal_food,\n",
    "                                                retrieve_gold_GoalFood(raw_Y_train_turn,\n",
    "                                                                       ontology = ontology,\n",
    "                                                                       device = DEVICE))\n",
    "            \n",
    "            loss_goal_pricerange = GOAL_LOSS_FUNCTION(goal_pricerange,\n",
    "                                                      retrieve_gold_GoalPriceRange(raw_Y_train_turn,\n",
    "                                                                                   ontology = ontology,\n",
    "                                                                                   device = DEVICE))\n",
    "            \n",
    "            loss_goal_name = GOAL_LOSS_FUNCTION(goal_name,\n",
    "                                                retrieve_gold_GoalName(raw_Y_train_turn,\n",
    "                                                                       ontology = ontology,\n",
    "                                                                       device = DEVICE))\n",
    "            \n",
    "            loss_goal_area = GOAL_LOSS_FUNCTION(goal_area,\n",
    "                                                retrieve_gold_GoalArea(raw_Y_train_turn,\n",
    "                                                                       ontology = ontology,\n",
    "                                                                       device = DEVICE))\n",
    "            \n",
    "            loss_method = METHOD_LOSS_FUNCTION(method,\n",
    "                                               retrieve_gold_Method(raw_Y_train_turn,\n",
    "                                                                    ontology = ontology,\n",
    "                                                                    device = DEVICE))\n",
    "            \n",
    "            loss_requested = REQUESTED_LOSS_FUNCTION(requested,\n",
    "                                                     retrieve_gold_Requested(raw_Y_train_turn,\n",
    "                                                                             ontology = ontology,\n",
    "                                                                             device = DEVICE))\n",
    "\n",
    "            loss = loss_goal_food + loss_goal_pricerange + loss_goal_name + loss_goal_area + loss_method + loss_requested\n",
    "            \n",
    "            loss.backward(retain_graph = True)\n",
    "            \n",
    "            optimizer_AllModel.step()\n",
    "    \n",
    "    dev_goal_accuracy, \\\n",
    "    dev_goal_l2, \\\n",
    "    dev_requested_accuracy, \\\n",
    "    dev_requested_l2, \\\n",
    "    dev_method_accuracy, \\\n",
    "    dev_method_l2 = get_scores(model_All, raw_X_dev, raw_Y_dev, dataset = \"dstc2_dev\")\n",
    "    logging.info(\"DEV Acc:\\t\\t{}({})\\t\\t{}({})\\t\\t{}({})\".format(dev_goal_accuracy,\n",
    "                                                             np.around(dev_goal_accuracy, decimals = 2),\n",
    "                                                             dev_requested_accuracy,\n",
    "                                                             np.around(dev_requested_accuracy, decimals = 2),\n",
    "                                                             dev_method_accuracy,\n",
    "                                                             np.around(dev_method_accuracy, decimals = 2)))\n",
    "    logging.info(\"DEV L2:\\t\\t{}({})\\t\\t{}({})\\t\\t{}({})\".format(dev_goal_l2,\n",
    "                                                             np.around(dev_goal_l2, decimals = 2),\n",
    "                                                             dev_requested_l2,\n",
    "                                                             np.around(dev_requested_l2, decimals = 2),\n",
    "                                                             dev_method_l2,\n",
    "                                                             np.around(dev_method_l2, decimals = 2)))\n",
    "    dev_goal_accuracies.append(dev_goal_accuracy)\n",
    "    dev_requested_accuracies.append(dev_requested_accuracy)\n",
    "    dev_method_accuracies.append(dev_method_accuracy)\n",
    "\n",
    "    test_goal_accuracy, \\\n",
    "    test_goal_l2, \\\n",
    "    test_requested_accuracy, \\\n",
    "    test_requested_l2, \\\n",
    "    test_method_accuracy, \\\n",
    "    test_method_l2 = get_scores(model_All, raw_X_test, raw_Y_test, dataset = \"dstc2_test\")\n",
    "    logging.info(\"TEST Acc:\\t\\t{}({})\\t\\t{}({})\\t\\t{}({})\".format(test_goal_accuracy,\n",
    "                                                              np.around(test_goal_accuracy, decimals = 2),\n",
    "                                                              test_requested_accuracy,\n",
    "                                                              np.around(test_requested_accuracy, decimals = 2),\n",
    "                                                              test_method_accuracy,\n",
    "                                                              np.around(test_method_accuracy, decimals = 2)))\n",
    "    logging.info(\"TEST L2:\\t\\t{}({})\\t\\t{}({})\\t\\t{}({})\".format(test_goal_l2,\n",
    "                                                              np.around(test_goal_l2, decimals = 2),\n",
    "                                                              test_requested_l2,\n",
    "                                                              np.around(test_requested_l2, decimals = 2),\n",
    "                                                              test_method_l2,\n",
    "                                                              np.around(test_method_l2, decimals = 2)))\n",
    "    test_goal_accuracies.append(test_goal_accuracy)\n",
    "    test_requested_accuracies.append(test_requested_accuracy)\n",
    "    test_method_accuracies.append(test_requested_accuracy)\n",
    "        \n",
    "    all_early_stopping.on_epoch_end(epoch = (epoch + 1),\n",
    "                                    current_value = (dev_goal_accuracy + dev_requested_accuracy + dev_method_accuracy))\n",
    "    \n",
    "    if all_early_stopping.stop_training:\n",
    "        break\n",
    "\n",
    "plotly_plot(dev_goal_accuracies, test_goal_accuracies, \"Goal\")\n",
    "plotly_plot(dev_requested_accuracies, test_requested_accuracies, \"Requested\")\n",
    "plotly_plot(dev_method_accuracies, test_method_accuracies, \"Method\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save All Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_All.state_dict(), \"model_All.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load All Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_All = AllModel(vocabulary_size = VOCABULARY_SIZE,\n",
    "                               embedding_dim = EMBEDDING_DIM,\n",
    "                               altered_embedding_dim = ALTERED_EMBEDDING_DIM,\n",
    "                               hidden_dim = HIDDEN_DIM,\n",
    "                               goal_food_dim = GOAL_FOOD_DIM,\n",
    "                               goal_pricerange_dim = GOAL_PRICERANGE_DIM,\n",
    "                               goal_name_dim = GOAL_NAME_DIM,\n",
    "                               goal_area_dim = GOAL_AREA_DIM,\n",
    "                               method_dim = METHOD_DIM,\n",
    "                               requested_dim = REQUESTED_DIM,\n",
    "                               device = DEVICE)\n",
    "model_All = model_All.to(DEVICE)\n",
    "model_All.load_state_dict(torch.load(\"model_All.pt\"))\n",
    "model_All.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_scores(model_All, raw_X_dev, raw_Y_dev, dataset = \"dstc2_dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_scores(model_All, raw_X_test, raw_Y_test, dataset = \"dstc2_test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
