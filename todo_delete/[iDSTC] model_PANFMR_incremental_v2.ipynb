{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check GPU availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Feb  4 18:57:38 2019       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 384.145                Driver Version: 384.145                   |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:02:00.0 Off |                  N/A |\r\n",
      "| 23%   26C    P8    17W / 250W |      0MiB / 11172MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:03:00.0 Off |                  N/A |\r\n",
      "| 23%   32C    P8    17W / 250W |      0MiB / 11172MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/is/andrei-\n",
      "[nltk_data]     cc/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import copy\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import plotly\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm_notebook\n",
    "from idst_util import trivial\n",
    "from idst_util import dstc2\n",
    "\n",
    "from plotly.graph_objs import Scatter, Layout\n",
    "from plotly.graph_objs.layout import Margin\n",
    "plotly.offline.init_notebook_mode(connected = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check DSTC2 availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:+--------------------------------+\n",
      "INFO:root:|         _ ____  ___________    |\n",
      "INFO:root:|        (_) __ \\/ ___/_  __/    |\n",
      "INFO:root:|       / / / / /\\__ \\ / /       |\n",
      "INFO:root:|      / / /_/ /___/ // /        |\n",
      "INFO:root:|     /_/_____//____//_/         |\n",
      "INFO:root:|                                |\n",
      "INFO:root:+--------------------------------+\n",
      "INFO:root:|Incremental Dialog State Tracker|\n",
      "INFO:root:+--------------------------------+\n",
      "INFO:root:+--------------------------------+\n",
      "INFO:root:|     Dialog State Tracker 2     |\n",
      "INFO:root:|         Data Checker           |\n",
      "INFO:root:+--------------------------------+\n",
      "INFO:root:Looking for dstc2 directory in .\n",
      "INFO:root:dstc2 was found!\n",
      "INFO:root:Looking for dstc2_traindev directory in ./dstc2\n",
      "INFO:root:dstc2_traindev was found!\n",
      "INFO:root:Looking for dstc2_test directory in ./dstc2\n",
      "INFO:root:dstc2_test was found!\n",
      "INFO:root:Looking for dstc2_scripts directory in ./dstc2\n",
      "INFO:root:dstc2_scripts was found!\n",
      "INFO:root:Done!\n"
     ]
    }
   ],
   "source": [
    "trivial.print_idst()\n",
    "dstc2.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:+--------------------------------+\n",
      "INFO:root:|     Dialog State Tracker 2     |\n",
      "INFO:root:|       Dataset Retrieval        |\n",
      "INFO:root:+--------------------------------+\n",
      "INFO:root:Reading dstc2_train.flist, dstc2_dev.flist and ontology_dstc2.json\n",
      "INFO:root:Asserted 1612 dialogs for dstc2_train.flist\n",
      "INFO:root:Asserted 506 dialogs for dstc2_dev.flist\n",
      "INFO:root:Extracting raw train features\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c583ba68c4264567a2939a35ad0c6547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1612), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Extracting raw dev features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc2b2b6169404565863ba144f4b72a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=506), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Reading dstc2_test.flist\n",
      "INFO:root:Asserted 1117 dialogs for dstc2_test.flist\n",
      "INFO:root:Extracting raw test features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b615893c4ee9473f94a29e19f929723c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1117), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "raw_X_train, raw_Y_train, \\\n",
    "raw_X_dev, raw_Y_dev, \\\n",
    "raw_X_test, raw_Y_test, \\\n",
    "ontology = dstc2.retrieve_raw_datasets(train_data_augmentation = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"+--------------------------------+\")\n",
    "logging.info(\"|            Baseline            |\")\n",
    "logging.info(\"+--------------------------------+\")\n",
    "\n",
    "GPU_ID = 1\n",
    "DEVICE = torch.device(\"cuda:{}\".format(GPU_ID) if torch.cuda.is_available() else \"cpu\")\n",
    "#DEVICE = \"cpu\"\n",
    "if DEVICE == \"cpu\":\n",
    "    logging.warning(\"Running on CPU\")\n",
    "else:\n",
    "    logging.info(\"Running on GPU {}\".format(GPU_ID))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_and_score(turn, token_to_index, mode, device):\n",
    "    indices = []\n",
    "    scores = []\n",
    "    if mode == \"train\":\n",
    "        for system_token, system_token_score in turn[\"system\"]:\n",
    "            indices.append(token_to_index[system_token])\n",
    "            scores.append(system_token_score)\n",
    "        for user_token, user_token_score in turn[\"user\"]:\n",
    "            if np.random.binomial(n = 1, p = 0.1) == 1:\n",
    "                indices.append(token_to_index[\"<unk>\"])\n",
    "            else:\n",
    "                indices.append(token_to_index[user_token])\n",
    "            scores.append(user_token_score)\n",
    "    else:\n",
    "        tokens_scores = turn[\"system\"] + turn[\"user\"]\n",
    "        for token, score in tokens_scores:\n",
    "            if token not in token_to_index:\n",
    "                indices.append(token_to_index[\"<unk>\"])\n",
    "            else:\n",
    "                indices.append(token_to_index[token])\n",
    "            scores.append(score)\n",
    "    assert len(indices) == len(scores)\n",
    "    return torch.tensor(indices, dtype = torch.long, device = device), torch.tensor(scores, dtype = torch.float, device = device)\n",
    "\n",
    "class EarlyStopping():\n",
    "    \n",
    "    def __init__(self, min_delta = 0, patience = 0):\n",
    "        \n",
    "        self.min_delta = min_delta\n",
    "        self.patience = patience\n",
    "        self.wait = 0\n",
    "        self.stopped_epoch = 0\n",
    "        self.best = -np.Inf\n",
    "        self.stop_training = False\n",
    "    \n",
    "    def on_epoch_end(self, epoch, current_value):\n",
    "        if np.greater((current_value - self.min_delta), self.best):\n",
    "            self.best = current_value\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait > self.patience:\n",
    "                self.stopped_epoch = epoch\n",
    "                self.stop_training = True\n",
    "        return self.stop_training\n",
    "\n",
    "def make_tracker(model_GoalPricerange, model_GoalArea, model_GoalName, model_GoalFood, model_Requested, model_Method, raw_X, raw_Y, dataset, percentage = 1.0):\n",
    "    \n",
    "    model_GoalPricerange = model_GoalPricerange.eval()\n",
    "    model_GoalArea = model_GoalArea.eval()\n",
    "    model_GoalName = model_GoalName.eval()\n",
    "    model_GoalFood = model_GoalFood.eval()\n",
    "    model_Requested = model_Requested.eval()\n",
    "    model_Method = model_Method.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        tracker_json = {}\n",
    "        tracker_json[\"dataset\"] = dataset\n",
    "        tracker_json[\"sessions\"] = []\n",
    "\n",
    "        start_time = time.time()\n",
    "        for raw_X_dialog, raw_Y_dialog in tqdm_notebook(zip(raw_X, raw_Y), total = len(raw_X)):\n",
    "            \n",
    "            model_GoalPricerange.hidden = model_GoalPricerange.init_hidden()\n",
    "            model_GoalArea.hidden = model_GoalArea.init_hidden()\n",
    "            model_GoalName.hidden = model_GoalName.init_hidden()\n",
    "            model_GoalFood.hidden = model_GoalFood.init_hidden()\n",
    "            model_Requested.hidden = model_Requested.init_hidden()\n",
    "            model_Method.hidden = model_Method.init_hidden()\n",
    "            \n",
    "            session = {}\n",
    "            session[\"session-id\"] = raw_X_dialog[\"session-id\"]\n",
    "            session[\"turns\"] = []\n",
    "\n",
    "            for raw_X_turn, raw_Y_turn in zip(raw_X_dialog[\"turns\"], raw_Y_dialog[\"turns\"]):\n",
    "                turn = {}\n",
    "                turn[\"goal-labels\"] = {}\n",
    "\n",
    "                indices, scores = get_index_and_score(raw_X_turn, token_to_index, mode = \"eval\", device = DEVICE)\n",
    "                \n",
    "                incremental_index = int(np.around(percentage * len(indices))) - 1\n",
    "                \n",
    "                goal_foods = model_GoalFood(indices, scores)\n",
    "                goal_food = goal_foods[incremental_index]\n",
    "                \n",
    "                goal_priceranges = model_GoalPricerange(indices, scores)\n",
    "                goal_pricerange = goal_priceranges[incremental_index]\n",
    "                \n",
    "                goal_names = model_GoalName(indices, scores)\n",
    "                goal_name = goal_names[incremental_index]\n",
    "                \n",
    "                goal_areas = model_GoalArea(indices, scores)\n",
    "                goal_area = goal_areas[incremental_index]\n",
    "                \n",
    "                requesteds = model_Requested(indices, scores)\n",
    "                requested = requesteds[incremental_index]\n",
    "                \n",
    "                methods = model_Method(indices, scores)\n",
    "                method = methods[incremental_index]\n",
    "                \n",
    "                turn[\"goal-labels\"][\"food\"] = retrieve_output_GoalFood(goal_food, ontology)\n",
    "                turn[\"goal-labels\"][\"pricerange\"] = retrieve_output_GoalPricerange(goal_pricerange, ontology)\n",
    "                turn[\"goal-labels\"][\"name\"] = retrieve_output_GoalName(goal_name, ontology)\n",
    "                turn[\"goal-labels\"][\"area\"] = retrieve_output_GoalArea(goal_area, ontology)\n",
    "                turn[\"requested-slots\"] = retrieve_output_Requested(requested, ontology)\n",
    "                turn[\"method-label\"] = retrieve_output_Method(method, ontology)\n",
    "                \n",
    "                session[\"turns\"].append(turn)\n",
    "                \n",
    "            tracker_json[\"sessions\"].append(session)\n",
    "            \n",
    "        end_time = time.time()\n",
    "        tracker_json[\"wall-time\"] = end_time - start_time\n",
    "        \n",
    "        return tracker_json\n",
    "\n",
    "def get_scores(tracker, dataset, predictor = False):\n",
    "    goal_pricerange_accuracy = None\n",
    "    goal_pricerange_l2 = None\n",
    "    goal_area_accuracy = None\n",
    "    goal_area_l2 = None\n",
    "    goal_name_accuracy = None\n",
    "    goal_name_l2 = None\n",
    "    goal_food_accuracy = None\n",
    "    goal_food_l2 = None\n",
    "    \n",
    "    goal_accuracy = None\n",
    "    goal_l2 = None\n",
    "    requested_accuracy = None\n",
    "    requested_l2 = None\n",
    "    method_accuracy = None\n",
    "    method_l2 = None\n",
    "    \n",
    "    with open(\"tracker_panfmr_incremental.json\", \"w\") as tracker_file:\n",
    "        json.dump(tracker, tracker_file)\n",
    "    \n",
    "    if predictor:\n",
    "        \n",
    "        if dataset == \"dstc2_train\":\n",
    "            !python2 dstc2/dstc2_scripts/score_predictor.py\\\n",
    "            --dataset dstc2_train\\\n",
    "            --dataroot dstc2/dstc2_traindev/data\\\n",
    "            --ontology dstc2/dstc2_scripts/config/ontology_dstc2.json\\\n",
    "            --trackfile tracker_panfmr_incremental.json\\\n",
    "            --scorefile tracker_panfmr_incremental.score.csv\n",
    "        elif dataset == \"dstc2_dev\":\n",
    "            !python2 dstc2/dstc2_scripts/score_predictor.py\\\n",
    "            --dataset dstc2_dev\\\n",
    "            --dataroot dstc2/dstc2_traindev/data\\\n",
    "            --ontology dstc2/dstc2_scripts/config/ontology_dstc2.json\\\n",
    "            --trackfile tracker_panfmr_incremental.json\\\n",
    "            --scorefile tracker_panfmr_incremental.score.csv\n",
    "        else:\n",
    "            !python2 dstc2/dstc2_scripts/score_predictor.py\\\n",
    "            --dataset dstc2_test\\\n",
    "            --dataroot dstc2/dstc2_test/data\\\n",
    "            --ontology dstc2/dstc2_scripts/config/ontology_dstc2.json\\\n",
    "            --trackfile tracker_panfmr_incremental.json\\\n",
    "            --scorefile tracker_panfmr_incremental.score.csv\n",
    "            \n",
    "    else: # predictor == False\n",
    "        \n",
    "        if dataset == \"dstc2_train\":\n",
    "            !python2 dstc2/dstc2_scripts/score.py\\\n",
    "            --dataset dstc2_train\\\n",
    "            --dataroot dstc2/dstc2_traindev/data\\\n",
    "            --ontology dstc2/dstc2_scripts/config/ontology_dstc2.json\\\n",
    "            --trackfile tracker_panfmr_incremental.json\\\n",
    "            --scorefile tracker_panfmr_incremental.score.csv\n",
    "        elif dataset == \"dstc2_dev\":\n",
    "            !python2 dstc2/dstc2_scripts/score.py\\\n",
    "            --dataset dstc2_dev\\\n",
    "            --dataroot dstc2/dstc2_traindev/data\\\n",
    "            --ontology dstc2/dstc2_scripts/config/ontology_dstc2.json\\\n",
    "            --trackfile tracker_panfmr_incremental.json\\\n",
    "            --scorefile tracker_panfmr_incremental.score.csv\n",
    "        else:\n",
    "            !python2 dstc2/dstc2_scripts/score.py\\\n",
    "            --dataset dstc2_test\\\n",
    "            --dataroot dstc2/dstc2_test/data\\\n",
    "            --ontology dstc2/dstc2_scripts/config/ontology_dstc2.json\\\n",
    "            --trackfile tracker_panfmr_incremental.json\\\n",
    "            --scorefile tracker_panfmr_incremental.score.csv\n",
    "        \n",
    "    score_file_cat = !cat tracker_panfmr_incremental.score.csv\n",
    "    \n",
    "    for line in score_file_cat:\n",
    "        if line.startswith(\"goal.pricerange, acc, 2, a\"):\n",
    "            value = line.split(\",\")[-1]\n",
    "            if \"-\" not in value:\n",
    "                goal_pricerange_accuracy = float(value)\n",
    "        if line.startswith(\"goal.pricerange, l2, 2, a\"):\n",
    "            value = line.split(\",\")[-1]\n",
    "            if \"-\" not in value:\n",
    "                goal_pricerange_l2 = float(value)\n",
    "        if line.startswith(\"goal.area, acc, 2, a\"):\n",
    "            value = line.split(\",\")[-1]\n",
    "            if \"-\" not in value:\n",
    "                goal_area_accuracy = float(value)\n",
    "        if line.startswith(\"goal.area, l2, 2, a\"):\n",
    "            value = line.split(\",\")[-1]\n",
    "            if \"-\" not in value:\n",
    "                goal_area_l2 = float(value)\n",
    "        if line.startswith(\"goal.name, acc, 2, a\"):\n",
    "            value = line.split(\",\")[-1]\n",
    "            if \"-\" not in value:\n",
    "                goal_name_accuracy = float(value)\n",
    "        if line.startswith(\"goal.name, l2, 2, a\"):\n",
    "            value = line.split(\",\")[-1]\n",
    "            if \"-\" not in value:\n",
    "                goal_name_l2 = float(value)\n",
    "        if line.startswith(\"goal.food, acc, 2, a\"):\n",
    "            value = line.split(\",\")[-1]\n",
    "            if \"-\" not in value:\n",
    "                goal_food_accuracy = float(value)\n",
    "        if line.startswith(\"goal.food, l2, 2, a\"):\n",
    "            value = line.split(\",\")[-1]\n",
    "            if \"-\" not in value:\n",
    "                goal_food_l2 = float(value)\n",
    "        if line.startswith(\"goal.joint, acc, 2, a\"):\n",
    "            value = line.split(\",\")[-1]\n",
    "            if \"-\" not in value:\n",
    "                goal_accuracy = float(value)\n",
    "        if line.startswith(\"goal.joint, l2, 2, a\"):\n",
    "            value = line.split(\",\")[-1]\n",
    "            if \"-\" not in value:\n",
    "                goal_l2 = float(value)\n",
    "        if line.startswith(\"requested.all, acc, 2, a\"):\n",
    "            value = line.split(\",\")[-1]\n",
    "            if \"-\" not in value:\n",
    "                requested_accuracy = float(value)\n",
    "        if line.startswith(\"requested.all, l2, 2, a\"):\n",
    "            value = line.split(\",\")[-1]\n",
    "            if \"-\" not in value:\n",
    "                requested_l2 = float(value)\n",
    "        if line.startswith(\"method, acc, 2, a\"):\n",
    "            value = line.split(\",\")[-1]\n",
    "            if \"-\" not in value:\n",
    "                method_accuracy = float(value)\n",
    "        if line.startswith(\"method, l2, 2, a\"):\n",
    "            value = line.split(\",\")[-1]\n",
    "            if \"-\" not in value:\n",
    "                method_l2 = float(value)\n",
    "    \n",
    "    scores_dict = {}\n",
    "    scores_dict[\"goal_pricerange_accuracy\"] = goal_pricerange_accuracy\n",
    "    scores_dict[\"goal_pricerange_l2\"] = goal_pricerange_l2\n",
    "    scores_dict[\"goal_area_accuracy\"] = goal_area_accuracy\n",
    "    scores_dict[\"goal_area_l2\"] = goal_area_l2\n",
    "    scores_dict[\"goal_name_accuracy\"] = goal_name_accuracy\n",
    "    scores_dict[\"goal_name_l2\"] = goal_name_l2\n",
    "    scores_dict[\"goal_food_accuracy\"] = goal_food_accuracy\n",
    "    scores_dict[\"goal_food_l2\"] = goal_food_l2\n",
    "    scores_dict[\"goal_accuracy\"] = goal_accuracy\n",
    "    scores_dict[\"goal_l2\"] = goal_l2\n",
    "    scores_dict[\"requested_accuracy\"] = requested_accuracy\n",
    "    scores_dict[\"requested_l2\"] = requested_l2\n",
    "    scores_dict[\"method_accuracy\"] = method_accuracy\n",
    "    scores_dict[\"method_l2\"] = method_l2\n",
    "    \n",
    "    return scores_dict\n",
    "\n",
    "def retrieve_gold_GoalFood(raw_Y, ontology, device):\n",
    "    ontology_informable_food = ontology[\"informable\"][\"food\"]\n",
    "    raw_goal_food = raw_Y[\"goal\"][\"food\"]\n",
    "    goal_food = 0\n",
    "    if raw_goal_food != None:\n",
    "        if raw_goal_food == \"dontcare\":\n",
    "            goal_food = 1\n",
    "        else:    \n",
    "            goal_food = ontology_informable_food.index(raw_goal_food) + 2\n",
    "    return torch.tensor([goal_food], dtype = torch.long, device = device)\n",
    "\n",
    "def retrieve_output_GoalFood(output_tensor, ontology):\n",
    "    ontology_informable_food = ontology[\"informable\"][\"food\"]\n",
    "    output_tensor = output_tensor.view(-1)\n",
    "    output_tensor = torch.exp(output_tensor)\n",
    "    goal_food_dict = {}\n",
    "    \n",
    "    index = torch.argmax(output_tensor).item()\n",
    "    goal_food_dict[\"dontcare\"] = output_tensor[1].item() \n",
    "    for index in range(len(output_tensor) - 2):\n",
    "        goal_food_dict[ontology_informable_food[index]] = output_tensor[index + 2].item()\n",
    "    return goal_food_dict\n",
    "\n",
    "def retrieve_gold_GoalPricerange(raw_Y, ontology, device):\n",
    "    ontology_informable_pricerange = ontology[\"informable\"][\"pricerange\"]\n",
    "    raw_goal_pricerange = raw_Y[\"goal\"][\"pricerange\"]\n",
    "    goal_pricerange = 0\n",
    "    if raw_goal_pricerange != None:\n",
    "        if raw_goal_pricerange == \"dontcare\":\n",
    "            goal_pricerange = 1\n",
    "        else:    \n",
    "            goal_pricerange = ontology_informable_pricerange.index(raw_goal_pricerange) + 2\n",
    "    return torch.tensor([goal_pricerange], dtype = torch.long, device = device)\n",
    "\n",
    "def retrieve_output_GoalPricerange(output_tensor, ontology):\n",
    "    ontology_informable_pricerange = ontology[\"informable\"][\"pricerange\"]\n",
    "    output_tensor = output_tensor.view(-1)\n",
    "    output_tensor = torch.exp(output_tensor)\n",
    "    goal_pricerange_dict = {}\n",
    "    \n",
    "    index = torch.argmax(output_tensor).item()\n",
    "    goal_pricerange_dict[\"dontcare\"] = output_tensor[1].item()\n",
    "    for index in range(len(output_tensor) - 2):     \n",
    "        goal_pricerange_dict[ontology_informable_pricerange[index]] = output_tensor[index + 2].item()\n",
    "    return goal_pricerange_dict\n",
    "\n",
    "def retrieve_gold_GoalName(raw_Y, ontology, device):\n",
    "    ontology_informable_name = ontology[\"informable\"][\"name\"]\n",
    "    raw_goal_name = raw_Y[\"goal\"][\"name\"]\n",
    "    goal_name = 0\n",
    "    if raw_goal_name != None:\n",
    "        if raw_goal_name == \"dontcare\":\n",
    "            goal_name = 1\n",
    "        else:    \n",
    "            goal_name = ontology_informable_name.index(raw_goal_name) + 2\n",
    "    return torch.tensor([goal_name], dtype = torch.long, device = device)\n",
    "\n",
    "def retrieve_output_GoalName(output_tensor, ontology):\n",
    "    ontology_informable_name = ontology[\"informable\"][\"name\"]\n",
    "    output_tensor = output_tensor.view(-1)\n",
    "    output_tensor = torch.exp(output_tensor)\n",
    "    goal_name_dict = {}\n",
    "    \n",
    "    index = torch.argmax(output_tensor).item()\n",
    "    goal_name_dict[\"dontcare\"] = output_tensor[1].item()\n",
    "    for index in range(len(output_tensor) - 2):\n",
    "        goal_name_dict[ontology_informable_name[index]] = output_tensor[index + 2].item()\n",
    "        \n",
    "    return goal_name_dict\n",
    "\n",
    "def retrieve_gold_GoalArea(raw_Y, ontology, device):\n",
    "    ontology_informable_area = ontology[\"informable\"][\"area\"]\n",
    "    raw_goal_area = raw_Y[\"goal\"][\"area\"]\n",
    "    goal_area = 0\n",
    "    if raw_goal_area != None:\n",
    "        if raw_goal_area == \"dontcare\":\n",
    "            goal_area = 1\n",
    "        else:    \n",
    "            goal_area = ontology_informable_area.index(raw_goal_area) + 2\n",
    "    return torch.tensor([goal_area], dtype = torch.long, device = device)\n",
    "\n",
    "def retrieve_output_GoalArea(output_tensor, ontology):\n",
    "    ontology_informable_area = ontology[\"informable\"][\"area\"]\n",
    "    output_tensor = output_tensor.view(-1)\n",
    "    output_tensor = torch.exp(output_tensor)\n",
    "    goal_area_dict = {}\n",
    "    \n",
    "    index = torch.argmax(output_tensor).item()\n",
    "    goal_area_dict[\"dontcare\"] = output_tensor[1].item()\n",
    "    for index in range(len(output_tensor) - 2):\n",
    "        goal_area_dict[ontology_informable_area[index]] = output_tensor[index + 2].item()\n",
    "        \n",
    "    return goal_area_dict\n",
    "\n",
    "def retrieve_gold_Method(raw_Y, ontology, device):\n",
    "    ontology_method = ontology[\"method\"]\n",
    "    raw_gold_method = raw_Y[\"method\"]\n",
    "    gold_method = ontology_method.index(raw_gold_method)\n",
    "    return torch.tensor([gold_method], dtype = torch.long, device = device)\n",
    "\n",
    "def retrieve_output_Method(output_tensor, ontology):\n",
    "    ontology_method = ontology[\"method\"]\n",
    "    output_tensor = output_tensor.view(-1)\n",
    "    output_tensor = torch.exp(output_tensor)\n",
    "    method_dict = {}\n",
    "    \n",
    "    for index in range(len(output_tensor)):\n",
    "        method_dict[ontology_method[index]] = output_tensor[index].item()\n",
    "    \n",
    "    return method_dict\n",
    "\n",
    "def retrieve_gold_Requested(raw_Y, ontology, device):\n",
    "    ontology_requestable = ontology[\"requestable\"]\n",
    "    raw_gold_requested = raw_Y[\"requested\"]\n",
    "    gold_requested = np.zeros(len(ontology_requestable), dtype = float)\n",
    "    if len(raw_gold_requested) != 0:\n",
    "        for requested in raw_gold_requested:\n",
    "            gold_requested[ontology_requestable.index(requested)] = 1.0\n",
    "    return torch.tensor([gold_requested], dtype = torch.float, device = device)\n",
    "\n",
    "def retrieve_output_Requested(output_tensor, ontology):\n",
    "    ontology_requestable = ontology[\"requestable\"]\n",
    "    output_tensor = output_tensor.view(-1)\n",
    "    requested_dict = {}\n",
    "    for index in range(len(output_tensor)):\n",
    "        probability_value = output_tensor[index].item()\n",
    "        if np.greater_equal(probability_value, 0.5):\n",
    "            requested_dict[ontology_requestable[index]] = probability_value\n",
    "    return requested_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create vocabularies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"+--------------------------------+\")\n",
    "logging.info(\"|          Vocabulary            |\")\n",
    "logging.info(\"+--------------------------------+\")\n",
    "logging.info(\"Creating token_to_index, index_to_token and token_to_count dictionaries\")\n",
    "\n",
    "token_to_index = {\"<unk>\": 0}\n",
    "index_to_token = {0: \"<unk>\"}\n",
    "token_to_count = {\"<unk>\": 1}\n",
    "\n",
    "for raw_train_dialog in tqdm_notebook(raw_X_train):\n",
    "    \n",
    "    for raw_train_turn in raw_train_dialog[\"turns\"]:\n",
    "        \n",
    "        tokens_scores = raw_train_turn[\"system\"] + raw_train_turn[\"user\"]\n",
    "        \n",
    "        for token_score in tokens_scores:\n",
    "            token = token_score[0]\n",
    "            if token not in token_to_index:\n",
    "                token_to_index[token] = len(token_to_index)\n",
    "                index_to_token[len(token_to_index)] = token\n",
    "                token_to_count[token] = 1\n",
    "            else:\n",
    "                token_to_count[token] += 1\n",
    "                \n",
    "assert len(token_to_index) == len(index_to_token)\n",
    "assert len(token_to_index) == len(token_to_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"+--------------------------------+\")\n",
    "logging.info(\"|         Configuration          |\")\n",
    "logging.info(\"+--------------------------------+\")\n",
    "\n",
    "VOCABULARY_SIZE = len(token_to_index)\n",
    "logging.info(\"VOCABULARY_SIZE:\\t\\t\\t{}\".format(VOCABULARY_SIZE))\n",
    "\n",
    "# NOTE: +2 because of null and dontcare\n",
    "GOAL_FOOD_DIM = len(ontology[\"informable\"][\"food\"]) + 2 \n",
    "GOAL_PRICERANGE_DIM = len(ontology[\"informable\"][\"pricerange\"]) + 2\n",
    "GOAL_NAME_DIM = len(ontology[\"informable\"][\"name\"]) + 2\n",
    "GOAL_AREA_DIM = len(ontology[\"informable\"][\"area\"]) + 2\n",
    "METHOD_DIM = len(ontology[\"method\"])\n",
    "REQUESTED_DIM = len(ontology[\"requestable\"])\n",
    "EMBEDDING_DIM = 170\n",
    "ALTERED_EMBEDDING_DIM = 300\n",
    "HIDDEN_DIM = 100\n",
    "NUM_EPOCHS = 50\n",
    "BATCH_SIZE = 10\n",
    "PREDICTOR_DIM = 2\n",
    "PREDICTOR_LOSS_FUNCTION = nn.CrossEntropyLoss()\n",
    "GOAL_LOSS_FUNCTION = nn.CrossEntropyLoss()\n",
    "METHOD_LOSS_FUNCTION = nn.CrossEntropyLoss()\n",
    "REQUESTED_LOSS_FUNCTION = nn.BCELoss()\n",
    "logging.info(\"GOAL_FOOD_DIM:\\t\\t\\t{}\".format(GOAL_FOOD_DIM))\n",
    "logging.info(\"GOAL_PRICERANGE_DIM:\\t\\t\\t{}\".format(GOAL_PRICERANGE_DIM))\n",
    "logging.info(\"GOAL_NAME_DIM:\\t\\t\\t{}\".format(GOAL_NAME_DIM))\n",
    "logging.info(\"GOAL_AREA_DIM:\\t\\t\\t{}\".format(GOAL_AREA_DIM))\n",
    "logging.info(\"METHOD_DIM:\\t\\t\\t\\t{}\".format(METHOD_DIM))\n",
    "logging.info(\"REQUESTED_DIM:\\t\\t\\t{}\".format(REQUESTED_DIM))\n",
    "logging.info(\"EMBEDDING_DIM:\\t\\t\\t{}\".format(EMBEDDING_DIM))\n",
    "logging.info(\"ALTERED_EMBEDDING_DIM:\\t\\t{}\".format(ALTERED_EMBEDDING_DIM))\n",
    "logging.info(\"HIDDEN_DIM:\\t\\t\\t\\t{}\".format(HIDDEN_DIM))\n",
    "logging.info(\"NUM_EPOCHS:\\t\\t\\t\\t{}\".format(NUM_EPOCHS))\n",
    "logging.info(\"BATCH_SIZE:\\t\\t\\t\\t{}\".format(BATCH_SIZE))\n",
    "logging.info(\"PREDICTOR_DIM:\\t\\t\\t{}\".format(PREDICTOR_DIM))\n",
    "logging.info(\"PREDICTOR_LOSS_FUNCTION:\\t\\t{}\".format(PREDICTOR_LOSS_FUNCTION))\n",
    "logging.info(\"GOAL_LOSS_FUNCTION:\\t\\t\\t{}\".format(GOAL_LOSS_FUNCTION))\n",
    "logging.info(\"METHOD_LOSS_FUNCTION:\\t\\t\\t{}\".format(METHOD_LOSS_FUNCTION))\n",
    "logging.info(\"REQUESTED_LOSS_FUNCTION:\\t\\t{}\".format(REQUESTED_LOSS_FUNCTION))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal Pricerange Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoalPricerangeModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 vocabulary_size,\n",
    "                 embedding_dim,\n",
    "                 altered_embedding_dim,\n",
    "                 hidden_dim,\n",
    "                 goal_pricerange_dim,\n",
    "                 device):\n",
    "        \n",
    "        super(GoalPricerangeModel, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.goal_pricerange_dim = goal_pricerange_dim\n",
    "        self.device = device\n",
    "        \n",
    "        self.embeddings = nn.Embedding(num_embeddings = vocabulary_size,\n",
    "                                       embedding_dim = embedding_dim)\n",
    "        \n",
    "        self.altered_embeddings = nn.Linear(in_features = (embedding_dim + 1),\n",
    "                                            out_features = altered_embedding_dim)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size = altered_embedding_dim,\n",
    "                            hidden_size = hidden_dim)\n",
    "        \n",
    "        self.goal_pricerange_classifier = nn.Linear(in_features = hidden_dim,\n",
    "                                                    out_features = goal_pricerange_dim)\n",
    "        \n",
    "        self.hidden = self.init_hidden()\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        \n",
    "        return (torch.zeros(1, 1, self.hidden_dim, device = self.device),\n",
    "                torch.zeros(1, 1, self.hidden_dim, device = self.device))\n",
    "        \n",
    "    def forward(self, indices, scores):\n",
    "    \n",
    "        embeddings = self.embeddings(indices)\n",
    "        \n",
    "        embeddings_concat_score = torch.cat((embeddings, scores.unsqueeze(dim = 1)), dim = 1) \n",
    "        \n",
    "        altered_embeddings = F.relu(self.altered_embeddings(embeddings_concat_score))\n",
    "        \n",
    "        lstm_out, self.hidden = self.lstm(altered_embeddings.view(len(indices), 1, -1), self.hidden)\n",
    "        \n",
    "        goal_pricerange = F.log_softmax(self.goal_pricerange_classifier(lstm_out).view(-1, self.goal_pricerange_dim), dim = 1) \n",
    "        \n",
    "        return goal_pricerange\n",
    "\n",
    "model_GoalPricerange = GoalPricerangeModel(vocabulary_size = VOCABULARY_SIZE,\n",
    "                                           embedding_dim = EMBEDDING_DIM,\n",
    "                                           altered_embedding_dim = ALTERED_EMBEDDING_DIM,\n",
    "                                           hidden_dim = HIDDEN_DIM,\n",
    "                                           goal_pricerange_dim = GOAL_PRICERANGE_DIM,\n",
    "                                           device = DEVICE)\n",
    "\n",
    "model_GoalPricerange = model_GoalPricerange.to(DEVICE)\n",
    "\n",
    "optimizer_GoalPricerangeModel = optim.Adam(model_GoalPricerange.parameters(), lr = 1e-3, amsgrad = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal Area Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoalAreaModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 vocabulary_size,\n",
    "                 embedding_dim,\n",
    "                 altered_embedding_dim,\n",
    "                 hidden_dim,\n",
    "                 goal_area_dim,\n",
    "                 device):\n",
    "        \n",
    "        super(GoalAreaModel, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.goal_area_dim = goal_area_dim\n",
    "        self.device = device\n",
    "        \n",
    "        self.embeddings = nn.Embedding(num_embeddings = vocabulary_size,\n",
    "                                       embedding_dim = embedding_dim)\n",
    "        \n",
    "        self.altered_embeddings = nn.Linear(in_features = (embedding_dim + 1),\n",
    "                                            out_features = altered_embedding_dim)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size = altered_embedding_dim,\n",
    "                            hidden_size = hidden_dim)\n",
    "        \n",
    "        self.goal_area_classifier = nn.Linear(in_features = hidden_dim,\n",
    "                                              out_features = goal_area_dim)\n",
    "        \n",
    "        self.hidden = self.init_hidden()\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        \n",
    "        return (torch.zeros(1, 1, self.hidden_dim, device = self.device),\n",
    "                torch.zeros(1, 1, self.hidden_dim, device = self.device))\n",
    "        \n",
    "    def forward(self, indices, scores):\n",
    "    \n",
    "        embeddings = self.embeddings(indices)\n",
    "        \n",
    "        embeddings_concat_score = torch.cat((embeddings, scores.unsqueeze(dim = 1)), dim = 1) \n",
    "        \n",
    "        altered_embeddings = F.relu(self.altered_embeddings(embeddings_concat_score))\n",
    "        \n",
    "        lstm_out, self.hidden = self.lstm(altered_embeddings.view(len(indices), 1, -1), self.hidden)\n",
    "        \n",
    "        goal_area = F.log_softmax(self.goal_area_classifier(lstm_out).view(-1, self.goal_area_dim), dim = 1)\n",
    "        \n",
    "        return goal_area\n",
    "\n",
    "model_GoalArea = GoalAreaModel(vocabulary_size = VOCABULARY_SIZE,\n",
    "                               embedding_dim = EMBEDDING_DIM,\n",
    "                               altered_embedding_dim = ALTERED_EMBEDDING_DIM,\n",
    "                               hidden_dim = HIDDEN_DIM,\n",
    "                               goal_area_dim = GOAL_AREA_DIM,\n",
    "                               device = DEVICE)\n",
    "\n",
    "model_GoalArea = model_GoalArea.to(DEVICE)\n",
    "\n",
    "optimizer_GoalAreaModel = optim.Adam(model_GoalArea.parameters(), lr = 1e-3, amsgrad = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal Name Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoalNameModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 vocabulary_size,\n",
    "                 embedding_dim,\n",
    "                 altered_embedding_dim,\n",
    "                 hidden_dim,\n",
    "                 goal_name_dim,\n",
    "                 device):\n",
    "        \n",
    "        super(GoalNameModel, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.goal_name_dim = goal_name_dim\n",
    "        self.device = device\n",
    "        \n",
    "        self.embeddings = nn.Embedding(num_embeddings = vocabulary_size,\n",
    "                                       embedding_dim = embedding_dim)\n",
    "        \n",
    "        self.altered_embeddings = nn.Linear(in_features = (embedding_dim + 1),\n",
    "                                            out_features = altered_embedding_dim)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size = altered_embedding_dim,\n",
    "                            hidden_size = hidden_dim)\n",
    "        \n",
    "        self.goal_name_classifier = nn.Linear(in_features = hidden_dim,\n",
    "                                              out_features = goal_name_dim)\n",
    "        \n",
    "        self.hidden = self.init_hidden()\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        \n",
    "        return (torch.zeros(1, 1, self.hidden_dim, device = self.device),\n",
    "                torch.zeros(1, 1, self.hidden_dim, device = self.device))\n",
    "        \n",
    "    def forward(self, indices, scores):\n",
    "    \n",
    "        embeddings = self.embeddings(indices)\n",
    "        \n",
    "        embeddings_concat_score = torch.cat((embeddings, scores.unsqueeze(dim = 1)), dim = 1) \n",
    "        \n",
    "        altered_embeddings = F.relu(self.altered_embeddings(embeddings_concat_score))\n",
    "        \n",
    "        lstm_out, self.hidden = self.lstm(altered_embeddings.view(len(indices), 1, -1), self.hidden)\n",
    "        \n",
    "        goal_name = F.log_softmax(self.goal_name_classifier(lstm_out).view(-1, self.goal_name_dim), dim = 1)\n",
    "        \n",
    "        return goal_name\n",
    "\n",
    "model_GoalName = GoalNameModel(vocabulary_size = VOCABULARY_SIZE,\n",
    "                               embedding_dim = EMBEDDING_DIM,\n",
    "                               altered_embedding_dim = ALTERED_EMBEDDING_DIM,\n",
    "                               hidden_dim = HIDDEN_DIM,\n",
    "                               goal_name_dim = GOAL_NAME_DIM,\n",
    "                               device = DEVICE)\n",
    "\n",
    "model_GoalName = model_GoalName.to(DEVICE)\n",
    "\n",
    "optimizer_GoalNameModel = optim.Adam(model_GoalName.parameters(), lr = 1e-3, amsgrad = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal Food Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoalFoodModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 vocabulary_size,\n",
    "                 embedding_dim,\n",
    "                 altered_embedding_dim,\n",
    "                 hidden_dim,\n",
    "                 goal_food_dim,\n",
    "                 device):\n",
    "        \n",
    "        super(GoalFoodModel, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.goal_food_dim = goal_food_dim\n",
    "        self.device = device\n",
    "        \n",
    "        self.embeddings = nn.Embedding(num_embeddings = vocabulary_size,\n",
    "                                       embedding_dim = embedding_dim)\n",
    "        \n",
    "        self.altered_embeddings = nn.Linear(in_features = (embedding_dim + 1),\n",
    "                                            out_features = altered_embedding_dim)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size = altered_embedding_dim,\n",
    "                            hidden_size = hidden_dim)\n",
    "        \n",
    "        self.goal_food_classifier = nn.Linear(in_features = hidden_dim,\n",
    "                                              out_features = goal_food_dim)\n",
    "        \n",
    "        self.hidden = self.init_hidden()\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        \n",
    "        return (torch.zeros(1, 1, self.hidden_dim, device = self.device),\n",
    "                torch.zeros(1, 1, self.hidden_dim, device = self.device))\n",
    "        \n",
    "    def forward(self, indices, scores):\n",
    "    \n",
    "        embeddings = self.embeddings(indices)\n",
    "        \n",
    "        embeddings_concat_score = torch.cat((embeddings, scores.unsqueeze(dim = 1)), dim = 1) \n",
    "        \n",
    "        altered_embeddings = F.relu(self.altered_embeddings(embeddings_concat_score))\n",
    "        \n",
    "        lstm_out, self.hidden = self.lstm(altered_embeddings.view(len(indices), 1, -1), self.hidden)\n",
    "        \n",
    "        goal_food = F.log_softmax(self.goal_food_classifier(lstm_out).view(-1, self.goal_food_dim), dim = 1)        \n",
    "        \n",
    "        return goal_food\n",
    "\n",
    "model_GoalFood = GoalFoodModel(vocabulary_size = VOCABULARY_SIZE,\n",
    "                               embedding_dim = EMBEDDING_DIM,\n",
    "                               altered_embedding_dim = ALTERED_EMBEDDING_DIM,\n",
    "                               hidden_dim = HIDDEN_DIM,\n",
    "                               goal_food_dim = GOAL_FOOD_DIM,\n",
    "                               device = DEVICE)\n",
    "\n",
    "model_GoalFood = model_GoalFood.to(DEVICE)\n",
    "\n",
    "optimizer_GoalFoodModel = optim.Adam(model_GoalFood.parameters(), lr = 1e-3, amsgrad = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requested Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RequestedModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 vocabulary_size,\n",
    "                 embedding_dim,\n",
    "                 altered_embedding_dim,\n",
    "                 hidden_dim,\n",
    "                 requested_dim,\n",
    "                 device):\n",
    "        \n",
    "        super(RequestedModel, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.requested_dim = requested_dim\n",
    "        self.device = device\n",
    "        \n",
    "        self.embeddings = nn.Embedding(num_embeddings = vocabulary_size,\n",
    "                                       embedding_dim = embedding_dim)\n",
    "        \n",
    "        self.altered_embeddings = nn.Linear(in_features = (embedding_dim + 1),\n",
    "                                            out_features = altered_embedding_dim)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size = altered_embedding_dim,\n",
    "                            hidden_size = hidden_dim)\n",
    "        \n",
    "        self.requested_classifier = nn.Linear(in_features = hidden_dim,\n",
    "                                              out_features = requested_dim)\n",
    "        \n",
    "        self.hidden = self.init_hidden()\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        \n",
    "        return (torch.zeros(1, 1, self.hidden_dim, device = self.device),\n",
    "                torch.zeros(1, 1, self.hidden_dim, device = self.device))\n",
    "        \n",
    "    def forward(self, indices, scores):\n",
    "    \n",
    "        embeddings = self.embeddings(indices)\n",
    "        \n",
    "        embeddings_concat_score = torch.cat((embeddings, scores.unsqueeze(dim = 1)), dim = 1) \n",
    "        \n",
    "        altered_embeddings = F.relu(self.altered_embeddings(embeddings_concat_score))\n",
    "        \n",
    "        lstm_out, self.hidden = self.lstm(altered_embeddings.view(len(indices), 1, -1), self.hidden)\n",
    "        \n",
    "        requested = torch.sigmoid(self.requested_classifier(lstm_out).view(-1, self.requested_dim))\n",
    "        \n",
    "        return requested\n",
    "\n",
    "model_Requested = RequestedModel(vocabulary_size = VOCABULARY_SIZE,\n",
    "                                 embedding_dim = EMBEDDING_DIM,\n",
    "                                 altered_embedding_dim = ALTERED_EMBEDDING_DIM,\n",
    "                                 hidden_dim = HIDDEN_DIM,\n",
    "                                 requested_dim = REQUESTED_DIM,\n",
    "                                 device = DEVICE)\n",
    "\n",
    "model_Requested = model_Requested.to(DEVICE)\n",
    "\n",
    "optimizer_RequestedModel = optim.Adam(model_Requested.parameters(), lr = 1e-3, amsgrad = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MethodModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 vocabulary_size,\n",
    "                 embedding_dim,\n",
    "                 altered_embedding_dim,\n",
    "                 hidden_dim,\n",
    "                 method_dim,\n",
    "                 device):\n",
    "        \n",
    "        super(MethodModel, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.method_dim = method_dim\n",
    "        self.device = device\n",
    "        \n",
    "        self.embeddings = nn.Embedding(num_embeddings = vocabulary_size,\n",
    "                                       embedding_dim = embedding_dim)\n",
    "        \n",
    "        self.altered_embeddings = nn.Linear(in_features = (embedding_dim + 1),\n",
    "                                            out_features = altered_embedding_dim)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size = altered_embedding_dim,\n",
    "                            hidden_size = hidden_dim)\n",
    "        \n",
    "        self.method_classifier = nn.Linear(in_features = hidden_dim,\n",
    "                                           out_features = method_dim)\n",
    "        \n",
    "        self.hidden = self.init_hidden()\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        \n",
    "        return (torch.zeros(1, 1, self.hidden_dim, device = self.device),\n",
    "                torch.zeros(1, 1, self.hidden_dim, device = self.device))\n",
    "        \n",
    "    def forward(self, indices, scores):\n",
    "    \n",
    "        embeddings = self.embeddings(indices)\n",
    "        \n",
    "        embeddings_concat_score = torch.cat((embeddings, scores.unsqueeze(dim = 1)), dim = 1) \n",
    "        \n",
    "        altered_embeddings = F.relu(self.altered_embeddings(embeddings_concat_score))\n",
    "        \n",
    "        lstm_out, self.hidden = self.lstm(altered_embeddings.view(len(indices), 1, -1), self.hidden)\n",
    "        \n",
    "        method = F.log_softmax(self.method_classifier(lstm_out).view(-1, self.method_dim), dim = 1)\n",
    "        \n",
    "        return method\n",
    "\n",
    "model_Method = MethodModel(vocabulary_size = VOCABULARY_SIZE,\n",
    "                           embedding_dim = EMBEDDING_DIM,\n",
    "                           altered_embedding_dim = ALTERED_EMBEDDING_DIM,\n",
    "                           hidden_dim = HIDDEN_DIM,\n",
    "                           method_dim = METHOD_DIM,\n",
    "                           device = DEVICE)\n",
    "\n",
    "model_Method = model_Method.to(DEVICE)\n",
    "\n",
    "optimizer_MethodModel = optim.Adam(model_Method.parameters(), lr = 1e-3, amsgrad = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Goal Pricerange Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dev_goal_accuracies = []\n",
    "dev_requested_accuracies = []\n",
    "dev_method_accuracies = []\n",
    "\n",
    "goal_pricerange_early_stopping = EarlyStopping(patience = 4)\n",
    "\n",
    "train_indices_loader = torch.utils.data.DataLoader(np.arange(raw_X_train.shape[0]), batch_size = BATCH_SIZE, shuffle = True)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    logging.info(\"Epoch\\t{}/{}\".format(epoch + 1, NUM_EPOCHS))\n",
    "    \n",
    "    model_GoalPricerange = model_GoalPricerange.train()\n",
    "    \n",
    "    for train_indices in tqdm_notebook(train_indices_loader, total = len(train_indices_loader)):\n",
    "        \n",
    "        optimizer_GoalPricerangeModel.zero_grad()\n",
    "\n",
    "        dialogs_loss = 0\n",
    "    \n",
    "        for raw_X_train_dialog, raw_Y_train_dialog in zip(raw_X_train[train_indices], raw_Y_train[train_indices]):\n",
    "\n",
    "            model_GoalPricerange.hidden = model_GoalPricerange.init_hidden()\n",
    "\n",
    "            for raw_X_train_turn, raw_Y_train_turn in zip(raw_X_train_dialog[\"turns\"], raw_Y_train_dialog[\"turns\"]):\n",
    "\n",
    "                indices, scores = get_index_and_score(raw_X_train_turn, token_to_index, mode = \"train\", device = DEVICE)\n",
    "\n",
    "                goal_priceranges = model_GoalPricerange(indices, scores)\n",
    "\n",
    "                for goal_pricerange in goal_priceranges:\n",
    "\n",
    "                    goal_pricerange = goal_pricerange.unsqueeze(0)\n",
    "\n",
    "                    loss_goal_pricerange = GOAL_LOSS_FUNCTION(goal_pricerange,\n",
    "                                                              retrieve_gold_GoalPricerange(raw_Y_train_turn,\n",
    "                                                                                           ontology = ontology,\n",
    "                                                                                           device = DEVICE))\n",
    "                    dialogs_loss += loss_goal_pricerange\n",
    "\n",
    "        dialogs_loss.backward(retain_graph = False)\n",
    "\n",
    "        optimizer_GoalPricerangeModel.step()\n",
    "        \n",
    "    dev_tracker = make_tracker(model_GoalPricerange,\n",
    "                       model_GoalArea,\n",
    "                       model_GoalName,\n",
    "                       model_GoalFood,\n",
    "                       model_Requested,\n",
    "                       model_Method,\n",
    "                       raw_X_dev, raw_Y_dev, dataset = \"dstc2_dev\", percentage = 1.0)\n",
    "    dev_scores_dict = get_scores(dev_tracker, dataset = \"dstc2_dev\")\n",
    "    \n",
    "    logging.info(\"DEV Goal Pricerange Acc: {}\".format(dev_scores_dict[\"goal_pricerange_accuracy\"]))\n",
    "    \n",
    "    logging.info(\"DEV Acc:\\t\\t{}({})\\t\\t{}({})\\t\\t{}({})\".format(dev_scores_dict[\"goal_accuracy\"],\n",
    "                                                                 np.around(dev_scores_dict[\"goal_accuracy\"], decimals = 2),\n",
    "                                                                 dev_scores_dict[\"requested_accuracy\"],\n",
    "                                                                 np.around(dev_scores_dict[\"requested_accuracy\"], decimals = 2),\n",
    "                                                                 dev_scores_dict[\"method_accuracy\"],\n",
    "                                                                 np.around(dev_scores_dict[\"method_accuracy\"], decimals = 2)))\n",
    "    logging.info(\"DEV L2:\\t\\t{}({})\\t\\t{}({})\\t\\t{}({})\".format(dev_scores_dict[\"goal_l2\"],\n",
    "                                                                np.around(dev_scores_dict[\"goal_l2\"], decimals = 2),\n",
    "                                                                dev_scores_dict[\"requested_l2\"],\n",
    "                                                                np.around(dev_scores_dict[\"requested_l2\"], decimals = 2),\n",
    "                                                                dev_scores_dict[\"method_l2\"],\n",
    "                                                                np.around(dev_scores_dict[\"method_l2\"], decimals = 2)))\n",
    "\n",
    "    goal_pricerange_early_stopping.on_epoch_end(epoch = (epoch + 1), current_value = (dev_scores_dict[\"goal_pricerange_accuracy\"]))\n",
    "    \n",
    "    if goal_pricerange_early_stopping.wait == 0:\n",
    "        torch.save(model_GoalPricerange.state_dict(), \"model_PANFMR_incremental_GoalPricerange.pt\")\n",
    "    \n",
    "    if goal_pricerange_early_stopping.stop_training:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Goal Pricerange Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GoalPricerange = GoalPricerangeModel(vocabulary_size = VOCABULARY_SIZE,\n",
    "                                           embedding_dim = EMBEDDING_DIM,\n",
    "                                           altered_embedding_dim = ALTERED_EMBEDDING_DIM,\n",
    "                                           hidden_dim = HIDDEN_DIM,\n",
    "                                           goal_pricerange_dim = GOAL_PRICERANGE_DIM,\n",
    "                                           device = DEVICE)\n",
    "\n",
    "model_GoalPricerange = model_GoalPricerange.to(DEVICE)\n",
    "model_GoalPricerange.load_state_dict(torch.load(\"model_PANFMR_incremental_GoalPricerange.pt\"))\n",
    "model_GoalPricerange.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Print scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_tracker = make_tracker(model_GoalPricerange,\n",
    "                           model_GoalArea,\n",
    "                           model_GoalName,\n",
    "                           model_GoalFood,\n",
    "                           model_Requested,\n",
    "                           model_Method,\n",
    "                           raw_X_dev, raw_Y_dev, dataset = \"dstc2_dev\", percentage = 1.0)\n",
    "get_scores(dev_tracker, dataset = \"dstc2_dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tracker = make_tracker(model_GoalPricerange,\n",
    "                            model_GoalArea,\n",
    "                            model_GoalName,\n",
    "                            model_GoalFood,\n",
    "                            model_Requested,\n",
    "                            model_Method,\n",
    "                            raw_X_test, raw_Y_test, dataset = \"dstc2_test\", percentage = 1.0)\n",
    "get_scores(test_tracker, dataset = \"dstc2_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Goal Area Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dev_goal_accuracies = []\n",
    "dev_requested_accuracies = []\n",
    "dev_method_accuracies = []\n",
    "\n",
    "goal_area_early_stopping = EarlyStopping(patience = 4)\n",
    "\n",
    "train_indices_loader = torch.utils.data.DataLoader(np.arange(raw_X_train.shape[0]), batch_size = BATCH_SIZE, shuffle = True)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    logging.info(\"Epoch\\t{}/{}\".format(epoch + 1, NUM_EPOCHS))\n",
    "    \n",
    "    model_GoalArea = model_GoalArea.train()\n",
    "    \n",
    "    for train_indices in tqdm_notebook(train_indices_loader, total = len(train_indices_loader)):\n",
    "        \n",
    "        optimizer_GoalAreaModel.zero_grad()\n",
    "\n",
    "        dialogs_loss = 0\n",
    "    \n",
    "        for raw_X_train_dialog, raw_Y_train_dialog in zip(raw_X_train[train_indices], raw_Y_train[train_indices]):\n",
    "\n",
    "            model_GoalArea.hidden = model_GoalArea.init_hidden()\n",
    "\n",
    "            for raw_X_train_turn, raw_Y_train_turn in zip(raw_X_train_dialog[\"turns\"], raw_Y_train_dialog[\"turns\"]):\n",
    "\n",
    "                indices, scores = get_index_and_score(raw_X_train_turn, token_to_index, mode = \"train\", device = DEVICE)\n",
    "\n",
    "                goal_areas = model_GoalArea(indices, scores)\n",
    "\n",
    "                for goal_area in goal_areas:\n",
    "\n",
    "                    goal_area = goal_area.unsqueeze(0)\n",
    "\n",
    "                    loss_goal_area = GOAL_LOSS_FUNCTION(goal_area,\n",
    "                                                        retrieve_gold_GoalArea(raw_Y_train_turn,\n",
    "                                                                               ontology = ontology,\n",
    "                                                                               device = DEVICE))\n",
    "                    dialogs_loss += loss_goal_area\n",
    "\n",
    "        dialogs_loss.backward(retain_graph = False)\n",
    "\n",
    "        optimizer_GoalAreaModel.step()\n",
    "    \n",
    "    dev_tracker = make_tracker(model_GoalPricerange,\n",
    "                   model_GoalArea,\n",
    "                   model_GoalName,\n",
    "                   model_GoalFood,\n",
    "                   model_Requested,\n",
    "                   model_Method,\n",
    "                   raw_X_dev, raw_Y_dev, dataset = \"dstc2_dev\", percentage = 1.0)\n",
    "    dev_scores_dict = get_scores(dev_tracker, dataset = \"dstc2_dev\")\n",
    "\n",
    "    logging.info(\"DEV Goal Area Acc: {}\".format(dev_scores_dict[\"goal_area_accuracy\"]))\n",
    "\n",
    "    logging.info(\"DEV Acc:\\t\\t{}({})\\t\\t{}({})\\t\\t{}({})\".format(dev_scores_dict[\"goal_accuracy\"],\n",
    "                                                                 np.around(dev_scores_dict[\"goal_accuracy\"], decimals = 2),\n",
    "                                                                 dev_scores_dict[\"requested_accuracy\"],\n",
    "                                                                 np.around(dev_scores_dict[\"requested_accuracy\"], decimals = 2),\n",
    "                                                                 dev_scores_dict[\"method_accuracy\"],\n",
    "                                                                 np.around(dev_scores_dict[\"method_accuracy\"], decimals = 2)))\n",
    "    logging.info(\"DEV L2:\\t\\t{}({})\\t\\t{}({})\\t\\t{}({})\".format(dev_scores_dict[\"goal_l2\"],\n",
    "                                                                np.around(dev_scores_dict[\"goal_l2\"], decimals = 2),\n",
    "                                                                dev_scores_dict[\"requested_l2\"],\n",
    "                                                                np.around(dev_scores_dict[\"requested_l2\"], decimals = 2),\n",
    "                                                                dev_scores_dict[\"method_l2\"],\n",
    "                                                                np.around(dev_scores_dict[\"method_l2\"], decimals = 2)))\n",
    "\n",
    "    goal_area_early_stopping.on_epoch_end(epoch = (epoch + 1), current_value = (dev_scores_dict[\"goal_area_accuracy\"]))\n",
    "    \n",
    "    if goal_area_early_stopping.wait == 0:\n",
    "        torch.save(model_GoalArea.state_dict(), \"model_PANFMR_incremental_GoalArea.pt\")\n",
    "    \n",
    "    if goal_area_early_stopping.stop_training:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Goal Area Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GoalArea = GoalAreaModel(vocabulary_size = VOCABULARY_SIZE,\n",
    "                               embedding_dim = EMBEDDING_DIM,\n",
    "                               altered_embedding_dim = ALTERED_EMBEDDING_DIM,\n",
    "                               hidden_dim = HIDDEN_DIM,\n",
    "                               goal_area_dim = GOAL_AREA_DIM,\n",
    "                               device = DEVICE)\n",
    "\n",
    "model_GoalArea = model_GoalArea.to(DEVICE)\n",
    "model_GoalArea.load_state_dict(torch.load(\"model_PANFMR_incremental_GoalArea.pt\"))\n",
    "model_GoalArea.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_tracker = make_tracker(model_GoalPricerange,\n",
    "                           model_GoalArea,\n",
    "                           model_GoalName,\n",
    "                           model_GoalFood,\n",
    "                           model_Requested,\n",
    "                           model_Method,\n",
    "                           raw_X_dev, raw_Y_dev, dataset = \"dstc2_dev\", percentage = 1.0)\n",
    "get_scores(dev_tracker, dataset = \"dstc2_dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tracker = make_tracker(model_GoalPricerange,\n",
    "                            model_GoalArea,\n",
    "                            model_GoalName,\n",
    "                            model_GoalFood,\n",
    "                            model_Requested,\n",
    "                            model_Method,\n",
    "                            raw_X_test, raw_Y_test, dataset = \"dstc2_test\", percentage = 1.0)\n",
    "get_scores(test_tracker, dataset = \"dstc2_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Goal Name Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dev_goal_accuracies = []\n",
    "dev_requested_accuracies = []\n",
    "dev_method_accuracies = []\n",
    "\n",
    "goal_name_early_stopping = EarlyStopping(patience = 4)\n",
    "\n",
    "train_indices_loader = torch.utils.data.DataLoader(np.arange(raw_X_train.shape[0]), batch_size = BATCH_SIZE, shuffle = True)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    logging.info(\"Epoch\\t{}/{}\".format(epoch + 1, NUM_EPOCHS))\n",
    "    \n",
    "    model_GoalName = model_GoalName.train()\n",
    "    \n",
    "    for train_indices in tqdm_notebook(train_indices_loader, total = len(train_indices_loader)):\n",
    "        \n",
    "        optimizer_GoalNameModel.zero_grad()\n",
    "\n",
    "        dialogs_loss = 0\n",
    "    \n",
    "        for raw_X_train_dialog, raw_Y_train_dialog in zip(raw_X_train[train_indices], raw_Y_train[train_indices]):\n",
    "\n",
    "            model_GoalName.hidden = model_GoalName.init_hidden()\n",
    "\n",
    "            for raw_X_train_turn, raw_Y_train_turn in zip(raw_X_train_dialog[\"turns\"], raw_Y_train_dialog[\"turns\"]):\n",
    "\n",
    "                indices, scores = get_index_and_score(raw_X_train_turn, token_to_index, mode = \"train\", device = DEVICE)\n",
    "\n",
    "                goal_names = model_GoalName(indices, scores)\n",
    "\n",
    "                for goal_name in goal_names:\n",
    "\n",
    "                    goal_name = goal_name.unsqueeze(0)\n",
    "\n",
    "                    loss_goal_name = GOAL_LOSS_FUNCTION(goal_name,\n",
    "                                                        retrieve_gold_GoalName(raw_Y_train_turn,\n",
    "                                                                               ontology = ontology,\n",
    "                                                                               device = DEVICE))\n",
    "                    dialogs_loss += loss_goal_name\n",
    "\n",
    "        dialogs_loss.backward(retain_graph = False)\n",
    "\n",
    "        optimizer_GoalNameModel.step()\n",
    "    \n",
    "    dev_tracker = make_tracker(model_GoalPricerange,\n",
    "                   model_GoalArea,\n",
    "                   model_GoalName,\n",
    "                   model_GoalFood,\n",
    "                   model_Requested,\n",
    "                   model_Method,\n",
    "                   raw_X_dev, raw_Y_dev, dataset = \"dstc2_dev\", percentage = 1.0)\n",
    "    dev_scores_dict = get_scores(dev_tracker, dataset = \"dstc2_dev\")\n",
    "\n",
    "    logging.info(\"DEV Goal Name Acc: {}\".format(dev_scores_dict[\"goal_name_accuracy\"]))\n",
    "\n",
    "    logging.info(\"DEV Acc:\\t\\t{}({})\\t\\t{}({})\\t\\t{}({})\".format(dev_scores_dict[\"goal_accuracy\"],\n",
    "                                                                 np.around(dev_scores_dict[\"goal_accuracy\"], decimals = 2),\n",
    "                                                                 dev_scores_dict[\"requested_accuracy\"],\n",
    "                                                                 np.around(dev_scores_dict[\"requested_accuracy\"], decimals = 2),\n",
    "                                                                 dev_scores_dict[\"method_accuracy\"],\n",
    "                                                                 np.around(dev_scores_dict[\"method_accuracy\"], decimals = 2)))\n",
    "    logging.info(\"DEV L2:\\t\\t{}({})\\t\\t{}({})\\t\\t{}({})\".format(dev_scores_dict[\"goal_l2\"],\n",
    "                                                                np.around(dev_scores_dict[\"goal_l2\"], decimals = 2),\n",
    "                                                                dev_scores_dict[\"requested_l2\"],\n",
    "                                                                np.around(dev_scores_dict[\"requested_l2\"], decimals = 2),\n",
    "                                                                dev_scores_dict[\"method_l2\"],\n",
    "                                                                np.around(dev_scores_dict[\"method_l2\"], decimals = 2)))\n",
    "\n",
    "    goal_name_early_stopping.on_epoch_end(epoch = (epoch + 1), current_value = (dev_scores_dict[\"goal_name_accuracy\"]))\n",
    "    \n",
    "    if goal_name_early_stopping.wait == 0:\n",
    "        torch.save(model_GoalName.state_dict(), \"model_PANFMR_incremental_GoalName.pt\")\n",
    "    \n",
    "    if goal_name_early_stopping.stop_training:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Goal Name Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GoalName = GoalNameModel(vocabulary_size = VOCABULARY_SIZE,\n",
    "                               embedding_dim = EMBEDDING_DIM,\n",
    "                               altered_embedding_dim = ALTERED_EMBEDDING_DIM,\n",
    "                               hidden_dim = HIDDEN_DIM,\n",
    "                               goal_name_dim = GOAL_NAME_DIM,\n",
    "                               device = DEVICE)\n",
    "\n",
    "model_GoalName = model_GoalName.to(DEVICE)\n",
    "model_GoalName.load_state_dict(torch.load(\"model_PANFMR_incremental_GoalName.pt\"))\n",
    "model_GoalName.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_tracker = make_tracker(model_GoalPricerange,\n",
    "                           model_GoalArea,\n",
    "                           model_GoalName,\n",
    "                           model_GoalFood,\n",
    "                           model_Requested,\n",
    "                           model_Method,\n",
    "                           raw_X_dev, raw_Y_dev, dataset = \"dstc2_dev\", percentage = 1.0)\n",
    "get_scores(dev_tracker, dataset = \"dstc2_dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tracker = make_tracker(model_GoalPricerange,\n",
    "                            model_GoalArea,\n",
    "                            model_GoalName,\n",
    "                            model_GoalFood,\n",
    "                            model_Requested,\n",
    "                            model_Method,\n",
    "                            raw_X_test, raw_Y_test, dataset = \"dstc2_test\", percentage = 1.0)\n",
    "get_scores(test_tracker, dataset = \"dstc2_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Goal Food Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dev_goal_accuracies = []\n",
    "dev_requested_accuracies = []\n",
    "dev_method_accuracies = []\n",
    "\n",
    "goal_food_early_stopping = EarlyStopping(patience = 6)\n",
    "\n",
    "train_indices_loader = torch.utils.data.DataLoader(np.arange(raw_X_train.shape[0]), batch_size = BATCH_SIZE, shuffle = True)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    logging.info(\"Epoch\\t{}/{}\".format(epoch + 1, NUM_EPOCHS))\n",
    "    \n",
    "    model_GoalFood = model_GoalFood.train()\n",
    "    \n",
    "    for train_indices in tqdm_notebook(train_indices_loader, total = len(train_indices_loader)):\n",
    "        \n",
    "        optimizer_GoalFoodModel.zero_grad()\n",
    "\n",
    "        dialogs_loss = 0\n",
    "    \n",
    "        for raw_X_train_dialog, raw_Y_train_dialog in zip(raw_X_train[train_indices], raw_Y_train[train_indices]):\n",
    "\n",
    "            model_GoalFood.hidden = model_GoalFood.init_hidden()\n",
    "\n",
    "            for raw_X_train_turn, raw_Y_train_turn in zip(raw_X_train_dialog[\"turns\"], raw_Y_train_dialog[\"turns\"]):\n",
    "\n",
    "                indices, scores = get_index_and_score(raw_X_train_turn, token_to_index, mode = \"train\", device = DEVICE)\n",
    "\n",
    "                goal_foods = model_GoalFood(indices, scores)\n",
    "\n",
    "                for goal_food in goal_foods:\n",
    "\n",
    "                    goal_food = goal_food.unsqueeze(0)\n",
    "\n",
    "                    loss_goal_food = GOAL_LOSS_FUNCTION(goal_food,\n",
    "                                                        retrieve_gold_GoalFood(raw_Y_train_turn,\n",
    "                                                                               ontology = ontology,\n",
    "                                                                               device = DEVICE))\n",
    "                    dialogs_loss += loss_goal_food\n",
    "\n",
    "        dialogs_loss.backward(retain_graph = False)\n",
    "\n",
    "        optimizer_GoalFoodModel.step()\n",
    "    \n",
    "    dev_tracker = make_tracker(model_GoalPricerange,\n",
    "                   model_GoalArea,\n",
    "                   model_GoalName,\n",
    "                   model_GoalFood,\n",
    "                   model_Requested,\n",
    "                   model_Method,\n",
    "                   raw_X_dev, raw_Y_dev, dataset = \"dstc2_dev\", percentage = 1.0)\n",
    "    dev_scores_dict = get_scores(dev_tracker, dataset = \"dstc2_dev\")\n",
    "\n",
    "    logging.info(\"DEV Goal Food Acc: {}\".format(dev_scores_dict[\"goal_food_accuracy\"]))\n",
    "\n",
    "    logging.info(\"DEV Acc:\\t\\t{}({})\\t\\t{}({})\\t\\t{}({})\".format(dev_scores_dict[\"goal_accuracy\"],\n",
    "                                                                 np.around(dev_scores_dict[\"goal_accuracy\"], decimals = 2),\n",
    "                                                                 dev_scores_dict[\"requested_accuracy\"],\n",
    "                                                                 np.around(dev_scores_dict[\"requested_accuracy\"], decimals = 2),\n",
    "                                                                 dev_scores_dict[\"method_accuracy\"],\n",
    "                                                                 np.around(dev_scores_dict[\"method_accuracy\"], decimals = 2)))\n",
    "    logging.info(\"DEV L2:\\t\\t{}({})\\t\\t{}({})\\t\\t{}({})\".format(dev_scores_dict[\"goal_l2\"],\n",
    "                                                                np.around(dev_scores_dict[\"goal_l2\"], decimals = 2),\n",
    "                                                                dev_scores_dict[\"requested_l2\"],\n",
    "                                                                np.around(dev_scores_dict[\"requested_l2\"], decimals = 2),\n",
    "                                                                dev_scores_dict[\"method_l2\"],\n",
    "                                                                np.around(dev_scores_dict[\"method_l2\"], decimals = 2)))\n",
    "\n",
    "    goal_food_early_stopping.on_epoch_end(epoch = (epoch + 1), current_value = (dev_scores_dict[\"goal_food_accuracy\"]))\n",
    "    \n",
    "    if goal_food_early_stopping.wait == 0:\n",
    "        torch.save(model_GoalFood.state_dict(), \"model_PANFMR_incremental_GoalFood.pt\")\n",
    "    \n",
    "    if goal_food_early_stopping.stop_training:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Goal Food Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GoalFood = GoalFoodModel(vocabulary_size = VOCABULARY_SIZE,\n",
    "                               embedding_dim = EMBEDDING_DIM,\n",
    "                               altered_embedding_dim = ALTERED_EMBEDDING_DIM,\n",
    "                               hidden_dim = HIDDEN_DIM,\n",
    "                               goal_food_dim = GOAL_FOOD_DIM,\n",
    "                               device = DEVICE)\n",
    "\n",
    "model_GoalFood = model_GoalFood.to(DEVICE)\n",
    "model_GoalFood.load_state_dict(torch.load(\"model_PANFMR_incremental_GoalFood.pt\"))\n",
    "model_GoalFood.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_tracker = make_tracker(model_GoalPricerange,\n",
    "                           model_GoalArea,\n",
    "                           model_GoalName,\n",
    "                           model_GoalFood,\n",
    "                           model_Requested,\n",
    "                           model_Method,\n",
    "                           raw_X_dev, raw_Y_dev, dataset = \"dstc2_dev\", percentage = 1.0)\n",
    "get_scores(dev_tracker, dataset = \"dstc2_dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tracker = make_tracker(model_GoalPricerange,\n",
    "                            model_GoalArea,\n",
    "                            model_GoalName,\n",
    "                            model_GoalFood,\n",
    "                            model_Requested,\n",
    "                            model_Method,\n",
    "                            raw_X_test, raw_Y_test, dataset = \"dstc2_test\", percentage = 1.0)\n",
    "get_scores(test_tracker, dataset = \"dstc2_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Requested Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dev_goal_accuracies = []\n",
    "dev_requested_accuracies = []\n",
    "dev_method_accuracies = []\n",
    "\n",
    "requested_early_stopping = EarlyStopping(patience = 6)\n",
    "\n",
    "train_indices_loader = torch.utils.data.DataLoader(np.arange(raw_X_train.shape[0]), batch_size = BATCH_SIZE, shuffle = True)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    logging.info(\"Epoch\\t{}/{}\".format(epoch + 1, NUM_EPOCHS))\n",
    "    \n",
    "    model_Requested = model_Requested.train()\n",
    "    \n",
    "    for train_indices in tqdm_notebook(train_indices_loader, total = len(train_indices_loader)):\n",
    "        \n",
    "        optimizer_RequestedModel.zero_grad()\n",
    "\n",
    "        dialogs_loss = 0\n",
    "    \n",
    "        for raw_X_train_dialog, raw_Y_train_dialog in zip(raw_X_train[train_indices], raw_Y_train[train_indices]):\n",
    "\n",
    "            model_Requested.hidden = model_Requested.init_hidden()\n",
    "\n",
    "            for raw_X_train_turn, raw_Y_train_turn in zip(raw_X_train_dialog[\"turns\"], raw_Y_train_dialog[\"turns\"]):\n",
    "\n",
    "                indices, scores = get_index_and_score(raw_X_train_turn, token_to_index, mode = \"train\", device = DEVICE)\n",
    "\n",
    "                requesteds = model_Requested(indices, scores)\n",
    "\n",
    "                for requested in requesteds:\n",
    "\n",
    "                    requested = requested.unsqueeze(0)\n",
    "\n",
    "                    loss_requested = REQUESTED_LOSS_FUNCTION(requested,\n",
    "                                                             retrieve_gold_Requested(raw_Y_train_turn,\n",
    "                                                                                     ontology = ontology,\n",
    "                                                                                     device = DEVICE))\n",
    "                    dialogs_loss += loss_requested\n",
    "\n",
    "        dialogs_loss.backward(retain_graph = False)\n",
    "\n",
    "        optimizer_RequestedModel.step()\n",
    "    \n",
    "    dev_tracker = make_tracker(model_GoalPricerange,\n",
    "                   model_GoalArea,\n",
    "                   model_GoalName,\n",
    "                   model_GoalFood,\n",
    "                   model_Requested,\n",
    "                   model_Method,\n",
    "                   raw_X_dev, raw_Y_dev, dataset = \"dstc2_dev\", percentage = 1.0)\n",
    "    dev_scores_dict = get_scores(dev_tracker, dataset = \"dstc2_dev\")\n",
    "    \n",
    "    logging.info(\"DEV Acc:\\t\\t{}({})\\t\\t{}({})\\t\\t{}({})\".format(dev_scores_dict[\"goal_accuracy\"],\n",
    "                                                                 np.around(dev_scores_dict[\"goal_accuracy\"], decimals = 2),\n",
    "                                                                 dev_scores_dict[\"requested_accuracy\"],\n",
    "                                                                 np.around(dev_scores_dict[\"requested_accuracy\"], decimals = 2),\n",
    "                                                                 dev_scores_dict[\"method_accuracy\"],\n",
    "                                                                 np.around(dev_scores_dict[\"method_accuracy\"], decimals = 2)))\n",
    "    logging.info(\"DEV L2:\\t\\t{}({})\\t\\t{}({})\\t\\t{}({})\".format(dev_scores_dict[\"goal_l2\"],\n",
    "                                                                np.around(dev_scores_dict[\"goal_l2\"], decimals = 2),\n",
    "                                                                dev_scores_dict[\"requested_l2\"],\n",
    "                                                                np.around(dev_scores_dict[\"requested_l2\"], decimals = 2),\n",
    "                                                                dev_scores_dict[\"method_l2\"],\n",
    "                                                                np.around(dev_scores_dict[\"method_l2\"], decimals = 2)))\n",
    "\n",
    "    requested_early_stopping.on_epoch_end(epoch = (epoch + 1), current_value = (dev_scores_dict[\"requested_accuracy\"]))\n",
    "    \n",
    "    if requested_early_stopping.wait == 0:\n",
    "        torch.save(model_Requested.state_dict(), \"model_PANFMR_incremental_Requested.pt\")\n",
    "    \n",
    "    if requested_early_stopping.stop_training:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Requested Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Requested = RequestedModel(vocabulary_size = VOCABULARY_SIZE,\n",
    "                                 embedding_dim = EMBEDDING_DIM,\n",
    "                                 altered_embedding_dim = ALTERED_EMBEDDING_DIM,\n",
    "                                 hidden_dim = HIDDEN_DIM,\n",
    "                                 requested_dim = REQUESTED_DIM,\n",
    "                                 device = DEVICE)\n",
    "\n",
    "model_Requested = model_Requested.to(DEVICE)\n",
    "model_Requested.load_state_dict(torch.load(\"model_PANFMR_incremental_Requested.pt\"))\n",
    "model_Requested.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_tracker = make_tracker(model_GoalPricerange,\n",
    "                           model_GoalArea,\n",
    "                           model_GoalName,\n",
    "                           model_GoalFood,\n",
    "                           model_Requested,\n",
    "                           model_Method,\n",
    "                           raw_X_dev, raw_Y_dev, dataset = \"dstc2_dev\", percentage = 1.0)\n",
    "get_scores(dev_tracker, dataset = \"dstc2_dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tracker = make_tracker(model_GoalPricerange,\n",
    "                            model_GoalArea,\n",
    "                            model_GoalName,\n",
    "                            model_GoalFood,\n",
    "                            model_Requested,\n",
    "                            model_Method,\n",
    "                            raw_X_test, raw_Y_test, dataset = \"dstc2_test\", percentage = 1.0)\n",
    "get_scores(test_tracker, dataset = \"dstc2_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Method Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dev_goal_accuracies = []\n",
    "dev_requested_accuracies = []\n",
    "dev_method_accuracies = []\n",
    "\n",
    "method_early_stopping = EarlyStopping(patience = 6)\n",
    "\n",
    "train_indices_loader = torch.utils.data.DataLoader(np.arange(raw_X_train.shape[0]), batch_size = BATCH_SIZE, shuffle = True)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    logging.info(\"Epoch\\t{}/{}\".format(epoch + 1, NUM_EPOCHS))\n",
    "    \n",
    "    model_Method = model_Method.train()\n",
    "    \n",
    "    for train_indices in tqdm_notebook(train_indices_loader, total = len(train_indices_loader)):\n",
    "    \n",
    "        optimizer_MethodModel.zero_grad()\n",
    "\n",
    "        dialogs_loss = 0\n",
    "    \n",
    "        for raw_X_train_dialog, raw_Y_train_dialog in zip(raw_X_train[train_indices], raw_Y_train[train_indices]):\n",
    "\n",
    "            model_Method.hidden = model_Method.init_hidden()\n",
    "\n",
    "            for raw_X_train_turn, raw_Y_train_turn in zip(raw_X_train_dialog[\"turns\"], raw_Y_train_dialog[\"turns\"]):\n",
    "\n",
    "                indices, scores = get_index_and_score(raw_X_train_turn, token_to_index, mode = \"train\", device = DEVICE)\n",
    "\n",
    "                methods = model_Method(indices, scores)\n",
    "\n",
    "                for method in methods:\n",
    "\n",
    "                    method = method.unsqueeze(0)\n",
    "\n",
    "                    loss_method = METHOD_LOSS_FUNCTION(method,\n",
    "                                                       retrieve_gold_Method(raw_Y_train_turn,\n",
    "                                                                            ontology = ontology,\n",
    "                                                                            device = DEVICE))\n",
    "                    dialogs_loss += loss_method\n",
    "\n",
    "        dialogs_loss.backward(retain_graph = False)\n",
    "\n",
    "        optimizer_MethodModel.step()\n",
    "    \n",
    "    dev_tracker = make_tracker(model_GoalPricerange,\n",
    "                   model_GoalArea,\n",
    "                   model_GoalName,\n",
    "                   model_GoalFood,\n",
    "                   model_Requested,\n",
    "                   model_Method,\n",
    "                   raw_X_dev, raw_Y_dev, dataset = \"dstc2_dev\", percentage = 1.0)\n",
    "    dev_scores_dict = get_scores(dev_tracker, dataset = \"dstc2_dev\")\n",
    "    \n",
    "    logging.info(\"DEV Acc:\\t\\t{}({})\\t\\t{}({})\\t\\t{}({})\".format(dev_scores_dict[\"goal_accuracy\"],\n",
    "                                                                 np.around(dev_scores_dict[\"goal_accuracy\"], decimals = 2),\n",
    "                                                                 dev_scores_dict[\"requested_accuracy\"],\n",
    "                                                                 np.around(dev_scores_dict[\"requested_accuracy\"], decimals = 2),\n",
    "                                                                 dev_scores_dict[\"method_accuracy\"],\n",
    "                                                                 np.around(dev_scores_dict[\"method_accuracy\"], decimals = 2)))\n",
    "    logging.info(\"DEV L2:\\t\\t{}({})\\t\\t{}({})\\t\\t{}({})\".format(dev_scores_dict[\"goal_l2\"],\n",
    "                                                                np.around(dev_scores_dict[\"goal_l2\"], decimals = 2),\n",
    "                                                                dev_scores_dict[\"requested_l2\"],\n",
    "                                                                np.around(dev_scores_dict[\"requested_l2\"], decimals = 2),\n",
    "                                                                dev_scores_dict[\"method_l2\"],\n",
    "                                                                np.around(dev_scores_dict[\"method_l2\"], decimals = 2)))\n",
    "\n",
    "    method_early_stopping.on_epoch_end(epoch = (epoch + 1), current_value = (dev_scores_dict[\"method_accuracy\"]))\n",
    "    \n",
    "    if method_early_stopping.wait == 0:\n",
    "        torch.save(model_Method.state_dict(), \"model_PANFMR_incremental_Method.pt\")\n",
    "    \n",
    "    if method_early_stopping.stop_training:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Method Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Method = MethodModel(vocabulary_size = VOCABULARY_SIZE,\n",
    "                           embedding_dim = EMBEDDING_DIM,\n",
    "                           altered_embedding_dim = ALTERED_EMBEDDING_DIM,\n",
    "                           hidden_dim = HIDDEN_DIM,\n",
    "                           method_dim = METHOD_DIM,\n",
    "                           device = DEVICE)\n",
    "\n",
    "model_Method = model_Method.to(DEVICE)\n",
    "model_Method.load_state_dict(torch.load(\"model_PANFMR_incremental_Method.pt\"))\n",
    "model_Method.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dev_tracker = make_tracker(model_GoalPricerange,\n",
    "                           model_GoalArea,\n",
    "                           model_GoalName,\n",
    "                           model_GoalFood,\n",
    "                           model_Requested,\n",
    "                           model_Method,\n",
    "                           raw_X_dev, raw_Y_dev, dataset = \"dstc2_dev\", percentage = 1.0)\n",
    "get_scores(dev_tracker, dataset = \"dstc2_dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tracker = make_tracker(model_GoalPricerange,\n",
    "                            model_GoalArea,\n",
    "                            model_GoalName,\n",
    "                            model_GoalFood,\n",
    "                            model_Requested,\n",
    "                            model_Method,\n",
    "                            raw_X_test, raw_Y_test, dataset = \"dstc2_test\", percentage = 1.0)\n",
    "get_scores(test_tracker, dataset = \"dstc2_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot incremental accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotly_plot_incremental(percentages, goal_accuracies, requested_accuracies, method_accuracies, dataset):\n",
    "    plotly.offline.iplot({\n",
    "                            \"data\": [Scatter(\n",
    "                                            x = percentages,\n",
    "                                            y = goal_accuracies,\n",
    "                                            mode = \"lines+markers\",\n",
    "                                            name = \"{} Goal Accuracy\".format(dataset),\n",
    "                                            marker = dict(color = \"#3498db\")),\n",
    "                                    Scatter(\n",
    "                                            x = percentages,\n",
    "                                            y = requested_accuracies,\n",
    "                                            mode = \"lines+markers\",\n",
    "                                            name = \"{} Requested Accuracy\".format(dataset),\n",
    "                                            marker = dict(color = \"#1abc9c\")),\n",
    "                                    Scatter(\n",
    "                                            x = percentages,\n",
    "                                            y = method_accuracies,\n",
    "                                            mode = \"lines+markers\",\n",
    "                                            name = \"{} Method Accuracy\".format(dataset),\n",
    "                                            marker = dict(color = \"#9b59b6\"))],\n",
    "                            \"layout\": Layout(\n",
    "                                             title = \"<b>Percentage - Accuracy</b>\",\n",
    "                                             xaxis = dict(title = \"<b>Percentage</b>\",\n",
    "                                                          dtick = 0.1,\n",
    "                                                          titlefont = dict(color = \"#34495e\")),\n",
    "                                             yaxis = dict(title = \"<b>Accuracy</b>\",\n",
    "                                                          titlefont = dict(color = \"#34495e\")),\n",
    "                                             margin = Margin(b = 150))\n",
    "                        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "dev_goal_accuracies = []\n",
    "dev_goal_l2s = []\n",
    "dev_requested_accuracies = []\n",
    "dev_requested_l2s = []\n",
    "dev_method_accuracies = []\n",
    "dev_method_l2s = []\n",
    "\n",
    "test_goal_accuracies = []\n",
    "test_goal_l2s = []\n",
    "test_requested_accuracies = []\n",
    "test_requested_l2s = []\n",
    "test_method_accuracies = []\n",
    "test_method_l2s = []\n",
    "\n",
    "for percentage in tqdm_notebook(percentages, total = len(percentages)):\n",
    "    \n",
    "    dev_incremental_tracker = make_tracker(model_GoalPricerange, model_GoalArea, model_GoalName, model_GoalFood, model_Requested, model_Method, raw_X_dev, raw_Y_dev, dataset = \"dstc2_dev\", percentage = percentage)\n",
    "    \n",
    "    dev_scores_dict = get_scores(dev_incremental_tracker, dataset = \"dstc2_dev\")\n",
    "    \n",
    "    dev_goal_accuracies.append(dev_scores_dict[\"goal_accuracy\"])\n",
    "    dev_goal_l2s.append(dev_scores_dict[\"goal_l2\"])\n",
    "    dev_requested_accuracies.append(dev_scores_dict[\"requested_accuracy\"])\n",
    "    dev_requested_l2s.append(dev_scores_dict[\"requested_l2\"])\n",
    "    dev_method_accuracies.append(dev_scores_dict[\"method_accuracy\"])\n",
    "    dev_method_l2s.append(dev_scores_dict[\"method_l2\"])\n",
    "    \n",
    "    test_incremental_tracker = make_tracker(model_GoalPricerange, model_GoalArea, model_GoalName, model_GoalFood, model_Requested, model_Method, raw_X_test, raw_Y_test, dataset = \"dstc2_test\", percentage = percentage)\n",
    "    \n",
    "    test_scores_dict = get_scores(test_incremental_tracker, dataset = \"dstc2_test\")\n",
    "    \n",
    "    test_goal_accuracies.append(test_scores_dict[\"goal_accuracy\"])\n",
    "    test_goal_l2s.append(test_scores_dict[\"goal_l2\"])\n",
    "    test_requested_accuracies.append(test_scores_dict[\"requested_accuracy\"])\n",
    "    test_requested_l2s.append(test_scores_dict[\"requested_l2\"])\n",
    "    test_method_accuracies.append(test_scores_dict[\"method_accuracy\"])\n",
    "    test_method_l2s.append(test_scores_dict[\"method_l2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_plot_incremental(percentages, dev_goal_accuracies, dev_requested_accuracies, dev_method_accuracies, \"Dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_plot_incremental(percentages, test_goal_accuracies, test_requested_accuracies, test_method_accuracies, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUPERVISED TURN TAKING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Goal Pricerange Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GoalPricerange = GoalPricerangeModel(vocabulary_size = VOCABULARY_SIZE,\n",
    "                                           embedding_dim = EMBEDDING_DIM,\n",
    "                                           altered_embedding_dim = ALTERED_EMBEDDING_DIM,\n",
    "                                           hidden_dim = HIDDEN_DIM,\n",
    "                                           goal_pricerange_dim = GOAL_PRICERANGE_DIM,\n",
    "                                           device = DEVICE)\n",
    "\n",
    "model_GoalPricerange = model_GoalPricerange.to(DEVICE)\n",
    "model_GoalPricerange.load_state_dict(torch.load(\"model_PANFMR_incremental_GoalPricerange.pt\"))\n",
    "model_GoalPricerange.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Goal Area Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GoalArea = GoalAreaModel(vocabulary_size = VOCABULARY_SIZE,\n",
    "                               embedding_dim = EMBEDDING_DIM,\n",
    "                               altered_embedding_dim = ALTERED_EMBEDDING_DIM,\n",
    "                               hidden_dim = HIDDEN_DIM,\n",
    "                               goal_area_dim = GOAL_AREA_DIM,\n",
    "                               device = DEVICE)\n",
    "\n",
    "model_GoalArea = model_GoalArea.to(DEVICE)\n",
    "model_GoalArea.load_state_dict(torch.load(\"model_PANFMR_incremental_GoalArea.pt\"))\n",
    "model_GoalArea.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Goal Name Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GoalName = GoalNameModel(vocabulary_size = VOCABULARY_SIZE,\n",
    "                               embedding_dim = EMBEDDING_DIM,\n",
    "                               altered_embedding_dim = ALTERED_EMBEDDING_DIM,\n",
    "                               hidden_dim = HIDDEN_DIM,\n",
    "                               goal_name_dim = GOAL_NAME_DIM,\n",
    "                               device = DEVICE)\n",
    "\n",
    "model_GoalName = model_GoalName.to(DEVICE)\n",
    "model_GoalName.load_state_dict(torch.load(\"model_PANFMR_incremental_GoalName.pt\"))\n",
    "model_GoalName.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Goal Food Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GoalFood = GoalFoodModel(vocabulary_size = VOCABULARY_SIZE,\n",
    "                               embedding_dim = EMBEDDING_DIM,\n",
    "                               altered_embedding_dim = ALTERED_EMBEDDING_DIM,\n",
    "                               hidden_dim = HIDDEN_DIM,\n",
    "                               goal_food_dim = GOAL_FOOD_DIM,\n",
    "                               device = DEVICE)\n",
    "\n",
    "model_GoalFood = model_GoalFood.to(DEVICE)\n",
    "model_GoalFood.load_state_dict(torch.load(\"model_PANFMR_incremental_GoalFood.pt\"))\n",
    "model_GoalFood.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Requested Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Requested = RequestedModel(vocabulary_size = VOCABULARY_SIZE,\n",
    "                                 embedding_dim = EMBEDDING_DIM,\n",
    "                                 altered_embedding_dim = ALTERED_EMBEDDING_DIM,\n",
    "                                 hidden_dim = HIDDEN_DIM,\n",
    "                                 requested_dim = REQUESTED_DIM,\n",
    "                                 device = DEVICE)\n",
    "\n",
    "model_Requested = model_Requested.to(DEVICE)\n",
    "model_Requested.load_state_dict(torch.load(\"model_PANFMR_incremental_Requested.pt\"))\n",
    "model_Requested.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Method Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Method = MethodModel(vocabulary_size = VOCABULARY_SIZE,\n",
    "                           embedding_dim = EMBEDDING_DIM,\n",
    "                           altered_embedding_dim = ALTERED_EMBEDDING_DIM,\n",
    "                           hidden_dim = HIDDEN_DIM,\n",
    "                           method_dim = METHOD_DIM,\n",
    "                           device = DEVICE)\n",
    "\n",
    "model_Method = model_Method.to(DEVICE)\n",
    "model_Method.load_state_dict(torch.load(\"model_PANFMR_incremental_Method.pt\"))\n",
    "model_Method.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_tracker = make_tracker(model_GoalPricerange,\n",
    "                           model_GoalArea,\n",
    "                           model_GoalName,\n",
    "                           model_GoalFood,\n",
    "                           model_Requested,\n",
    "                           model_Method,\n",
    "                           raw_X_dev, raw_Y_dev, dataset = \"dstc2_dev\", percentage = 1.0)\n",
    "get_scores(dev_tracker, dataset = \"dstc2_dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tracker = make_tracker(model_GoalPricerange,\n",
    "                            model_GoalArea,\n",
    "                            model_GoalName,\n",
    "                            model_GoalFood,\n",
    "                            model_Requested,\n",
    "                            model_Method,\n",
    "                            raw_X_test, raw_Y_test, dataset = \"dstc2_test\", percentage = 1.0)\n",
    "get_scores(test_tracker, dataset = \"dstc2_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictor utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_predictor_loss(model, raw_X, predictor_Y, objective, device):\n",
    "    \n",
    "    model = model.eval()\n",
    "    \n",
    "    loss = 0\n",
    "                           \n",
    "    for raw_X_dialog, predictor_Y_dialog in zip(raw_X, predictor_Y):\n",
    "\n",
    "            model.hidden = model.init_hidden()\n",
    "\n",
    "            for raw_X_turn, predictor_Y_turn in zip(raw_X_dialog[\"turns\"], predictor_Y_dialog[\"turns\"]):\n",
    "\n",
    "                indices, scores = get_index_and_score(raw_X_turn, token_to_index, mode = \"eval\", device = DEVICE)\n",
    "\n",
    "                model_predictions = model(indices, scores)\n",
    "\n",
    "                for model_prediction, gold_prediction in zip(model_predictions, predictor_Y_turn[objective]):\n",
    "\n",
    "                    model_prediction = model_prediction.unsqueeze(0)\n",
    "                    \n",
    "                    gold_prediction = torch.tensor([gold_prediction], dtype = torch.long, device = DEVICE)\n",
    "\n",
    "                    prediction_loss = PREDICTOR_LOSS_FUNCTION(model_prediction, gold_prediction)\n",
    "\n",
    "                    loss += prediction_loss\n",
    "    return loss\n",
    "\n",
    "def get_gaps_vector(vector):\n",
    "    gaps_vector = []\n",
    "    \n",
    "    for value in vector:\n",
    "        if value == vector[-1]:\n",
    "            gaps_vector.append(0)\n",
    "        else:\n",
    "            gaps_vector.append(1)\n",
    "    \n",
    "    return gaps_vector\n",
    "\n",
    "\n",
    "def get_predictor_score(dataset, session_id, turns_so_far):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    tracker_json = {}\n",
    "    tracker_json[\"dataset\"] = dataset\n",
    "    tracker_json[\"sessions\"] = []\n",
    "    \n",
    "    session = {}\n",
    "    session[\"session-id\"] = session_id\n",
    "    session[\"turns\"] = turns_so_far\n",
    "    \n",
    "    tracker_json[\"sessions\"].append(session)\n",
    "        \n",
    "    end_time = time.time()\n",
    "    \n",
    "    tracker_json[\"wall-time\"] = end_time - start_time\n",
    "    \n",
    "    return get_scores(tracker_json, dataset, predictor = True)\n",
    "    \n",
    "\n",
    "def get_predictor_Y(model_GoalPricerange, model_GoalArea, model_GoalName, model_GoalFood, model_Requested, model_Method, dataset, ontology):\n",
    "    \n",
    "    predictor_Y = []\n",
    "    \n",
    "    if dataset == \"dstc2_train\":\n",
    "        raw_X = raw_X_train\n",
    "        raw_Y = raw_Y_train\n",
    "    elif dataset == \"dstc2_dev\":\n",
    "        raw_X = raw_X_dev\n",
    "        raw_Y = raw_Y_dev\n",
    "    else: # dataset == \"dstc2_test\"\n",
    "        raw_X = raw_X_test\n",
    "        raw_Y = raw_Y_test\n",
    "    \n",
    "    model_GoalPricerange = model_GoalPricerange.eval()\n",
    "    model_GoalArea = model_GoalArea.eval()\n",
    "    model_GoalName = model_GoalName.eval()\n",
    "    model_GoalFood = model_GoalFood.eval()\n",
    "    model_Requested = model_Requested.eval()\n",
    "    model_Method = model_Method.eval()\n",
    "    \n",
    "    for raw_X_dialog, raw_Y_dialog in tqdm_notebook(zip(raw_X, raw_Y), total = len(raw_X)):\n",
    "        \n",
    "        assert(raw_X_dialog[\"session-id\"] == raw_Y_dialog[\"session-id\"])\n",
    "        \n",
    "        predictor_Y_dialog = {}\n",
    "        predictor_Y_dialog[\"session-id\"] = raw_Y_dialog[\"session-id\"]\n",
    "        predictor_Y_dialog[\"turns\"] = []\n",
    "        \n",
    "        model_GoalPricerange.hidden = model_GoalPricerange.init_hidden()\n",
    "        model_GoalArea.hidden = model_GoalArea.init_hidden()\n",
    "        model_GoalName.hidden = model_GoalName.init_hidden()\n",
    "        model_GoalFood.hidden = model_GoalFood.init_hidden()\n",
    "        model_Requested.hidden = model_Requested.init_hidden()\n",
    "        model_Method.hidden = model_Method.init_hidden()\n",
    "\n",
    "        turns_so_far = []\n",
    "\n",
    "        for raw_X_turn, raw_Y_turn in zip(raw_X_dialog[\"turns\"], raw_Y_dialog[\"turns\"]):\n",
    "            \n",
    "            predictor_Y_turn = {}\n",
    "            predictor_Y_turn[\"goal_pricerange_predictor\"] = []\n",
    "            predictor_Y_turn[\"goal_area_predictor\"] = []\n",
    "            predictor_Y_turn[\"goal_name_predictor\"] = []\n",
    "            predictor_Y_turn[\"goal_food_predictor\"] = []\n",
    "            predictor_Y_turn[\"requested_predictor\"] = []\n",
    "            predictor_Y_turn[\"method_predictor\"] = []\n",
    "            \n",
    "            turn = {}\n",
    "            turn[\"goal-labels\"] = {}\n",
    "\n",
    "            indices, scores = get_index_and_score(raw_X_turn, token_to_index, mode = \"eval\", device = DEVICE)\n",
    "\n",
    "            goal_foods = model_GoalFood(indices, scores)\n",
    "            goal_priceranges = model_GoalPricerange(indices, scores)\n",
    "            goal_names = model_GoalName(indices, scores)\n",
    "            goal_areas = model_GoalArea(indices, scores)\n",
    "            requesteds = model_Requested(indices, scores)\n",
    "            methods = model_Method(indices, scores)\n",
    "            \n",
    "            for goal_food, goal_pricerange, goal_name, goal_area, requested, method in zip(goal_foods, goal_priceranges, goal_names, goal_areas, requesteds, methods):\n",
    "                \n",
    "                turns_so_far_copy = copy.deepcopy(turns_so_far)\n",
    "                \n",
    "                turn[\"goal-labels\"][\"food\"] = retrieve_output_GoalFood(goal_food, ontology)\n",
    "                turn[\"goal-labels\"][\"pricerange\"] = retrieve_output_GoalPricerange(goal_pricerange, ontology)\n",
    "                turn[\"goal-labels\"][\"name\"] = retrieve_output_GoalName(goal_name, ontology)\n",
    "                turn[\"goal-labels\"][\"area\"] = retrieve_output_GoalArea(goal_area, ontology)\n",
    "                turn[\"requested-slots\"] = retrieve_output_Requested(requested, ontology)\n",
    "                turn[\"method-label\"] = retrieve_output_Method(method, ontology)\n",
    "            \n",
    "                turns_so_far_copy.append(turn)\n",
    "                \n",
    "                scores_dict = get_predictor_score(dataset, raw_X_dialog[\"session-id\"], turns_so_far_copy)\n",
    "                \n",
    "                predictor_Y_turn[\"goal_pricerange_predictor\"].append(scores_dict[\"goal_pricerange_accuracy\"])\n",
    "                predictor_Y_turn[\"goal_area_predictor\"].append(scores_dict[\"goal_area_accuracy\"])\n",
    "                predictor_Y_turn[\"goal_name_predictor\"].append(scores_dict[\"goal_name_accuracy\"])\n",
    "                predictor_Y_turn[\"goal_food_predictor\"].append(scores_dict[\"goal_food_accuracy\"])\n",
    "                predictor_Y_turn[\"requested_predictor\"].append(scores_dict[\"requested_accuracy\"])\n",
    "                predictor_Y_turn[\"method_predictor\"].append(scores_dict[\"method_accuracy\"])\n",
    "                                \n",
    "            turns_so_far.append(turn)\n",
    "                \n",
    "            predictor_Y_turn[\"goal_pricerange_predictor\"] = get_gaps_vector(predictor_Y_turn[\"goal_pricerange_predictor\"])\n",
    "            predictor_Y_turn[\"goal_area_predictor\"] = get_gaps_vector(predictor_Y_turn[\"goal_area_predictor\"])\n",
    "            predictor_Y_turn[\"goal_name_predictor\"] = get_gaps_vector(predictor_Y_turn[\"goal_name_predictor\"])\n",
    "            predictor_Y_turn[\"goal_food_predictor\"] = get_gaps_vector(predictor_Y_turn[\"goal_food_predictor\"])\n",
    "            predictor_Y_turn[\"requested_predictor\"] = get_gaps_vector(predictor_Y_turn[\"requested_predictor\"])\n",
    "            predictor_Y_turn[\"method_predictor\"] = get_gaps_vector(predictor_Y_turn[\"method_predictor\"])\n",
    "            \n",
    "            predictor_Y_dialog[\"turns\"].append(predictor_Y_turn)\n",
    "            \n",
    "        predictor_Y.append(predictor_Y_dialog) \n",
    "    \n",
    "    return np.array(predictor_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute development set predictor labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dev_predictor_Y = get_predictor_Y(model_GoalPricerange,\n",
    "                                  model_GoalArea,\n",
    "                                  model_GoalName,\n",
    "                                  model_GoalFood,\n",
    "                                  model_Requested,\n",
    "                                  model_Method,\n",
    "                                  \"dstc2_dev\",\n",
    "                                  ontology)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save development set predictor labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"dev_predictor_Y\", dev_predictor_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load development set predictor labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_predictor_Y = np.load(\"dev_predictor_Y.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute train set predictor labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictor_Y = get_predictor_Y(model_GoalPricerange,\n",
    "                                    model_GoalArea,\n",
    "                                    model_GoalName,\n",
    "                                    model_GoalFood,\n",
    "                                    model_Requested,\n",
    "                                    model_Method,\n",
    "                                    \"dstc2_train\",\n",
    "                                    ontology)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save train set predictor labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"train_predictor_Y\", train_predictor_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train set predictor labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictor_Y = np.load(\"train_predictor_Y.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal Pricerange Predictor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoalPricerangePredictorModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 vocabulary_size,\n",
    "                 embedding_dim,\n",
    "                 altered_embedding_dim,\n",
    "                 hidden_dim,\n",
    "                 goal_pricerange_predictor_dim,\n",
    "                 device):\n",
    "        \n",
    "        super(GoalPricerangePredictorModel, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.goal_pricerange_predictor_dim = goal_pricerange_predictor_dim\n",
    "        self.device = device\n",
    "        \n",
    "        self.embeddings = nn.Embedding(num_embeddings = vocabulary_size,\n",
    "                                       embedding_dim = embedding_dim)\n",
    "        \n",
    "        self.altered_embeddings = nn.Linear(in_features = (embedding_dim + 1),\n",
    "                                            out_features = altered_embedding_dim)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size = altered_embedding_dim,\n",
    "                            hidden_size = hidden_dim)\n",
    "        \n",
    "        self.goal_pricerange_predictor_classifier = nn.Linear(in_features = hidden_dim,\n",
    "                                                              out_features = goal_pricerange_predictor_dim)\n",
    "        \n",
    "        self.hidden = self.init_hidden()\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        \n",
    "        return (torch.zeros(1, 1, self.hidden_dim, device = self.device),\n",
    "                torch.zeros(1, 1, self.hidden_dim, device = self.device))\n",
    "        \n",
    "    def forward(self, indices, scores):\n",
    "    \n",
    "        embeddings = self.embeddings(indices)\n",
    "        \n",
    "        embeddings_concat_score = torch.cat((embeddings, scores.unsqueeze(dim = 1)), dim = 1) \n",
    "        \n",
    "        altered_embeddings = F.relu(self.altered_embeddings(embeddings_concat_score))\n",
    "        \n",
    "        lstm_out, self.hidden = self.lstm(altered_embeddings.view(len(indices), 1, -1), self.hidden)\n",
    "        \n",
    "        goal_pricerange_predictor = F.log_softmax(self.goal_pricerange_predictor_classifier(lstm_out).view(-1, self.goal_pricerange_predictor_dim), dim = 1) \n",
    "        \n",
    "        return goal_pricerange_predictor\n",
    "\n",
    "model_GoalPricerangePredictor = GoalPricerangePredictorModel(vocabulary_size = VOCABULARY_SIZE,\n",
    "                                                             embedding_dim = EMBEDDING_DIM,\n",
    "                                                             altered_embedding_dim = ALTERED_EMBEDDING_DIM,\n",
    "                                                             hidden_dim = HIDDEN_DIM,\n",
    "                                                             goal_pricerange_predictor_dim = PREDICTOR_DIM,\n",
    "                                                             device = DEVICE)\n",
    "\n",
    "model_GoalPricerangePredictor = model_GoalPricerangePredictor.to(DEVICE)\n",
    "\n",
    "optimizer_GoalPricerangePredictorModel = optim.Adam(model_GoalPricerangePredictor.parameters(), lr = 1e-3, amsgrad = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal Area Predictor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoalAreaPredictorModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 vocabulary_size,\n",
    "                 embedding_dim,\n",
    "                 altered_embedding_dim,\n",
    "                 hidden_dim,\n",
    "                 goal_area_predictor_dim,\n",
    "                 device):\n",
    "        \n",
    "        super(GoalAreaPredictorModel, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.goal_area_predictor_dim = goal_area_predictor_dim\n",
    "        self.device = device\n",
    "        \n",
    "        self.embeddings = nn.Embedding(num_embeddings = vocabulary_size,\n",
    "                                       embedding_dim = embedding_dim)\n",
    "        \n",
    "        self.altered_embeddings = nn.Linear(in_features = (embedding_dim + 1),\n",
    "                                            out_features = altered_embedding_dim)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size = altered_embedding_dim,\n",
    "                            hidden_size = hidden_dim)\n",
    "        \n",
    "        self.goal_area_predictor_classifier = nn.Linear(in_features = hidden_dim,\n",
    "                                                        out_features = goal_area_predictor_dim)\n",
    "        \n",
    "        self.hidden = self.init_hidden()\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        \n",
    "        return (torch.zeros(1, 1, self.hidden_dim, device = self.device),\n",
    "                torch.zeros(1, 1, self.hidden_dim, device = self.device))\n",
    "        \n",
    "    def forward(self, indices, scores):\n",
    "    \n",
    "        embeddings = self.embeddings(indices)\n",
    "        \n",
    "        embeddings_concat_score = torch.cat((embeddings, scores.unsqueeze(dim = 1)), dim = 1) \n",
    "        \n",
    "        altered_embeddings = F.relu(self.altered_embeddings(embeddings_concat_score))\n",
    "        \n",
    "        lstm_out, self.hidden = self.lstm(altered_embeddings.view(len(indices), 1, -1), self.hidden)\n",
    "        \n",
    "        goal_area_predictor = F.log_softmax(self.goal_area_predictor_classifier(lstm_out).view(-1, self.goal_area_predictor_dim), dim = 1)\n",
    "        \n",
    "        return goal_area_predictor\n",
    "\n",
    "model_GoalAreaPredictor = GoalAreaPredictorModel(vocabulary_size = VOCABULARY_SIZE,\n",
    "                                                 embedding_dim = EMBEDDING_DIM,\n",
    "                                                 altered_embedding_dim = ALTERED_EMBEDDING_DIM,\n",
    "                                                 hidden_dim = HIDDEN_DIM,\n",
    "                                                 goal_area_predictor_dim = PREDICTOR_DIM,\n",
    "                                                 device = DEVICE)\n",
    "\n",
    "model_GoalAreaPredictor = model_GoalAreaPredictor.to(DEVICE)\n",
    "\n",
    "optimizer_GoalAreaPredictorModel = optim.Adam(model_GoalAreaPredictor.parameters(), lr = 1e-3, amsgrad = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal Name Predictor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoalNamePredictorModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 vocabulary_size,\n",
    "                 embedding_dim,\n",
    "                 altered_embedding_dim,\n",
    "                 hidden_dim,\n",
    "                 goal_name_predictor_dim,\n",
    "                 device):\n",
    "        \n",
    "        super(GoalNamePredictorModel, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.goal_name_predictor_dim = goal_name_predictor_dim\n",
    "        self.device = device\n",
    "        \n",
    "        self.embeddings = nn.Embedding(num_embeddings = vocabulary_size,\n",
    "                                       embedding_dim = embedding_dim)\n",
    "        \n",
    "        self.altered_embeddings = nn.Linear(in_features = (embedding_dim + 1),\n",
    "                                            out_features = altered_embedding_dim)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size = altered_embedding_dim,\n",
    "                            hidden_size = hidden_dim)\n",
    "        \n",
    "        self.goal_name_predictor_classifier = nn.Linear(in_features = hidden_dim,\n",
    "                                                        out_features = goal_name_predictor_dim)\n",
    "        \n",
    "        self.hidden = self.init_hidden()\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        \n",
    "        return (torch.zeros(1, 1, self.hidden_dim, device = self.device),\n",
    "                torch.zeros(1, 1, self.hidden_dim, device = self.device))\n",
    "        \n",
    "    def forward(self, indices, scores):\n",
    "    \n",
    "        embeddings = self.embeddings(indices)\n",
    "        \n",
    "        embeddings_concat_score = torch.cat((embeddings, scores.unsqueeze(dim = 1)), dim = 1) \n",
    "        \n",
    "        altered_embeddings = F.relu(self.altered_embeddings(embeddings_concat_score))\n",
    "        \n",
    "        lstm_out, self.hidden = self.lstm(altered_embeddings.view(len(indices), 1, -1), self.hidden)\n",
    "        \n",
    "        goal_name_predictor = F.log_softmax(self.goal_name_predictor_classifier(lstm_out).view(-1, self.goal_name_predictor_dim), dim = 1)\n",
    "        \n",
    "        return goal_name_predictor\n",
    "\n",
    "model_GoalNamePredictor = GoalNamePredictorModel(vocabulary_size = VOCABULARY_SIZE,\n",
    "                                                 embedding_dim = EMBEDDING_DIM,\n",
    "                                                 altered_embedding_dim = ALTERED_EMBEDDING_DIM,\n",
    "                                                 hidden_dim = HIDDEN_DIM,\n",
    "                                                 goal_name_predictor_dim = PREDICTOR_DIM,\n",
    "                                                 device = DEVICE)\n",
    "\n",
    "model_GoalNamePredictor = model_GoalNamePredictor.to(DEVICE)\n",
    "\n",
    "optimizer_GoalNamePredictorModel = optim.Adam(model_GoalNamePredictor.parameters(), lr = 1e-3, amsgrad = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal Food Predictor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoalFoodPredictorModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 vocabulary_size,\n",
    "                 embedding_dim,\n",
    "                 altered_embedding_dim,\n",
    "                 hidden_dim,\n",
    "                 goal_food_predictor_dim,\n",
    "                 device):\n",
    "        \n",
    "        super(GoalFoodPredictorModel, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.goal_food_predictor_dim = goal_food_predictor_dim\n",
    "        self.device = device\n",
    "        \n",
    "        self.embeddings = nn.Embedding(num_embeddings = vocabulary_size,\n",
    "                                       embedding_dim = embedding_dim)\n",
    "        \n",
    "        self.altered_embeddings = nn.Linear(in_features = (embedding_dim + 1),\n",
    "                                            out_features = altered_embedding_dim)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size = altered_embedding_dim,\n",
    "                            hidden_size = hidden_dim)\n",
    "        \n",
    "        self.goal_food_predictor_classifier = nn.Linear(in_features = hidden_dim,\n",
    "                                              out_features = goal_food_predictor_dim)\n",
    "        \n",
    "        self.hidden = self.init_hidden()\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        \n",
    "        return (torch.zeros(1, 1, self.hidden_dim, device = self.device),\n",
    "                torch.zeros(1, 1, self.hidden_dim, device = self.device))\n",
    "        \n",
    "    def forward(self, indices, scores):\n",
    "    \n",
    "        embeddings = self.embeddings(indices)\n",
    "        \n",
    "        embeddings_concat_score = torch.cat((embeddings, scores.unsqueeze(dim = 1)), dim = 1) \n",
    "        \n",
    "        altered_embeddings = F.relu(self.altered_embeddings(embeddings_concat_score))\n",
    "        \n",
    "        lstm_out, self.hidden = self.lstm(altered_embeddings.view(len(indices), 1, -1), self.hidden)\n",
    "        \n",
    "        goal_food_predictor = F.log_softmax(self.goal_food_predictor_classifier(lstm_out).view(-1, self.goal_food_predictor_dim), dim = 1)        \n",
    "        \n",
    "        return goal_food_predictor\n",
    "\n",
    "model_GoalFoodPredictor = GoalFoodPredictorModel(vocabulary_size = VOCABULARY_SIZE,\n",
    "                                                 embedding_dim = EMBEDDING_DIM,\n",
    "                                                 altered_embedding_dim = ALTERED_EMBEDDING_DIM,\n",
    "                                                 hidden_dim = HIDDEN_DIM,\n",
    "                                                 goal_food_predictor_dim = PREDICTOR_DIM,\n",
    "                                                 device = DEVICE)\n",
    "\n",
    "model_GoalFoodPredictor = model_GoalFoodPredictor.to(DEVICE)\n",
    "\n",
    "optimizer_GoalFoodPredictorModel = optim.Adam(model_GoalFoodPredictor.parameters(), lr = 1e-3, amsgrad = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requested Predictor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RequestedPredictorModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 vocabulary_size,\n",
    "                 embedding_dim,\n",
    "                 altered_embedding_dim,\n",
    "                 hidden_dim,\n",
    "                 requested_predictor_dim,\n",
    "                 device):\n",
    "        \n",
    "        super(RequestedPredictorModel, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.requested_predictor_dim = requested_predictor_dim\n",
    "        self.device = device\n",
    "        \n",
    "        self.embeddings = nn.Embedding(num_embeddings = vocabulary_size,\n",
    "                                       embedding_dim = embedding_dim)\n",
    "        \n",
    "        self.altered_embeddings = nn.Linear(in_features = (embedding_dim + 1),\n",
    "                                            out_features = altered_embedding_dim)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size = altered_embedding_dim,\n",
    "                            hidden_size = hidden_dim)\n",
    "        \n",
    "        self.requested_predictor_classifier = nn.Linear(in_features = hidden_dim,\n",
    "                                                        out_features = requested_predictor_dim)\n",
    "        \n",
    "        self.hidden = self.init_hidden()\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        \n",
    "        return (torch.zeros(1, 1, self.hidden_dim, device = self.device),\n",
    "                torch.zeros(1, 1, self.hidden_dim, device = self.device))\n",
    "        \n",
    "    def forward(self, indices, scores):\n",
    "    \n",
    "        embeddings = self.embeddings(indices)\n",
    "        \n",
    "        embeddings_concat_score = torch.cat((embeddings, scores.unsqueeze(dim = 1)), dim = 1) \n",
    "        \n",
    "        altered_embeddings = F.relu(self.altered_embeddings(embeddings_concat_score))\n",
    "        \n",
    "        lstm_out, self.hidden = self.lstm(altered_embeddings.view(len(indices), 1, -1), self.hidden)\n",
    "        \n",
    "        requested_predictor = F.log_softmax(self.requested_predictor_classifier(lstm_out).view(-1, self.requested_predictor_dim), dim = 1)\n",
    "        \n",
    "        return requested_predictor\n",
    "\n",
    "model_RequestedPredictor = RequestedPredictorModel(vocabulary_size = VOCABULARY_SIZE,\n",
    "                                                   embedding_dim = EMBEDDING_DIM,\n",
    "                                                   altered_embedding_dim = ALTERED_EMBEDDING_DIM,\n",
    "                                                   hidden_dim = HIDDEN_DIM,\n",
    "                                                   requested_predictor_dim = PREDICTOR_DIM,\n",
    "                                                   device = DEVICE)\n",
    "\n",
    "model_RequestedPredictor = model_RequestedPredictor.to(DEVICE)\n",
    "\n",
    "optimizer_RequestedPredictorModel = optim.Adam(model_RequestedPredictor.parameters(), lr = 1e-3, amsgrad = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method Predictor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MethodPredictorModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 vocabulary_size,\n",
    "                 embedding_dim,\n",
    "                 altered_embedding_dim,\n",
    "                 hidden_dim,\n",
    "                 method_predictor_dim,\n",
    "                 device):\n",
    "        \n",
    "        super(MethodPredictorModel, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.method_predictor_dim = method_predictor_dim\n",
    "        self.device = device\n",
    "        \n",
    "        self.embeddings = nn.Embedding(num_embeddings = vocabulary_size,\n",
    "                                       embedding_dim = embedding_dim)\n",
    "        \n",
    "        self.altered_embeddings = nn.Linear(in_features = (embedding_dim + 1),\n",
    "                                            out_features = altered_embedding_dim)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size = altered_embedding_dim,\n",
    "                            hidden_size = hidden_dim)\n",
    "        \n",
    "        self.method_predictor_classifier = nn.Linear(in_features = hidden_dim,\n",
    "                                                     out_features = method_predictor_dim)\n",
    "        \n",
    "        self.hidden = self.init_hidden()\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        \n",
    "        return (torch.zeros(1, 1, self.hidden_dim, device = self.device),\n",
    "                torch.zeros(1, 1, self.hidden_dim, device = self.device))\n",
    "        \n",
    "    def forward(self, indices, scores):\n",
    "    \n",
    "        embeddings = self.embeddings(indices)\n",
    "        \n",
    "        embeddings_concat_score = torch.cat((embeddings, scores.unsqueeze(dim = 1)), dim = 1) \n",
    "        \n",
    "        altered_embeddings = F.relu(self.altered_embeddings(embeddings_concat_score))\n",
    "        \n",
    "        lstm_out, self.hidden = self.lstm(altered_embeddings.view(len(indices), 1, -1), self.hidden)\n",
    "        \n",
    "        method_predictor = F.log_softmax(self.method_predictor_classifier(lstm_out).view(-1, self.method_predictor_dim), dim = 1)\n",
    "        \n",
    "        return method_predictor\n",
    "\n",
    "model_MethodPredictor = MethodPredictorModel(vocabulary_size = VOCABULARY_SIZE,\n",
    "                                             embedding_dim = EMBEDDING_DIM,\n",
    "                                             altered_embedding_dim = ALTERED_EMBEDDING_DIM,\n",
    "                                             hidden_dim = HIDDEN_DIM,\n",
    "                                             method_predictor_dim = PREDICTOR_DIM,\n",
    "                                             device = DEVICE)\n",
    "\n",
    "model_MethodPredictor = model_MethodPredictor.to(DEVICE)\n",
    "\n",
    "optimizer_MethodPredictorModel = optim.Adam(model_MethodPredictor.parameters(), lr = 1e-3, amsgrad = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Goal Pricerange Predictor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_pricerange_predictor_early_stopping = EarlyStopping(patience = 6)\n",
    "\n",
    "train_indices_loader = torch.utils.data.DataLoader(np.arange(raw_X_train.shape[0]), batch_size = BATCH_SIZE, shuffle = True)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    logging.info(\"Epoch\\t{}/{}\".format(epoch + 1, NUM_EPOCHS))\n",
    "    \n",
    "    model_GoalPricerangePredictor = model_GoalPricerangePredictor.train()\n",
    "    \n",
    "    for train_indices in tqdm_notebook(train_indices_loader, total = len(train_indices_loader)):\n",
    "        \n",
    "        optimizer_GoalPricerangePredictorModel.zero_grad()\n",
    "            \n",
    "        dialogs_loss = 0\n",
    "    \n",
    "        for raw_X_train_dialog, train_predictor_Y_dialog in zip(raw_X_train[train_indices], train_predictor_Y[train_indices]):\n",
    "\n",
    "            model_GoalPricerangePredictor.hidden = model_GoalPricerangePredictor.init_hidden()\n",
    "\n",
    "            for raw_X_train_turn, train_predictor_Y_turn in zip(raw_X_train_dialog[\"turns\"], train_predictor_Y_dialog[\"turns\"]):\n",
    "\n",
    "                indices, scores = get_index_and_score(raw_X_train_turn, token_to_index, mode = \"train\", device = DEVICE)\n",
    "\n",
    "                goal_priceranges_predictor = model_GoalPricerangePredictor(indices, scores)\n",
    "\n",
    "                for goal_pricerange_predictor, gold_goal_pricerange_predictor in zip(goal_priceranges_predictor, train_predictor_Y_turn[\"goal_pricerange_predictor\"]):\n",
    "\n",
    "                    goal_pricerange_predictor = goal_pricerange_predictor.unsqueeze(0)\n",
    "                    \n",
    "                    gold_goal_pricerange_predictor = torch.tensor([gold_goal_pricerange_predictor], dtype = torch.long, device = DEVICE)\n",
    "                    \n",
    "                    loss_goal_pricerange_predictor = PREDICTOR_LOSS_FUNCTION(goal_pricerange_predictor, gold_goal_pricerange_predictor)\n",
    "\n",
    "                    dialogs_loss += loss_goal_pricerange_predictor\n",
    "                \n",
    "        dialogs_loss.backward(retain_graph = False)\n",
    "\n",
    "        optimizer_GoalPricerangePredictorModel.step()\n",
    "    \n",
    "    train_loss = compute_predictor_loss(model_GoalPricerangePredictor, raw_X_train, train_predictor_Y, objective = \"goal_pricerange_predictor\", device = DEVICE)\n",
    "    dev_loss = compute_predictor_loss(model_GoalPricerangePredictor, raw_X_dev, dev_predictor_Y, objective = \"goal_pricerange_predictor\", device = DEVICE)\n",
    "    \n",
    "    logging.info(\"TRAIN LOSS: {}\\tDEV LOSS: {}\".format(train_loss.item(), dev_loss.item()))\n",
    "\n",
    "    goal_pricerange_predictor_early_stopping.on_epoch_end(epoch = (epoch + 1), current_value = -dev_loss.item())\n",
    "    \n",
    "    if goal_pricerange_predictor_early_stopping.wait == 0:\n",
    "        torch.save(model_GoalPricerangePredictor.state_dict(), \"model_PANFMR_incremental_GoalPricerangePredictor.pt\")\n",
    "    \n",
    "    if goal_pricerange_predictor_early_stopping.stop_training:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Goal Pricerange Predictor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GoalPricerangePredictor = GoalPricerangePredictorModel(vocabulary_size = VOCABULARY_SIZE,\n",
    "                                                             embedding_dim = EMBEDDING_DIM,\n",
    "                                                             altered_embedding_dim = ALTERED_EMBEDDING_DIM,\n",
    "                                                             hidden_dim = HIDDEN_DIM,\n",
    "                                                             goal_pricerange_predictor_dim = PREDICTOR_DIM,\n",
    "                                                             device = DEVICE)\n",
    "\n",
    "model_GoalPricerangePredictor = model_GoalPricerangePredictor.to(DEVICE)\n",
    "model_GoalPricerangePredictor.load_state_dict(torch.load(\"model_PANFMR_incremental_GoalPricerangePredictor.pt\"))\n",
    "model_GoalPricerangePredictor.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Goal Area Predictor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_area_predictor_early_stopping = EarlyStopping(patience = 6)\n",
    "\n",
    "train_indices_loader = torch.utils.data.DataLoader(np.arange(raw_X_train.shape[0]), batch_size = BATCH_SIZE, shuffle = True)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    logging.info(\"Epoch\\t{}/{}\".format(epoch + 1, NUM_EPOCHS))\n",
    "    \n",
    "    model_GoalAreaPredictor = model_GoalAreaPredictor.train()\n",
    "    \n",
    "    for train_indices in tqdm_notebook(train_indices_loader, total = len(train_indices_loader)):\n",
    "        \n",
    "        optimizer_GoalAreaPredictorModel.zero_grad()\n",
    "            \n",
    "        dialogs_loss = 0\n",
    "    \n",
    "        for raw_X_train_dialog, train_predictor_Y_dialog in zip(raw_X_train[train_indices], train_predictor_Y[train_indices]):\n",
    "\n",
    "            model_GoalAreaPredictor.hidden = model_GoalAreaPredictor.init_hidden()\n",
    "\n",
    "            for raw_X_train_turn, train_predictor_Y_turn in zip(raw_X_train_dialog[\"turns\"], train_predictor_Y_dialog[\"turns\"]):\n",
    "\n",
    "                indices, scores = get_index_and_score(raw_X_train_turn, token_to_index, mode = \"train\", device = DEVICE)\n",
    "\n",
    "                goal_areas_predictor = model_GoalAreaPredictor(indices, scores)\n",
    "\n",
    "                for goal_area_predictor, gold_goal_area_predictor in zip(goal_areas_predictor, train_predictor_Y_turn[\"goal_area_predictor\"]):\n",
    "\n",
    "                    goal_area_predictor = goal_area_predictor.unsqueeze(0)\n",
    "                    \n",
    "                    gold_goal_area_predictor = torch.tensor([gold_goal_area_predictor], dtype = torch.long, device = DEVICE)\n",
    "                    \n",
    "                    loss_goal_area_predictor = PREDICTOR_LOSS_FUNCTION(goal_area_predictor, gold_goal_area_predictor)\n",
    "\n",
    "                    dialogs_loss += loss_goal_area_predictor\n",
    "                \n",
    "        dialogs_loss.backward(retain_graph = False)\n",
    "\n",
    "        optimizer_GoalAreaPredictorModel.step()\n",
    "    \n",
    "    train_loss = compute_predictor_loss(model_GoalAreaPredictor, raw_X_train, train_predictor_Y, objective = \"goal_area_predictor\", device = DEVICE)\n",
    "    dev_loss = compute_predictor_loss(model_GoalAreaPredictor, raw_X_dev, dev_predictor_Y, objective = \"goal_area_predictor\", device = DEVICE)\n",
    "    \n",
    "    logging.info(\"TRAIN LOSS: {}\\tDEV LOSS: {}\".format(train_loss.item(), dev_loss.item()))\n",
    "\n",
    "    goal_area_predictor_early_stopping.on_epoch_end(epoch = (epoch + 1), current_value = -dev_loss.item())\n",
    "    \n",
    "    if goal_area_predictor_early_stopping.wait == 0:\n",
    "        torch.save(model_GoalAreaPredictor.state_dict(), \"model_PANFMR_incremental_GoalAreaPredictor.pt\")\n",
    "    \n",
    "    if goal_area_predictor_early_stopping.stop_training:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Goal Area Predictor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GoalAreaPredictor = GoalAreaPredictorModel(vocabulary_size = VOCABULARY_SIZE,\n",
    "                                                 embedding_dim = EMBEDDING_DIM,\n",
    "                                                 altered_embedding_dim = ALTERED_EMBEDDING_DIM,\n",
    "                                                 hidden_dim = HIDDEN_DIM,\n",
    "                                                 goal_area_predictor_dim = PREDICTOR_DIM,\n",
    "                                                 device = DEVICE)\n",
    "\n",
    "model_GoalAreaPredictor = model_GoalAreaPredictor.to(DEVICE)\n",
    "model_GoalAreaPredictor.load_state_dict(torch.load(\"model_PANFMR_incremental_GoalAreaPredictor.pt\"))\n",
    "model_GoalAreaPredictor.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Goal Name Predictor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_name_predictor_early_stopping = EarlyStopping(patience = 6)\n",
    "\n",
    "train_indices_loader = torch.utils.data.DataLoader(np.arange(raw_X_train.shape[0]), batch_size = BATCH_SIZE, shuffle = True)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    logging.info(\"Epoch\\t{}/{}\".format(epoch + 1, NUM_EPOCHS))\n",
    "    \n",
    "    model_GoalNamePredictor = model_GoalNamePredictor.train()\n",
    "    \n",
    "    for train_indices in tqdm_notebook(train_indices_loader, total = len(train_indices_loader)):\n",
    "        \n",
    "        optimizer_GoalNamePredictorModel.zero_grad()\n",
    "            \n",
    "        dialogs_loss = 0\n",
    "    \n",
    "        for raw_X_train_dialog, train_predictor_Y_dialog in zip(raw_X_train[train_indices], train_predictor_Y[train_indices]):\n",
    "\n",
    "            model_GoalNamePredictor.hidden = model_GoalNamePredictor.init_hidden()\n",
    "\n",
    "            for raw_X_train_turn, train_predictor_Y_turn in zip(raw_X_train_dialog[\"turns\"], train_predictor_Y_dialog[\"turns\"]):\n",
    "\n",
    "                indices, scores = get_index_and_score(raw_X_train_turn, token_to_index, mode = \"train\", device = DEVICE)\n",
    "\n",
    "                goal_names_predictor = model_GoalNamePredictor(indices, scores)\n",
    "\n",
    "                for goal_name_predictor, gold_goal_name_predictor in zip(goal_names_predictor, train_predictor_Y_turn[\"goal_name_predictor\"]):\n",
    "\n",
    "                    goal_name_predictor = goal_name_predictor.unsqueeze(0)\n",
    "                    \n",
    "                    gold_goal_name_predictor = torch.tensor([gold_goal_name_predictor], dtype = torch.long, device = DEVICE)\n",
    "                    \n",
    "                    loss_goal_name_predictor = PREDICTOR_LOSS_FUNCTION(goal_name_predictor, gold_goal_name_predictor)\n",
    "\n",
    "                    dialogs_loss += loss_goal_name_predictor\n",
    "                \n",
    "        dialogs_loss.backward(retain_graph = False)\n",
    "\n",
    "        optimizer_GoalNamePredictorModel.step()\n",
    "    \n",
    "    train_loss = compute_predictor_loss(model_GoalNamePredictor, raw_X_train, train_predictor_Y, objective = \"goal_name_predictor\", device = DEVICE)\n",
    "    dev_loss = compute_predictor_loss(model_GoalNamePredictor, raw_X_dev, dev_predictor_Y, objective = \"goal_name_predictor\", device = DEVICE)\n",
    "    \n",
    "    logging.info(\"TRAIN LOSS: {}\\tDEV LOSS: {}\".format(train_loss.item(), dev_loss.item()))\n",
    "\n",
    "    goal_name_predictor_early_stopping.on_epoch_end(epoch = (epoch + 1), current_value = -dev_loss.item())\n",
    "    \n",
    "    if goal_name_predictor_early_stopping.wait == 0:\n",
    "        torch.save(model_GoalNamePredictor.state_dict(), \"model_PANFMR_incremental_GoalNamePredictor.pt\")\n",
    "    \n",
    "    if goal_name_predictor_early_stopping.stop_training:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Goal Name Predictor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GoalNamePredictor = GoalNamePredictorModel(vocabulary_size = VOCABULARY_SIZE,\n",
    "                                                 embedding_dim = EMBEDDING_DIM,\n",
    "                                                 altered_embedding_dim = ALTERED_EMBEDDING_DIM,\n",
    "                                                 hidden_dim = HIDDEN_DIM,\n",
    "                                                 goal_name_predictor_dim = PREDICTOR_DIM,\n",
    "                                                 device = DEVICE)\n",
    "\n",
    "model_GoalNamePredictor = model_GoalNamePredictor.to(DEVICE)\n",
    "model_GoalNamePredictor.load_state_dict(torch.load(\"model_PANFMR_incremental_GoalNamePredictor.pt\"))\n",
    "model_GoalNamePredictor.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Goal Food Predictor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_food_predictor_early_stopping = EarlyStopping(patience = 6)\n",
    "\n",
    "train_indices_loader = torch.utils.data.DataLoader(np.arange(raw_X_train.shape[0]), batch_size = BATCH_SIZE, shuffle = True)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    logging.info(\"Epoch\\t{}/{}\".format(epoch + 1, NUM_EPOCHS))\n",
    "    \n",
    "    model_GoalFoodPredictor = model_GoalFoodPredictor.train()\n",
    "    \n",
    "    for train_indices in tqdm_notebook(train_indices_loader, total = len(train_indices_loader)):\n",
    "        \n",
    "        optimizer_GoalFoodPredictorModel.zero_grad()\n",
    "            \n",
    "        dialogs_loss = 0\n",
    "    \n",
    "        for raw_X_train_dialog, train_predictor_Y_dialog in zip(raw_X_train[train_indices], train_predictor_Y[train_indices]):\n",
    "\n",
    "            model_GoalFoodPredictor.hidden = model_GoalFoodPredictor.init_hidden()\n",
    "\n",
    "            for raw_X_train_turn, train_predictor_Y_turn in zip(raw_X_train_dialog[\"turns\"], train_predictor_Y_dialog[\"turns\"]):\n",
    "\n",
    "                indices, scores = get_index_and_score(raw_X_train_turn, token_to_index, mode = \"train\", device = DEVICE)\n",
    "\n",
    "                goal_foods_predictor = model_GoalFoodPredictor(indices, scores)\n",
    "\n",
    "                for goal_food_predictor, gold_goal_food_predictor in zip(goal_foods_predictor, train_predictor_Y_turn[\"goal_food_predictor\"]):\n",
    "\n",
    "                    goal_food_predictor = goal_food_predictor.unsqueeze(0)\n",
    "                    \n",
    "                    gold_goal_food_predictor = torch.tensor([gold_goal_food_predictor], dtype = torch.long, device = DEVICE)\n",
    "                    \n",
    "                    loss_goal_food_predictor = PREDICTOR_LOSS_FUNCTION(goal_food_predictor, gold_goal_food_predictor)\n",
    "\n",
    "                    dialogs_loss += loss_goal_food_predictor\n",
    "                \n",
    "        dialogs_loss.backward(retain_graph = False)\n",
    "\n",
    "        optimizer_GoalFoodPredictorModel.step()\n",
    "    \n",
    "    train_loss = compute_predictor_loss(model_GoalFoodPredictor, raw_X_train, train_predictor_Y, objective = \"goal_food_predictor\", device = DEVICE)\n",
    "    dev_loss = compute_predictor_loss(model_GoalFoodPredictor, raw_X_dev, dev_predictor_Y, objective = \"goal_food_predictor\", device = DEVICE)\n",
    "    \n",
    "    logging.info(\"TRAIN LOSS: {}\\tDEV LOSS: {}\".format(train_loss.item(), dev_loss.item()))\n",
    "\n",
    "    goal_food_predictor_early_stopping.on_epoch_end(epoch = (epoch + 1), current_value = -dev_loss.item())\n",
    "    \n",
    "    if goal_food_predictor_early_stopping.wait == 0:\n",
    "        torch.save(model_GoalFoodPredictor.state_dict(), \"model_PANFMR_incremental_GoalFoodPredictor.pt\")\n",
    "    \n",
    "    if goal_food_predictor_early_stopping.stop_training:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Goal Food Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GoalFoodPredictor = GoalFoodPredictorModel(vocabulary_size = VOCABULARY_SIZE,\n",
    "                                                 embedding_dim = EMBEDDING_DIM,\n",
    "                                                 altered_embedding_dim = ALTERED_EMBEDDING_DIM,\n",
    "                                                 hidden_dim = HIDDEN_DIM,\n",
    "                                                 goal_food_predictor_dim = PREDICTOR_DIM,\n",
    "                                                 device = DEVICE)\n",
    "\n",
    "model_GoalFoodPredictor = model_GoalFoodPredictor.to(DEVICE)\n",
    "model_GoalFoodPredictor.load_state_dict(torch.load(\"model_PANFMR_incremental_GoalFoodPredictor.pt\"))\n",
    "model_GoalFoodPredictor.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Requested Predictor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requested_predictor_early_stopping = EarlyStopping(patience = 6)\n",
    "\n",
    "train_indices_loader = torch.utils.data.DataLoader(np.arange(raw_X_train.shape[0]), batch_size = BATCH_SIZE, shuffle = True)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    logging.info(\"Epoch\\t{}/{}\".format(epoch + 1, NUM_EPOCHS))\n",
    "    \n",
    "    model_RequestedPredictor = model_RequestedPredictor.train()\n",
    "    \n",
    "    for train_indices in tqdm_notebook(train_indices_loader, total = len(train_indices_loader)):\n",
    "        \n",
    "        optimizer_RequestedPredictorModel.zero_grad()\n",
    "            \n",
    "        dialogs_loss = 0\n",
    "    \n",
    "        for raw_X_train_dialog, train_predictor_Y_dialog in zip(raw_X_train[train_indices], train_predictor_Y[train_indices]):\n",
    "\n",
    "            model_RequestedPredictor.hidden = model_RequestedPredictor.init_hidden()\n",
    "\n",
    "            for raw_X_train_turn, train_predictor_Y_turn in zip(raw_X_train_dialog[\"turns\"], train_predictor_Y_dialog[\"turns\"]):\n",
    "\n",
    "                indices, scores = get_index_and_score(raw_X_train_turn, token_to_index, mode = \"train\", device = DEVICE)\n",
    "\n",
    "                requesteds_predictor = model_RequestedPredictor(indices, scores)\n",
    "\n",
    "                for requested_predictor, gold_requested_predictor in zip(requesteds_predictor, train_predictor_Y_turn[\"requested_predictor\"]):\n",
    "\n",
    "                    requested_predictor = requested_predictor.unsqueeze(0)\n",
    "                    \n",
    "                    gold_requested_predictor = torch.tensor([gold_requested_predictor], dtype = torch.long, device = DEVICE)\n",
    "                    \n",
    "                    loss_requested_predictor = PREDICTOR_LOSS_FUNCTION(requested_predictor, gold_requested_predictor)\n",
    "\n",
    "                    dialogs_loss += loss_requested_predictor\n",
    "                \n",
    "        dialogs_loss.backward(retain_graph = False)\n",
    "\n",
    "        optimizer_RequestedPredictorModel.step()\n",
    "    \n",
    "    train_loss = compute_predictor_loss(model_RequestedPredictor, raw_X_train, train_predictor_Y, objective = \"requested_predictor\", device = DEVICE)\n",
    "    dev_loss = compute_predictor_loss(model_RequestedPredictor, raw_X_dev, dev_predictor_Y, objective = \"requested_predictor\", device = DEVICE)\n",
    "    \n",
    "    logging.info(\"TRAIN LOSS: {}\\tDEV LOSS: {}\".format(train_loss.item(), dev_loss.item()))\n",
    "\n",
    "    requested_predictor_early_stopping.on_epoch_end(epoch = (epoch + 1), current_value = -dev_loss.item())\n",
    "    \n",
    "    if requested_predictor_early_stopping.wait == 0:\n",
    "        torch.save(model_RequestedPredictor.state_dict(), \"model_PANFMR_incremental_RequestedPredictor.pt\")\n",
    "    \n",
    "    if requested_predictor_early_stopping.stop_training:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Requested Predictor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RequestedPredictor = RequestedPredictorModel(vocabulary_size = VOCABULARY_SIZE,\n",
    "                                                   embedding_dim = EMBEDDING_DIM,\n",
    "                                                   altered_embedding_dim = ALTERED_EMBEDDING_DIM,\n",
    "                                                   hidden_dim = HIDDEN_DIM,\n",
    "                                                   requested_predictor_dim = PREDICTOR_DIM,\n",
    "                                                   device = DEVICE)\n",
    "\n",
    "model_RequestedPredictor = model_RequestedPredictor.to(DEVICE)\n",
    "model_RequestedPredictor.load_state_dict(torch.load(\"model_PANFMR_incremental_RequestedPredictor.pt\"))\n",
    "model_RequestedPredictor.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Method Predictor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_predictor_early_stopping = EarlyStopping(patience = 6)\n",
    "\n",
    "train_indices_loader = torch.utils.data.DataLoader(np.arange(raw_X_train.shape[0]), batch_size = BATCH_SIZE, shuffle = True)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    logging.info(\"Epoch\\t{}/{}\".format(epoch + 1, NUM_EPOCHS))\n",
    "    \n",
    "    model_MethodPredictor = model_MethodPredictor.train()\n",
    "    \n",
    "    for train_indices in tqdm_notebook(train_indices_loader, total = len(train_indices_loader)):\n",
    "        \n",
    "        optimizer_MethodPredictorModel.zero_grad()\n",
    "            \n",
    "        dialogs_loss = 0\n",
    "    \n",
    "        for raw_X_train_dialog, train_predictor_Y_dialog in zip(raw_X_train[train_indices], train_predictor_Y[train_indices]):\n",
    "\n",
    "            model_MethodPredictor.hidden = model_MethodPredictor.init_hidden()\n",
    "\n",
    "            for raw_X_train_turn, train_predictor_Y_turn in zip(raw_X_train_dialog[\"turns\"], train_predictor_Y_dialog[\"turns\"]):\n",
    "\n",
    "                indices, scores = get_index_and_score(raw_X_train_turn, token_to_index, mode = \"train\", device = DEVICE)\n",
    "\n",
    "                methods_predictor = model_MethodPredictor(indices, scores)\n",
    "\n",
    "                for method_predictor, gold_method_predictor in zip(methods_predictor, train_predictor_Y_turn[\"method_predictor\"]):\n",
    "\n",
    "                    method_predictor = method_predictor.unsqueeze(0)\n",
    "                    \n",
    "                    gold_method_predictor = torch.tensor([gold_method_predictor], dtype = torch.long, device = DEVICE)\n",
    "                    \n",
    "                    loss_method_predictor = PREDICTOR_LOSS_FUNCTION(method_predictor, gold_method_predictor)\n",
    "\n",
    "                    dialogs_loss += loss_method_predictor\n",
    "                \n",
    "        dialogs_loss.backward(retain_graph = False)\n",
    "\n",
    "        optimizer_MethodPredictorModel.step()\n",
    "    \n",
    "    train_loss = compute_predictor_loss(model_MethodPredictor, raw_X_train, train_predictor_Y, objective = \"method_predictor\", device = DEVICE)\n",
    "    dev_loss = compute_predictor_loss(model_MethodPredictor, raw_X_dev, dev_predictor_Y, objective = \"method_predictor\", device = DEVICE)\n",
    "    \n",
    "    logging.info(\"TRAIN LOSS: {}\\tDEV LOSS: {}\".format(train_loss.item(), dev_loss.item()))\n",
    "\n",
    "    method_predictor_early_stopping.on_epoch_end(epoch = (epoch + 1), current_value = -dev_loss.item())\n",
    "    \n",
    "    if method_predictor_early_stopping.wait == 0:\n",
    "        torch.save(model_MethodPredictor.state_dict(), \"model_PANFMR_incremental_MethodPredictor.pt\")\n",
    "    \n",
    "    if method_predictor_early_stopping.stop_training:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Method Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_MethodPredictor = MethodPredictorModel(vocabulary_size = VOCABULARY_SIZE,\n",
    "                                             embedding_dim = EMBEDDING_DIM,\n",
    "                                             altered_embedding_dim = ALTERED_EMBEDDING_DIM,\n",
    "                                             hidden_dim = HIDDEN_DIM,\n",
    "                                             method_predictor_dim = PREDICTOR_DIM,\n",
    "                                             device = DEVICE)\n",
    "\n",
    "model_MethodPredictor = model_MethodPredictor.to(DEVICE)\n",
    "model_MethodPredictor.load_state_dict(torch.load(\"model_PANFMR_incremental_MethodPredictor.pt\"))\n",
    "model_MethodPredictor.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictor_tracker(model_GoalPricerange, model_GoalArea, model_GoalName, model_GoalFood, model_Requested, model_Method,\n",
    "                           model_GoalPricerangePredictor, model_GoalAreaPredictor, model_GoalNamePredictor, model_GoalFoodPredictor, model_RequestedPredictor, model_MethodPredictor,\n",
    "                           raw_X, raw_Y, dataset):\n",
    "    \n",
    "    model_GoalPricerange = model_GoalPricerange.eval()\n",
    "    model_GoalArea = model_GoalArea.eval()\n",
    "    model_GoalName = model_GoalName.eval()\n",
    "    model_GoalFood = model_GoalFood.eval()\n",
    "    model_Requested = model_Requested.eval()\n",
    "    model_Method = model_Method.eval()\n",
    "    \n",
    "    model_GoalPricerangePredictor = model_GoalPricerangePredictor.eval()\n",
    "    model_GoalAreaPredictor = model_GoalAreaPredictor.eval()\n",
    "    model_GoalNamePredictor = model_GoalNamePredictor.eval()\n",
    "    model_GoalFoodPredictor = model_GoalFoodPredictor.eval()\n",
    "    model_RequestedPredictor = model_RequestedPredictor.eval()\n",
    "    model_MethodPredictor = model_MethodPredictor.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        tracker_json = {}\n",
    "        tracker_json[\"dataset\"] = dataset\n",
    "        tracker_json[\"sessions\"] = []\n",
    "\n",
    "        start_time = time.time()\n",
    "        for raw_X_dialog, raw_Y_dialog in tqdm_notebook(zip(raw_X, raw_Y), total = len(raw_X)):\n",
    "            \n",
    "            model_GoalPricerange.hidden = model_GoalPricerange.init_hidden()\n",
    "            model_GoalArea.hidden = model_GoalArea.init_hidden()\n",
    "            model_GoalName.hidden = model_GoalName.init_hidden()\n",
    "            model_GoalFood.hidden = model_GoalFood.init_hidden()\n",
    "            model_Requested.hidden = model_Requested.init_hidden()\n",
    "            model_Method.hidden = model_Method.init_hidden()\n",
    "            \n",
    "            model_GoalPricerangePredictor.hidden = model_GoalPricerangePredictor.init_hidden()\n",
    "            model_GoalAreaPredictor.hidden = model_GoalAreaPredictor.init_hidden()\n",
    "            model_GoalNamePredictor.hidden = model_GoalNamePredictor.init_hidden()\n",
    "            model_GoalFoodPredictor.hidden = model_GoalFoodPredictor.init_hidden()\n",
    "            model_RequestedPredictor.hidden = model_RequestedPredictor.init_hidden()\n",
    "            model_MethodPredictor.hidden = model_MethodPredictor.init_hidden()\n",
    "            \n",
    "            session = {}\n",
    "            session[\"session-id\"] = raw_X_dialog[\"session-id\"]\n",
    "            session[\"turns\"] = []\n",
    "\n",
    "            for raw_X_turn, raw_Y_turn in zip(raw_X_dialog[\"turns\"], raw_Y_dialog[\"turns\"]):\n",
    "                \n",
    "                turn = {}\n",
    "                turn[\"goal-labels\"] = {}\n",
    "\n",
    "                indices, scores = get_index_and_score(raw_X_turn, token_to_index, mode = \"eval\", device = DEVICE)\n",
    "                                \n",
    "                goal_priceranges = model_GoalPricerange(indices, scores)\n",
    "                goal_areas = model_GoalArea(indices, scores)\n",
    "                goal_names = model_GoalName(indices, scores)\n",
    "                goal_foods = model_GoalFood(indices, scores)\n",
    "                requesteds = model_Requested(indices, scores)\n",
    "                methods = model_Method(indices, scores)\n",
    "                \n",
    "                goal_priceranges_predictor = model_GoalPricerangePredictor(indices, scores)\n",
    "                goal_areas_predictor = model_GoalAreaPredictor(indices, scores)\n",
    "                goal_names_predictor = model_GoalNamePredictor(indices, scores)\n",
    "                goal_foods_predictor = model_GoalFoodPredictor(indices, scores)\n",
    "                requesteds_predictor = model_RequestedPredictor(indices, scores)\n",
    "                methods_predictor = model_MethodPredictor(indices, scores)\n",
    "                \n",
    "                for goal_pricerange, goal_area, goal_name, goal_food, requested, method, \\\n",
    "                    goal_pricerange_predictor, goal_area_predictor, goal_name_predictor, goal_food_predictor, requested_predictor, method_predictor in \\\n",
    "                    zip(goal_priceranges, goal_areas, goal_names, goal_foods, requesteds, methods, \\\n",
    "                       goal_priceranges_predictor, goal_areas_predictor, goal_names_predictor, goal_foods_predictor, requesteds_predictor, methods_predictor):\n",
    "                    \n",
    "                    goal_pricerange_predictor = torch.exp(goal_pricerange_predictor)[0].item()\n",
    "                    goal_area_predictor = torch.exp(goal_area_predictor)[0].item()\n",
    "                    goal_name_predictor = torch.exp(goal_name_predictor)[0].item()\n",
    "                    goal_food_predictor = torch.exp(goal_food_predictor)[0].item()\n",
    "                    requested_predictor = torch.exp(requested_predictor)[0].item()\n",
    "                    method_predictor = torch.exp(method_predictor)[0].item()\n",
    "                    \n",
    "                    if (goal_pricerange_predictor >= 0.5) and (goal_area_predictor >= 0.5) and (goal_name_predictor >= 0.5) and \\\n",
    "                        (goal_food_predictor >= 0.5) and (requested_predictor >= 0.5) and (method_predictor >= 0.5):\n",
    "                        turn[\"goal-labels\"][\"pricerange\"] = retrieve_output_GoalPricerange(goal_pricerange, ontology)\n",
    "                        turn[\"goal-labels\"][\"name\"] = retrieve_output_GoalName(goal_name, ontology)\n",
    "                        turn[\"goal-labels\"][\"area\"] = retrieve_output_GoalArea(goal_area, ontology)\n",
    "                        turn[\"goal-labels\"][\"food\"] = retrieve_output_GoalFood(goal_food, ontology)\n",
    "                        turn[\"requested-slots\"] = retrieve_output_Requested(requested, ontology)\n",
    "                        turn[\"method-label\"] = retrieve_output_Method(method, ontology)\n",
    "                \n",
    "                        session[\"turns\"].append(turn)\n",
    "                        break\n",
    "                \n",
    "            tracker_json[\"sessions\"].append(session)\n",
    "            \n",
    "        end_time = time.time()\n",
    "        tracker_json[\"wall-time\"] = end_time - start_time\n",
    "        \n",
    "        return tracker_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_tracker = make_predictor_tracker(model_GoalPricerange, model_GoalArea, model_GoalName, model_GoalFood, model_Requested, model_Method,\n",
    "                                     model_GoalPricerangePredictor, model_GoalAreaPredictor, model_GoalNamePredictor, model_GoalFoodPredictor, model_RequestedPredictor, model_MethodPredictor,\n",
    "                                     raw_X_dev, raw_Y_dev, \"dstc2_dev\")\n",
    "get_scores(dev_tracker, dataset = \"dstc2_dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
